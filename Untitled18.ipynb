{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeIQv21LDJmgH5rsqQdJBc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elijahManPerson/hello-world/blob/master/Untitled18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nduqisxESLGu",
        "outputId": "c7646b17-a0da-4eed-cd46-6fc673d7b9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.utils import class_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing or non-string values by replacing them with empty strings\n",
        "df_preprocessed['Raw text'] = df_preprocessed['Raw text'].fillna('')\n",
        "\n",
        "# Feature Engineering: Add sentence length and text length as features\n",
        "df_preprocessed['TextLength'] = df_preprocessed['Raw text'].apply(lambda x: len(str(x)))  # Ensure it's a string\n",
        "df_preprocessed['AvgSentenceLength'] = df_preprocessed['Raw text'].apply(lambda x: len(x.split()) / (x.count('.') + 1) if len(x.split()) > 0 else 0)  # Avoid division by zero\n",
        "\n",
        "# Define features (X) and target variables (y)\n",
        "X = df_preprocessed[['WordCount', 'TextLength', 'AvgSentenceLength', 'Raw text']]  # Include Raw text and new features\n",
        "y = df_preprocessed[['Pun', 'Spell', 'Voc', 'SS', 'AU', 'TS', 'ID', 'CS/PD', 'Coh', 'Pa', 'Total']]  # Target variables\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "q1O8TWwnSOta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Preprocessing using TF-IDF on 'Raw text'\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "X_train_text = tfidf.fit_transform(X_train['Raw text'].fillna('')).toarray()\n",
        "X_test_text = tfidf.transform(X_test['Raw text'].fillna('')).toarray()\n",
        "\n",
        "# Scale WordCount, TextLength, and AvgSentenceLength features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train[['WordCount', 'TextLength', 'AvgSentenceLength']])\n",
        "X_test_scaled = scaler.transform(X_test[['WordCount', 'TextLength', 'AvgSentenceLength']])\n",
        "\n",
        "# Combine scaled WordCount, TextLength, AvgSentenceLength with TF-IDF features\n",
        "X_train_combined = np.hstack([X_train_scaled, X_train_text])\n",
        "X_test_combined = np.hstack([X_test_scaled, X_test_text])\n"
      ],
      "metadata": {
        "id": "KywsrOmeSUOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to build the model with dropout and batch normalization\n",
        "def build_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
        "    model.add(BatchNormalization())  # Added batch normalization\n",
        "    model.add(Dropout(0.3))  # Added dropout\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "H0ueItw0SXHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to build the model with dropout and batch normalization\n",
        "def build_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=(input_dim,)))  # Updated input shape\n",
        "    model.add(BatchNormalization())  # Added batch normalization\n",
        "    model.add(Dropout(0.3))  # Added dropout\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Train models for each criterion using k-fold cross-validation\n",
        "models = {}\n",
        "for criterion, column in zip(['Punctuation', 'Spelling', 'Vocabulary', 'SentenceStructure', 'AU', 'TS', 'ID', 'CS/PD', 'Coh', 'Pa', 'Total'],\n",
        "                             ['Pun', 'Spell', 'Voc', 'SS', 'AU', 'TS', 'ID', 'CS/PD', 'Coh', 'Pa', 'Total']):\n",
        "    print(f'Training model for {criterion}...')\n",
        "\n",
        "    # Extract the target column for the current criterion\n",
        "    y_train_criterion = y_train[column].values  # Ensure it's numpy array, not pandas Series\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(X_train_combined):\n",
        "        X_fold_train, X_fold_val = X_train_combined[train_idx], X_train_combined[val_idx]\n",
        "        y_fold_train, y_fold_val = y_train_criterion[train_idx], y_train_criterion[val_idx]  # Corrected index access\n",
        "\n",
        "        # Build the model\n",
        "        model = build_model(input_dim=X_train_combined.shape[1])\n",
        "\n",
        "        # Calculate class weights to handle imbalance\n",
        "        class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_fold_train), y=y_fold_train)\n",
        "        class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "        # Train the model using k-fold data\n",
        "        history = model.fit(X_fold_train, y_fold_train, epochs=50, batch_size=32, validation_data=(X_fold_val, y_fold_val),\n",
        "                            class_weight=class_weights_dict, verbose=1)\n",
        "\n",
        "    # Save the model for each criterion\n",
        "    models[criterion] = model\n",
        "    test_loss, test_mae = model.evaluate(X_test_combined, y_test[column].values)  # Ensure y_test[column] is an array\n",
        "    print(f'Test MAE for {criterion}: {test_mae}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ8e2yZISaOy",
        "outputId": "c579877c-d617-4916-d7dc-a1e85045cdc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for Punctuation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 10.4676 - mae: 2.8240 - val_loss: 1.6712 - val_mae: 1.0714\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1184 - mae: 1.0091 - val_loss: 0.7725 - val_mae: 0.7153\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5485 - mae: 0.8158 - val_loss: 0.8137 - val_mae: 0.7457\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1604 - mae: 0.7836 - val_loss: 0.6483 - val_mae: 0.6557\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9475 - mae: 0.7569 - val_loss: 0.5861 - val_mae: 0.6234\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9657 - mae: 0.7658 - val_loss: 0.7104 - val_mae: 0.6584\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9143 - mae: 0.7529 - val_loss: 0.5204 - val_mae: 0.5778\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7562 - mae: 0.6491 - val_loss: 0.6955 - val_mae: 0.6451\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7028 - mae: 0.6748 - val_loss: 0.5456 - val_mae: 0.5827\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7665 - mae: 0.6733 - val_loss: 0.5128 - val_mae: 0.5675\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6349 - mae: 0.6184 - val_loss: 0.8596 - val_mae: 0.7098\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7149 - mae: 0.6792 - val_loss: 0.5590 - val_mae: 0.5823\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7556 - mae: 0.6333 - val_loss: 0.5968 - val_mae: 0.6016\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5568 - mae: 0.6253 - val_loss: 0.5623 - val_mae: 0.5859\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4801 - mae: 0.5903 - val_loss: 0.6747 - val_mae: 0.6261\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5244 - mae: 0.6049 - val_loss: 0.5790 - val_mae: 0.6004\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5149 - mae: 0.6038 - val_loss: 0.6390 - val_mae: 0.6365\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4192 - mae: 0.5544 - val_loss: 0.5488 - val_mae: 0.5929\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4940 - mae: 0.5334 - val_loss: 0.5527 - val_mae: 0.5916\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4449 - mae: 0.5557 - val_loss: 0.6224 - val_mae: 0.6315\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4785 - mae: 0.5662 - val_loss: 0.5436 - val_mae: 0.5833\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3555 - mae: 0.4991 - val_loss: 0.5271 - val_mae: 0.5758\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3555 - mae: 0.5097 - val_loss: 0.6379 - val_mae: 0.6278\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4102 - mae: 0.5141 - val_loss: 0.6664 - val_mae: 0.6400\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4050 - mae: 0.5459 - val_loss: 0.6399 - val_mae: 0.6277\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3959 - mae: 0.5220 - val_loss: 0.5763 - val_mae: 0.6036\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3263 - mae: 0.4899 - val_loss: 0.4903 - val_mae: 0.5564\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3496 - mae: 0.4661 - val_loss: 0.5923 - val_mae: 0.6142\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3678 - mae: 0.4897 - val_loss: 0.4902 - val_mae: 0.5563\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3508 - mae: 0.4772 - val_loss: 0.5030 - val_mae: 0.5630\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3318 - mae: 0.4606 - val_loss: 0.5433 - val_mae: 0.5832\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3127 - mae: 0.4737 - val_loss: 0.5779 - val_mae: 0.6000\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3820 - mae: 0.4692 - val_loss: 0.5301 - val_mae: 0.5798\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3080 - mae: 0.4529 - val_loss: 0.7504 - val_mae: 0.6806\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2530 - mae: 0.4492 - val_loss: 0.5764 - val_mae: 0.6049\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3202 - mae: 0.4671 - val_loss: 0.5308 - val_mae: 0.5782\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2444 - mae: 0.4232 - val_loss: 0.5419 - val_mae: 0.5857\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2499 - mae: 0.4378 - val_loss: 0.5929 - val_mae: 0.6077\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2785 - mae: 0.4205 - val_loss: 0.5232 - val_mae: 0.5655\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2656 - mae: 0.4283 - val_loss: 0.5308 - val_mae: 0.5738\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2409 - mae: 0.4130 - val_loss: 0.5821 - val_mae: 0.6065\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2880 - mae: 0.4255 - val_loss: 0.6693 - val_mae: 0.6448\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2591 - mae: 0.4134 - val_loss: 0.5496 - val_mae: 0.5892\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2277 - mae: 0.4010 - val_loss: 0.5621 - val_mae: 0.5950\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2577 - mae: 0.3990 - val_loss: 0.5643 - val_mae: 0.5930\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3015 - mae: 0.4082 - val_loss: 0.5538 - val_mae: 0.5870\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2236 - mae: 0.3987 - val_loss: 0.5234 - val_mae: 0.5722\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2322 - mae: 0.4009 - val_loss: 0.5890 - val_mae: 0.6054\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2314 - mae: 0.3818 - val_loss: 0.5517 - val_mae: 0.5883\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2241 - mae: 0.3956 - val_loss: 0.6078 - val_mae: 0.6153\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 5.2796 - mae: 1.9014 - val_loss: 2.2339 - val_mae: 1.3079\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.5978 - mae: 0.9931 - val_loss: 0.9812 - val_mae: 0.7967\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5331 - mae: 0.8875 - val_loss: 0.5388 - val_mae: 0.5693\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.1446 - mae: 0.7746 - val_loss: 0.4948 - val_mae: 0.5492\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9414 - mae: 0.7688 - val_loss: 0.4726 - val_mae: 0.5485\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7311 - mae: 0.7333 - val_loss: 0.5021 - val_mae: 0.5622\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8047 - mae: 0.7096 - val_loss: 0.5009 - val_mae: 0.5642\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6156 - mae: 0.6991 - val_loss: 0.4747 - val_mae: 0.5514\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6979 - mae: 0.6744 - val_loss: 0.5735 - val_mae: 0.6035\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6217 - mae: 0.6698 - val_loss: 0.5384 - val_mae: 0.5874\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6531 - mae: 0.6300 - val_loss: 0.6647 - val_mae: 0.6378\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5002 - mae: 0.6422 - val_loss: 0.5206 - val_mae: 0.5757\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4714 - mae: 0.5973 - val_loss: 0.5398 - val_mae: 0.5868\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5027 - mae: 0.6028 - val_loss: 0.5378 - val_mae: 0.5870\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5396 - mae: 0.5967 - val_loss: 0.5489 - val_mae: 0.5889\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4682 - mae: 0.5736 - val_loss: 0.5002 - val_mae: 0.5662\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5368 - mae: 0.5786 - val_loss: 0.5278 - val_mae: 0.5820\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3916 - mae: 0.5451 - val_loss: 0.4946 - val_mae: 0.5625\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5856 - mae: 0.5687 - val_loss: 0.6174 - val_mae: 0.6239\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4236 - mae: 0.5601 - val_loss: 0.5654 - val_mae: 0.5954\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4412 - mae: 0.5303 - val_loss: 0.5092 - val_mae: 0.5689\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4256 - mae: 0.5364 - val_loss: 0.5305 - val_mae: 0.5836\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4424 - mae: 0.5334 - val_loss: 0.5454 - val_mae: 0.5925\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4011 - mae: 0.5275 - val_loss: 0.5102 - val_mae: 0.5689\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3909 - mae: 0.5193 - val_loss: 0.5439 - val_mae: 0.5856\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3106 - mae: 0.4997 - val_loss: 0.5288 - val_mae: 0.5792\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3295 - mae: 0.4998 - val_loss: 0.5241 - val_mae: 0.5768\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3234 - mae: 0.4787 - val_loss: 0.5022 - val_mae: 0.5681\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3230 - mae: 0.4705 - val_loss: 0.5207 - val_mae: 0.5760\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3144 - mae: 0.4594 - val_loss: 0.5466 - val_mae: 0.5866\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3063 - mae: 0.4709 - val_loss: 0.4948 - val_mae: 0.5637\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2692 - mae: 0.4605 - val_loss: 0.5094 - val_mae: 0.5737\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3398 - mae: 0.4704 - val_loss: 0.5454 - val_mae: 0.5902\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2902 - mae: 0.4490 - val_loss: 0.5607 - val_mae: 0.5941\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2927 - mae: 0.4557 - val_loss: 0.5070 - val_mae: 0.5674\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3288 - mae: 0.4393 - val_loss: 0.5504 - val_mae: 0.5946\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2826 - mae: 0.4446 - val_loss: 0.5360 - val_mae: 0.5855\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2485 - mae: 0.4345 - val_loss: 0.5298 - val_mae: 0.5839\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2244 - mae: 0.4208 - val_loss: 0.5270 - val_mae: 0.5809\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2248 - mae: 0.4151 - val_loss: 0.5325 - val_mae: 0.5822\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2731 - mae: 0.4251 - val_loss: 0.5453 - val_mae: 0.5921\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2713 - mae: 0.4378 - val_loss: 0.5425 - val_mae: 0.5927\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2039 - mae: 0.3805 - val_loss: 0.5518 - val_mae: 0.5950\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2272 - mae: 0.4183 - val_loss: 0.6587 - val_mae: 0.6361\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2749 - mae: 0.4067 - val_loss: 0.5120 - val_mae: 0.5690\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2716 - mae: 0.3979 - val_loss: 0.5168 - val_mae: 0.5712\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3158 - mae: 0.4005 - val_loss: 0.5164 - val_mae: 0.5726\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2546 - mae: 0.3992 - val_loss: 0.5415 - val_mae: 0.5853\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2520 - mae: 0.4027 - val_loss: 0.5562 - val_mae: 0.5925\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2172 - mae: 0.3930 - val_loss: 0.5421 - val_mae: 0.5886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 3.9278 - mae: 1.3946 - val_loss: 2.2458 - val_mae: 1.2990\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3440 - mae: 0.8582 - val_loss: 1.0906 - val_mae: 0.8354\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1369 - mae: 0.8156 - val_loss: 0.7991 - val_mae: 0.6877\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0886 - mae: 0.7280 - val_loss: 0.6122 - val_mae: 0.6196\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7516 - mae: 0.7141 - val_loss: 0.6039 - val_mae: 0.6191\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7767 - mae: 0.6956 - val_loss: 0.6532 - val_mae: 0.6436\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6824 - mae: 0.6708 - val_loss: 0.5679 - val_mae: 0.5917\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.8576 - mae: 0.6867 - val_loss: 0.6060 - val_mae: 0.6136\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7274 - mae: 0.6444 - val_loss: 0.5161 - val_mae: 0.5586\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5220 - mae: 0.6022 - val_loss: 0.5377 - val_mae: 0.5766\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5985 - mae: 0.6012 - val_loss: 0.5804 - val_mae: 0.6054\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5288 - mae: 0.6083 - val_loss: 0.5382 - val_mae: 0.5841\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5934 - mae: 0.6167 - val_loss: 0.5549 - val_mae: 0.5887\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4730 - mae: 0.5757 - val_loss: 0.6017 - val_mae: 0.6106\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4740 - mae: 0.5710 - val_loss: 0.5692 - val_mae: 0.5947\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4883 - mae: 0.5798 - val_loss: 0.5487 - val_mae: 0.5852\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5459 - mae: 0.5836 - val_loss: 0.5678 - val_mae: 0.5976\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4005 - mae: 0.5625 - val_loss: 0.5558 - val_mae: 0.5880\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4932 - mae: 0.5650 - val_loss: 0.5742 - val_mae: 0.5970\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4072 - mae: 0.5406 - val_loss: 0.5695 - val_mae: 0.5944\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3745 - mae: 0.5425 - val_loss: 0.5884 - val_mae: 0.6063\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3984 - mae: 0.5294 - val_loss: 0.5821 - val_mae: 0.6070\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3952 - mae: 0.5353 - val_loss: 0.5337 - val_mae: 0.5776\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3807 - mae: 0.4997 - val_loss: 0.5468 - val_mae: 0.5829\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3643 - mae: 0.5024 - val_loss: 0.5786 - val_mae: 0.5948\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3377 - mae: 0.4971 - val_loss: 0.5543 - val_mae: 0.5858\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.3576 - mae: 0.4838 - val_loss: 0.5571 - val_mae: 0.5861\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3173 - mae: 0.4924 - val_loss: 0.5598 - val_mae: 0.5925\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3472 - mae: 0.4919 - val_loss: 0.5743 - val_mae: 0.5987\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5121 - mae: 0.5888 - val_loss: 0.5524 - val_mae: 0.5898\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3548 - mae: 0.5005 - val_loss: 0.5939 - val_mae: 0.6064\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2876 - mae: 0.4771 - val_loss: 0.6141 - val_mae: 0.6259\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2933 - mae: 0.4819 - val_loss: 0.5768 - val_mae: 0.5998\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2870 - mae: 0.4728 - val_loss: 0.5049 - val_mae: 0.5608\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2837 - mae: 0.4688 - val_loss: 0.5576 - val_mae: 0.5861\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2834 - mae: 0.4549 - val_loss: 0.5346 - val_mae: 0.5768\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2809 - mae: 0.4503 - val_loss: 0.5343 - val_mae: 0.5813\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3187 - mae: 0.4289 - val_loss: 0.5428 - val_mae: 0.5814\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2439 - mae: 0.4247 - val_loss: 0.5221 - val_mae: 0.5645\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2629 - mae: 0.4173 - val_loss: 0.5329 - val_mae: 0.5758\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2748 - mae: 0.4427 - val_loss: 0.5497 - val_mae: 0.5820\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2830 - mae: 0.4381 - val_loss: 0.5353 - val_mae: 0.5707\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2252 - mae: 0.4257 - val_loss: 0.5445 - val_mae: 0.5791\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2945 - mae: 0.4306 - val_loss: 0.5624 - val_mae: 0.5850\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2545 - mae: 0.4162 - val_loss: 0.5612 - val_mae: 0.5842\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2080 - mae: 0.4087 - val_loss: 0.5194 - val_mae: 0.5616\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2485 - mae: 0.4014 - val_loss: 0.5570 - val_mae: 0.5841\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2462 - mae: 0.4011 - val_loss: 0.5415 - val_mae: 0.5705\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2174 - mae: 0.3947 - val_loss: 0.5593 - val_mae: 0.5851\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2429 - mae: 0.4088 - val_loss: 0.5630 - val_mae: 0.5848\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 6.8987 - mae: 2.0512 - val_loss: 1.5218 - val_mae: 1.0511\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6318 - mae: 1.0216 - val_loss: 0.5212 - val_mae: 0.5740\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2668 - mae: 0.8753 - val_loss: 0.4843 - val_mae: 0.5634\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1120 - mae: 0.8117 - val_loss: 0.4905 - val_mae: 0.5655\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2161 - mae: 0.7906 - val_loss: 0.5029 - val_mae: 0.5663\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8502 - mae: 0.7463 - val_loss: 0.5650 - val_mae: 0.6012\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8603 - mae: 0.7386 - val_loss: 0.6742 - val_mae: 0.6532\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8202 - mae: 0.7388 - val_loss: 0.7687 - val_mae: 0.7093\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7368 - mae: 0.6970 - val_loss: 0.6670 - val_mae: 0.6533\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6902 - mae: 0.6858 - val_loss: 0.5958 - val_mae: 0.6117\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7256 - mae: 0.6991 - val_loss: 0.5607 - val_mae: 0.5946\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5531 - mae: 0.6216 - val_loss: 0.6976 - val_mae: 0.6680\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6069 - mae: 0.6803 - val_loss: 0.6672 - val_mae: 0.6519\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5798 - mae: 0.6542 - val_loss: 0.5361 - val_mae: 0.5804\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5425 - mae: 0.6093 - val_loss: 0.5991 - val_mae: 0.6145\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5421 - mae: 0.6491 - val_loss: 0.5288 - val_mae: 0.5758\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5575 - mae: 0.5954 - val_loss: 0.5387 - val_mae: 0.5821\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4765 - mae: 0.5793 - val_loss: 0.5486 - val_mae: 0.5912\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5084 - mae: 0.5729 - val_loss: 0.5450 - val_mae: 0.5836\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4516 - mae: 0.5552 - val_loss: 0.5971 - val_mae: 0.6157\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4175 - mae: 0.5618 - val_loss: 0.6332 - val_mae: 0.6394\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3554 - mae: 0.5386 - val_loss: 0.6770 - val_mae: 0.6549\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3991 - mae: 0.5450 - val_loss: 0.5609 - val_mae: 0.5895\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4322 - mae: 0.5365 - val_loss: 0.5413 - val_mae: 0.5841\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4724 - mae: 0.5371 - val_loss: 0.6008 - val_mae: 0.6166\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3950 - mae: 0.5205 - val_loss: 0.6748 - val_mae: 0.6414\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4786 - mae: 0.5329 - val_loss: 0.5602 - val_mae: 0.5886\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3530 - mae: 0.5169 - val_loss: 0.5981 - val_mae: 0.6144\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4325 - mae: 0.5231 - val_loss: 0.5677 - val_mae: 0.5996\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3501 - mae: 0.5003 - val_loss: 0.5560 - val_mae: 0.5915\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3038 - mae: 0.4839 - val_loss: 0.5306 - val_mae: 0.5745\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3701 - mae: 0.4861 - val_loss: 0.5655 - val_mae: 0.5891\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3307 - mae: 0.4794 - val_loss: 0.5667 - val_mae: 0.5975\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4096 - mae: 0.4843 - val_loss: 0.5826 - val_mae: 0.6066\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3260 - mae: 0.4740 - val_loss: 0.5602 - val_mae: 0.5882\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3215 - mae: 0.4687 - val_loss: 0.5844 - val_mae: 0.6024\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2838 - mae: 0.4541 - val_loss: 0.5485 - val_mae: 0.5835\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3267 - mae: 0.4368 - val_loss: 0.5454 - val_mae: 0.5885\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2687 - mae: 0.4439 - val_loss: 0.5983 - val_mae: 0.6154\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2418 - mae: 0.4279 - val_loss: 0.6148 - val_mae: 0.6276\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2887 - mae: 0.4605 - val_loss: 0.5542 - val_mae: 0.5900\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3104 - mae: 0.4379 - val_loss: 0.5290 - val_mae: 0.5782\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2660 - mae: 0.4451 - val_loss: 0.5508 - val_mae: 0.5887\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2536 - mae: 0.4278 - val_loss: 0.5943 - val_mae: 0.6122\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2179 - mae: 0.4250 - val_loss: 0.5547 - val_mae: 0.5895\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2921 - mae: 0.4330 - val_loss: 0.5574 - val_mae: 0.5903\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2903 - mae: 0.4159 - val_loss: 0.5689 - val_mae: 0.5931\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2191 - mae: 0.4116 - val_loss: 0.5292 - val_mae: 0.5760\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3128 - mae: 0.4297 - val_loss: 0.5865 - val_mae: 0.6039\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3054 - mae: 0.4144 - val_loss: 0.6178 - val_mae: 0.6301\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 3.2139 - mae: 1.4304 - val_loss: 1.2320 - val_mae: 0.8717\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5241 - mae: 0.8950 - val_loss: 0.7567 - val_mae: 0.6486\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.0135 - mae: 0.8078 - val_loss: 0.6620 - val_mae: 0.6235\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.0137 - mae: 0.7651 - val_loss: 0.6321 - val_mae: 0.6115\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.7805 - mae: 0.7235 - val_loss: 0.5125 - val_mae: 0.5670\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1686 - mae: 0.7365 - val_loss: 0.5102 - val_mae: 0.5674\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.7197 - mae: 0.6919 - val_loss: 0.5131 - val_mae: 0.5592\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6720 - mae: 0.6659 - val_loss: 0.5238 - val_mae: 0.5662\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.5496 - mae: 0.6284 - val_loss: 0.5233 - val_mae: 0.5673\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5054 - mae: 0.6039 - val_loss: 0.5272 - val_mae: 0.5756\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5344 - mae: 0.6038 - val_loss: 0.5122 - val_mae: 0.5608\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5643 - mae: 0.6008 - val_loss: 0.5633 - val_mae: 0.5913\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4716 - mae: 0.5990 - val_loss: 0.6235 - val_mae: 0.6083\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5418 - mae: 0.5961 - val_loss: 0.5973 - val_mae: 0.5982\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5560 - mae: 0.5806 - val_loss: 0.6216 - val_mae: 0.6036\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4925 - mae: 0.5970 - val_loss: 0.5643 - val_mae: 0.5818\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.5003 - mae: 0.5658 - val_loss: 0.5105 - val_mae: 0.5604\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4712 - mae: 0.5678 - val_loss: 0.4687 - val_mae: 0.5392\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5505 - mae: 0.5568 - val_loss: 0.5888 - val_mae: 0.6067\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4107 - mae: 0.5815 - val_loss: 0.5536 - val_mae: 0.5829\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4964 - mae: 0.5596 - val_loss: 0.5814 - val_mae: 0.6008\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4518 - mae: 0.5339 - val_loss: 0.5351 - val_mae: 0.5744\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5364 - mae: 0.5315 - val_loss: 0.5239 - val_mae: 0.5710\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3433 - mae: 0.5175 - val_loss: 0.4936 - val_mae: 0.5492\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3278 - mae: 0.4997 - val_loss: 0.4884 - val_mae: 0.5449\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4314 - mae: 0.5032 - val_loss: 0.5656 - val_mae: 0.5798\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4323 - mae: 0.5098 - val_loss: 0.5144 - val_mae: 0.5630\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3924 - mae: 0.4875 - val_loss: 0.5098 - val_mae: 0.5609\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3346 - mae: 0.4745 - val_loss: 0.5579 - val_mae: 0.5864\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3225 - mae: 0.4819 - val_loss: 0.6384 - val_mae: 0.6273\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3597 - mae: 0.5205 - val_loss: 0.5219 - val_mae: 0.5670\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3787 - mae: 0.4818 - val_loss: 0.5399 - val_mae: 0.5812\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4204 - mae: 0.5031 - val_loss: 0.5545 - val_mae: 0.5926\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3947 - mae: 0.4888 - val_loss: 0.5286 - val_mae: 0.5659\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.3723 - mae: 0.4858 - val_loss: 0.5274 - val_mae: 0.5700\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3227 - mae: 0.4739 - val_loss: 0.4903 - val_mae: 0.5469\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3149 - mae: 0.4805 - val_loss: 0.5087 - val_mae: 0.5623\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3114 - mae: 0.4729 - val_loss: 0.4897 - val_mae: 0.5459\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.3895 - mae: 0.4607 - val_loss: 0.5019 - val_mae: 0.5575\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2581 - mae: 0.4456 - val_loss: 0.4762 - val_mae: 0.5419\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2819 - mae: 0.4417 - val_loss: 0.5052 - val_mae: 0.5600\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2701 - mae: 0.4461 - val_loss: 0.5054 - val_mae: 0.5564\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3248 - mae: 0.4255 - val_loss: 0.4960 - val_mae: 0.5514\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2702 - mae: 0.4481 - val_loss: 0.5381 - val_mae: 0.5741\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3008 - mae: 0.4381 - val_loss: 0.5201 - val_mae: 0.5670\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2762 - mae: 0.4183 - val_loss: 0.5327 - val_mae: 0.5726\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2483 - mae: 0.4272 - val_loss: 0.5788 - val_mae: 0.5959\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2706 - mae: 0.4380 - val_loss: 0.5239 - val_mae: 0.5667\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2475 - mae: 0.4068 - val_loss: 0.5368 - val_mae: 0.5733\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2601 - mae: 0.4269 - val_loss: 0.5564 - val_mae: 0.5781\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6097 - mae: 0.6045\n",
            "Test MAE for Punctuation: 0.604089081287384\n",
            "Training model for Spelling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 15.4222 - mae: 3.9202 - val_loss: 4.9378 - val_mae: 2.0748\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 2.5215 - mae: 1.4410 - val_loss: 0.9472 - val_mae: 0.7938\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.5327 - mae: 0.9965 - val_loss: 0.6314 - val_mae: 0.6476\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0722 - mae: 0.9170 - val_loss: 0.5990 - val_mae: 0.6134\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0664 - mae: 0.8725 - val_loss: 0.5794 - val_mae: 0.5990\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8952 - mae: 0.8306 - val_loss: 0.6214 - val_mae: 0.6184\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7473 - mae: 0.7636 - val_loss: 0.6490 - val_mae: 0.6300\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7131 - mae: 0.7601 - val_loss: 0.6030 - val_mae: 0.6084\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7395 - mae: 0.7329 - val_loss: 0.6819 - val_mae: 0.6472\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5988 - mae: 0.7074 - val_loss: 0.5651 - val_mae: 0.5851\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6733 - mae: 0.6951 - val_loss: 0.5526 - val_mae: 0.5790\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5808 - mae: 0.6775 - val_loss: 0.5370 - val_mae: 0.5705\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4796 - mae: 0.6305 - val_loss: 0.5083 - val_mae: 0.5600\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4904 - mae: 0.6300 - val_loss: 0.6190 - val_mae: 0.6204\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4672 - mae: 0.6104 - val_loss: 0.4882 - val_mae: 0.5577\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5148 - mae: 0.6207 - val_loss: 0.5442 - val_mae: 0.5899\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4294 - mae: 0.5921 - val_loss: 0.4917 - val_mae: 0.5621\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4131 - mae: 0.5924 - val_loss: 0.4624 - val_mae: 0.5424\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4464 - mae: 0.5580 - val_loss: 0.4864 - val_mae: 0.5489\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3998 - mae: 0.5587 - val_loss: 0.5363 - val_mae: 0.5754\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4116 - mae: 0.5833 - val_loss: 0.4696 - val_mae: 0.5445\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3964 - mae: 0.5541 - val_loss: 0.4885 - val_mae: 0.5556\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3489 - mae: 0.5321 - val_loss: 0.4723 - val_mae: 0.5465\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3587 - mae: 0.5292 - val_loss: 0.4577 - val_mae: 0.5423\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3512 - mae: 0.5108 - val_loss: 0.4792 - val_mae: 0.5501\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3088 - mae: 0.4997 - val_loss: 0.4460 - val_mae: 0.5301\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3400 - mae: 0.4926 - val_loss: 0.5141 - val_mae: 0.5663\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3517 - mae: 0.5076 - val_loss: 0.4842 - val_mae: 0.5516\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3367 - mae: 0.5141 - val_loss: 0.4601 - val_mae: 0.5477\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3202 - mae: 0.4737 - val_loss: 0.4971 - val_mae: 0.5594\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3157 - mae: 0.4758 - val_loss: 0.4659 - val_mae: 0.5488\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3049 - mae: 0.4625 - val_loss: 0.4559 - val_mae: 0.5458\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2735 - mae: 0.4708 - val_loss: 0.4889 - val_mae: 0.5486\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2561 - mae: 0.4525 - val_loss: 0.4644 - val_mae: 0.5427\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2797 - mae: 0.4593 - val_loss: 0.4928 - val_mae: 0.5511\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2770 - mae: 0.4610 - val_loss: 0.4847 - val_mae: 0.5450\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2441 - mae: 0.4456 - val_loss: 0.4386 - val_mae: 0.5255\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2535 - mae: 0.4285 - val_loss: 0.4525 - val_mae: 0.5299\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2414 - mae: 0.4237 - val_loss: 0.5182 - val_mae: 0.5666\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2630 - mae: 0.4522 - val_loss: 0.4389 - val_mae: 0.5293\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2228 - mae: 0.4167 - val_loss: 0.4512 - val_mae: 0.5349\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2235 - mae: 0.3979 - val_loss: 0.4752 - val_mae: 0.5424\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2537 - mae: 0.4155 - val_loss: 0.5178 - val_mae: 0.5887\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3566 - mae: 0.4819 - val_loss: 0.4550 - val_mae: 0.5323\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2658 - mae: 0.4400 - val_loss: 0.4370 - val_mae: 0.5194\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2100 - mae: 0.4048 - val_loss: 0.4647 - val_mae: 0.5451\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2284 - mae: 0.4084 - val_loss: 0.4876 - val_mae: 0.5574\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2151 - mae: 0.4057 - val_loss: 0.4486 - val_mae: 0.5364\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2343 - mae: 0.4122 - val_loss: 0.4444 - val_mae: 0.5357\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2119 - mae: 0.3927 - val_loss: 0.4402 - val_mae: 0.5338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.4203 - mae: 2.0482 - val_loss: 4.5726 - val_mae: 1.8788\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.4727 - mae: 1.0353 - val_loss: 1.8727 - val_mae: 1.0668\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1273 - mae: 0.8952 - val_loss: 1.1222 - val_mae: 0.8373\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0330 - mae: 0.8628 - val_loss: 0.6987 - val_mae: 0.6693\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1019 - mae: 0.8405 - val_loss: 0.5873 - val_mae: 0.6152\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7970 - mae: 0.7498 - val_loss: 0.5456 - val_mae: 0.5960\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8240 - mae: 0.7487 - val_loss: 0.5789 - val_mae: 0.5907\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6381 - mae: 0.7004 - val_loss: 0.6713 - val_mae: 0.6385\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6704 - mae: 0.6650 - val_loss: 0.6175 - val_mae: 0.6112\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7249 - mae: 0.6864 - val_loss: 0.5573 - val_mae: 0.5764\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5782 - mae: 0.6576 - val_loss: 0.5328 - val_mae: 0.5828\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5652 - mae: 0.6223 - val_loss: 0.5407 - val_mae: 0.5749\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5497 - mae: 0.6397 - val_loss: 0.5067 - val_mae: 0.5621\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5082 - mae: 0.6512 - val_loss: 0.5091 - val_mae: 0.5583\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5090 - mae: 0.6260 - val_loss: 0.5019 - val_mae: 0.5578\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4494 - mae: 0.6020 - val_loss: 0.5032 - val_mae: 0.5556\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4651 - mae: 0.5944 - val_loss: 0.5633 - val_mae: 0.5887\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5381 - mae: 0.5849 - val_loss: 0.5111 - val_mae: 0.5578\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4424 - mae: 0.5712 - val_loss: 0.4899 - val_mae: 0.5473\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4066 - mae: 0.5490 - val_loss: 0.5266 - val_mae: 0.5734\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4390 - mae: 0.5504 - val_loss: 0.5085 - val_mae: 0.5593\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3928 - mae: 0.5475 - val_loss: 0.4697 - val_mae: 0.5391\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3305 - mae: 0.5010 - val_loss: 0.4757 - val_mae: 0.5389\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3266 - mae: 0.5180 - val_loss: 0.5399 - val_mae: 0.5790\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3922 - mae: 0.5227 - val_loss: 0.5008 - val_mae: 0.5553\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3567 - mae: 0.5150 - val_loss: 0.4782 - val_mae: 0.5472\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2825 - mae: 0.4888 - val_loss: 0.4976 - val_mae: 0.5572\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3407 - mae: 0.4988 - val_loss: 0.4747 - val_mae: 0.5439\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3093 - mae: 0.4904 - val_loss: 0.5131 - val_mae: 0.5623\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2808 - mae: 0.4775 - val_loss: 0.5200 - val_mae: 0.5731\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2843 - mae: 0.4553 - val_loss: 0.5015 - val_mae: 0.5604\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2803 - mae: 0.4732 - val_loss: 0.4633 - val_mae: 0.5384\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3046 - mae: 0.4816 - val_loss: 0.5062 - val_mae: 0.5624\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3220 - mae: 0.4834 - val_loss: 0.4892 - val_mae: 0.5483\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3611 - mae: 0.4746 - val_loss: 0.5028 - val_mae: 0.5583\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3209 - mae: 0.4617 - val_loss: 0.4670 - val_mae: 0.5384\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2819 - mae: 0.4537 - val_loss: 0.4677 - val_mae: 0.5430\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2936 - mae: 0.4516 - val_loss: 0.4643 - val_mae: 0.5353\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2754 - mae: 0.4509 - val_loss: 0.4967 - val_mae: 0.5585\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2611 - mae: 0.4366 - val_loss: 0.4947 - val_mae: 0.5559\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2672 - mae: 0.4426 - val_loss: 0.5085 - val_mae: 0.5620\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2716 - mae: 0.4292 - val_loss: 0.5010 - val_mae: 0.5519\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3142 - mae: 0.4535 - val_loss: 0.5612 - val_mae: 0.5933\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2724 - mae: 0.4338 - val_loss: 0.4698 - val_mae: 0.5351\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2158 - mae: 0.4310 - val_loss: 0.4784 - val_mae: 0.5487\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2312 - mae: 0.4206 - val_loss: 0.5008 - val_mae: 0.5604\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2490 - mae: 0.4285 - val_loss: 0.5261 - val_mae: 0.5744\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2763 - mae: 0.4275 - val_loss: 0.4803 - val_mae: 0.5452\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2545 - mae: 0.4202 - val_loss: 0.4788 - val_mae: 0.5431\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2238 - mae: 0.4043 - val_loss: 0.4606 - val_mae: 0.5291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 13.1576 - mae: 3.5548 - val_loss: 5.5504 - val_mae: 2.1777\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1983 - mae: 1.2531 - val_loss: 1.4235 - val_mae: 0.9330\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2315 - mae: 0.9421 - val_loss: 0.9446 - val_mae: 0.7737\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2689 - mae: 0.8809 - val_loss: 0.6138 - val_mae: 0.6265\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9064 - mae: 0.7875 - val_loss: 0.5340 - val_mae: 0.5734\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8526 - mae: 0.7831 - val_loss: 0.5118 - val_mae: 0.5464\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8365 - mae: 0.7587 - val_loss: 0.5633 - val_mae: 0.5773\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7200 - mae: 0.7154 - val_loss: 0.5773 - val_mae: 0.5802\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6920 - mae: 0.7001 - val_loss: 0.5220 - val_mae: 0.5542\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6139 - mae: 0.6778 - val_loss: 0.4961 - val_mae: 0.5439\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6622 - mae: 0.6811 - val_loss: 0.4767 - val_mae: 0.5400\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5515 - mae: 0.6687 - val_loss: 0.4685 - val_mae: 0.5310\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5150 - mae: 0.6231 - val_loss: 0.4975 - val_mae: 0.5408\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4955 - mae: 0.6137 - val_loss: 0.4780 - val_mae: 0.5363\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5299 - mae: 0.6152 - val_loss: 0.4730 - val_mae: 0.5271\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5253 - mae: 0.5963 - val_loss: 0.4766 - val_mae: 0.5302\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5226 - mae: 0.5959 - val_loss: 0.4570 - val_mae: 0.5250\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4927 - mae: 0.5844 - val_loss: 0.5455 - val_mae: 0.5628\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4233 - mae: 0.5793 - val_loss: 0.4977 - val_mae: 0.5407\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3778 - mae: 0.5605 - val_loss: 0.5117 - val_mae: 0.5541\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4291 - mae: 0.5633 - val_loss: 0.5110 - val_mae: 0.5538\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4606 - mae: 0.5464 - val_loss: 0.5278 - val_mae: 0.5591\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3918 - mae: 0.5352 - val_loss: 0.5007 - val_mae: 0.5437\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3991 - mae: 0.5321 - val_loss: 0.5336 - val_mae: 0.5674\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3690 - mae: 0.5447 - val_loss: 0.4704 - val_mae: 0.5266\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3544 - mae: 0.4982 - val_loss: 0.4875 - val_mae: 0.5378\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3324 - mae: 0.4928 - val_loss: 0.4877 - val_mae: 0.5414\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3137 - mae: 0.4966 - val_loss: 0.4722 - val_mae: 0.5354\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3372 - mae: 0.4853 - val_loss: 0.4975 - val_mae: 0.5420\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2868 - mae: 0.4831 - val_loss: 0.5098 - val_mae: 0.5541\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3380 - mae: 0.4790 - val_loss: 0.6122 - val_mae: 0.6051\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4116 - mae: 0.5508 - val_loss: 0.4989 - val_mae: 0.5447\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3322 - mae: 0.5012 - val_loss: 0.4834 - val_mae: 0.5405\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2672 - mae: 0.4760 - val_loss: 0.5020 - val_mae: 0.5554\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3345 - mae: 0.4848 - val_loss: 0.5138 - val_mae: 0.5547\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3434 - mae: 0.5043 - val_loss: 0.4941 - val_mae: 0.5362\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3059 - mae: 0.4782 - val_loss: 0.4844 - val_mae: 0.5423\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2554 - mae: 0.4486 - val_loss: 0.4881 - val_mae: 0.5458\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2670 - mae: 0.4575 - val_loss: 0.4833 - val_mae: 0.5371\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3110 - mae: 0.4557 - val_loss: 0.4984 - val_mae: 0.5437\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2581 - mae: 0.4446 - val_loss: 0.5072 - val_mae: 0.5482\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2597 - mae: 0.4420 - val_loss: 0.5132 - val_mae: 0.5537\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2310 - mae: 0.4313 - val_loss: 0.4872 - val_mae: 0.5333\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2746 - mae: 0.4406 - val_loss: 0.5188 - val_mae: 0.5492\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2474 - mae: 0.4297 - val_loss: 0.5120 - val_mae: 0.5595\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2812 - mae: 0.4331 - val_loss: 0.4936 - val_mae: 0.5459\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2560 - mae: 0.4295 - val_loss: 0.4842 - val_mae: 0.5355\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2538 - mae: 0.4379 - val_loss: 0.4678 - val_mae: 0.5316\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2280 - mae: 0.4140 - val_loss: 0.4643 - val_mae: 0.5266\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2526 - mae: 0.4038 - val_loss: 0.5024 - val_mae: 0.5498\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 11.8501 - mae: 3.3031 - val_loss: 5.2923 - val_mae: 2.1421\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9189 - mae: 1.2344 - val_loss: 1.2024 - val_mae: 0.9079\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3108 - mae: 0.9528 - val_loss: 0.7291 - val_mae: 0.6849\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9654 - mae: 0.8122 - val_loss: 0.5951 - val_mae: 0.6219\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8518 - mae: 0.7644 - val_loss: 0.7262 - val_mae: 0.6696\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7940 - mae: 0.8007 - val_loss: 0.6699 - val_mae: 0.6381\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9070 - mae: 0.7663 - val_loss: 0.5192 - val_mae: 0.5655\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7198 - mae: 0.7011 - val_loss: 0.6565 - val_mae: 0.6248\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6708 - mae: 0.7237 - val_loss: 0.6274 - val_mae: 0.6146\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6950 - mae: 0.6781 - val_loss: 0.6116 - val_mae: 0.5981\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7198 - mae: 0.6504 - val_loss: 0.5983 - val_mae: 0.6034\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5316 - mae: 0.6582 - val_loss: 0.6181 - val_mae: 0.6175\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5661 - mae: 0.6987 - val_loss: 0.5844 - val_mae: 0.5815\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5881 - mae: 0.6631 - val_loss: 0.5801 - val_mae: 0.5838\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5360 - mae: 0.6395 - val_loss: 0.5783 - val_mae: 0.5868\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5656 - mae: 0.6390 - val_loss: 0.5072 - val_mae: 0.5438\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5344 - mae: 0.5874 - val_loss: 0.5621 - val_mae: 0.5753\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4342 - mae: 0.6049 - val_loss: 0.5050 - val_mae: 0.5509\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4523 - mae: 0.5653 - val_loss: 0.6084 - val_mae: 0.6091\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4455 - mae: 0.5613 - val_loss: 0.5629 - val_mae: 0.5719\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3898 - mae: 0.5714 - val_loss: 0.5451 - val_mae: 0.5669\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4503 - mae: 0.6175 - val_loss: 0.4876 - val_mae: 0.5331\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3952 - mae: 0.5481 - val_loss: 0.4714 - val_mae: 0.5313\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3402 - mae: 0.5367 - val_loss: 0.4481 - val_mae: 0.5207\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3533 - mae: 0.5341 - val_loss: 0.4759 - val_mae: 0.5263\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3824 - mae: 0.5249 - val_loss: 0.4245 - val_mae: 0.5008\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3369 - mae: 0.4982 - val_loss: 0.4837 - val_mae: 0.5472\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3303 - mae: 0.4942 - val_loss: 0.4575 - val_mae: 0.5272\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4959 - mae: 0.6178 - val_loss: 0.4902 - val_mae: 0.5351\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3524 - mae: 0.5179 - val_loss: 0.4674 - val_mae: 0.5289\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4166 - mae: 0.5335 - val_loss: 0.5197 - val_mae: 0.5347\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3513 - mae: 0.5206 - val_loss: 0.4803 - val_mae: 0.5306\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3290 - mae: 0.4890 - val_loss: 0.4542 - val_mae: 0.5210\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3100 - mae: 0.4879 - val_loss: 0.4534 - val_mae: 0.5268\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3856 - mae: 0.5501 - val_loss: 0.5048 - val_mae: 0.5540\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3081 - mae: 0.4997 - val_loss: 0.4773 - val_mae: 0.5343\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3185 - mae: 0.4825 - val_loss: 0.4842 - val_mae: 0.5368\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2952 - mae: 0.4844 - val_loss: 0.4250 - val_mae: 0.5053\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3048 - mae: 0.4703 - val_loss: 0.4092 - val_mae: 0.4990\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2858 - mae: 0.4679 - val_loss: 0.4732 - val_mae: 0.5386\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2897 - mae: 0.4562 - val_loss: 0.4745 - val_mae: 0.5310\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2862 - mae: 0.4795 - val_loss: 0.4266 - val_mae: 0.5069\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3094 - mae: 0.4846 - val_loss: 0.4168 - val_mae: 0.5058\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2643 - mae: 0.4540 - val_loss: 0.4897 - val_mae: 0.5393\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2977 - mae: 0.4886 - val_loss: 0.4660 - val_mae: 0.5194\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2381 - mae: 0.4482 - val_loss: 0.4593 - val_mae: 0.5220\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2491 - mae: 0.4406 - val_loss: 0.4785 - val_mae: 0.5288\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2863 - mae: 0.4625 - val_loss: 0.5083 - val_mae: 0.5475\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2329 - mae: 0.4414 - val_loss: 0.5074 - val_mae: 0.5521\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2521 - mae: 0.4433 - val_loss: 0.4822 - val_mae: 0.5354\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 6.7655 - mae: 2.4869 - val_loss: 5.1090 - val_mae: 2.1198\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6937 - mae: 1.0785 - val_loss: 1.9988 - val_mae: 1.2358\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2704 - mae: 0.9125 - val_loss: 1.1979 - val_mae: 0.9286\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0003 - mae: 0.8729 - val_loss: 0.7703 - val_mae: 0.7185\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9812 - mae: 0.8135 - val_loss: 0.7591 - val_mae: 0.7100\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0226 - mae: 0.7993 - val_loss: 0.5932 - val_mae: 0.5985\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8739 - mae: 0.7756 - val_loss: 0.6014 - val_mae: 0.5986\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7494 - mae: 0.7401 - val_loss: 0.5739 - val_mae: 0.5869\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.7433 - mae: 0.6910 - val_loss: 0.5795 - val_mae: 0.5905\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6428 - mae: 0.6846 - val_loss: 0.5410 - val_mae: 0.5780\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5981 - mae: 0.6588 - val_loss: 0.5254 - val_mae: 0.5610\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5787 - mae: 0.6654 - val_loss: 0.5156 - val_mae: 0.5571\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6503 - mae: 0.6649 - val_loss: 0.5169 - val_mae: 0.5625\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4999 - mae: 0.6217 - val_loss: 0.5384 - val_mae: 0.5765\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5275 - mae: 0.6203 - val_loss: 0.4892 - val_mae: 0.5441\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5050 - mae: 0.5939 - val_loss: 0.4394 - val_mae: 0.5130\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4961 - mae: 0.5714 - val_loss: 0.5554 - val_mae: 0.5811\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4856 - mae: 0.6102 - val_loss: 0.4979 - val_mae: 0.5545\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4333 - mae: 0.5782 - val_loss: 0.5197 - val_mae: 0.5621\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4179 - mae: 0.5527 - val_loss: 0.5606 - val_mae: 0.5851\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4634 - mae: 0.5812 - val_loss: 0.5100 - val_mae: 0.5552\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3915 - mae: 0.5631 - val_loss: 0.5507 - val_mae: 0.5781\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4223 - mae: 0.5677 - val_loss: 0.4722 - val_mae: 0.5349\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3990 - mae: 0.5464 - val_loss: 0.5197 - val_mae: 0.5602\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4042 - mae: 0.5496 - val_loss: 0.4775 - val_mae: 0.5391\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3620 - mae: 0.5029 - val_loss: 0.5145 - val_mae: 0.5609\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4017 - mae: 0.5189 - val_loss: 0.4700 - val_mae: 0.5294\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3335 - mae: 0.4970 - val_loss: 0.4256 - val_mae: 0.5093\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3536 - mae: 0.5040 - val_loss: 0.4602 - val_mae: 0.5261\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3412 - mae: 0.5163 - val_loss: 0.4865 - val_mae: 0.5484\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3361 - mae: 0.4931 - val_loss: 0.4873 - val_mae: 0.5439\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3266 - mae: 0.4937 - val_loss: 0.4713 - val_mae: 0.5411\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2894 - mae: 0.4735 - val_loss: 0.5199 - val_mae: 0.5598\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3628 - mae: 0.5049 - val_loss: 0.4655 - val_mae: 0.5377\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2907 - mae: 0.4781 - val_loss: 0.4919 - val_mae: 0.5483\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3017 - mae: 0.4926 - val_loss: 0.5024 - val_mae: 0.5519\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3249 - mae: 0.4698 - val_loss: 0.5172 - val_mae: 0.5527\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3713 - mae: 0.4767 - val_loss: 0.5005 - val_mae: 0.5567\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3256 - mae: 0.4755 - val_loss: 0.4925 - val_mae: 0.5449\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3334 - mae: 0.4656 - val_loss: 0.4589 - val_mae: 0.5261\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4873 - mae: 0.5926 - val_loss: 0.5145 - val_mae: 0.5594\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4013 - mae: 0.5326 - val_loss: 0.4602 - val_mae: 0.5278\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3575 - mae: 0.4908 - val_loss: 0.4497 - val_mae: 0.5200\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3378 - mae: 0.4611 - val_loss: 0.4721 - val_mae: 0.5306\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2887 - mae: 0.4625 - val_loss: 0.4965 - val_mae: 0.5440\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2630 - mae: 0.4615 - val_loss: 0.4606 - val_mae: 0.5285\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2987 - mae: 0.4479 - val_loss: 0.4580 - val_mae: 0.5220\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2373 - mae: 0.4234 - val_loss: 0.4627 - val_mae: 0.5291\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2493 - mae: 0.4318 - val_loss: 0.4739 - val_mae: 0.5378\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2344 - mae: 0.4306 - val_loss: 0.4457 - val_mae: 0.5182\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5282 - mae: 0.5477\n",
            "Test MAE for Spelling: 0.5506880879402161\n",
            "Training model for Vocabulary...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 5.4099 - mae: 2.1161 - val_loss: 1.7994 - val_mae: 1.1724\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2549 - mae: 0.9889 - val_loss: 0.5245 - val_mae: 0.5765\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9138 - mae: 0.8739 - val_loss: 0.4998 - val_mae: 0.5660\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7353 - mae: 0.7414 - val_loss: 0.4620 - val_mae: 0.5495\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7078 - mae: 0.6991 - val_loss: 0.4554 - val_mae: 0.5417\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6359 - mae: 0.6847 - val_loss: 0.3771 - val_mae: 0.4830\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5537 - mae: 0.6319 - val_loss: 0.4626 - val_mae: 0.5379\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.5763 - mae: 0.6358 - val_loss: 0.5180 - val_mae: 0.5688\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5261 - mae: 0.6136 - val_loss: 0.3893 - val_mae: 0.4999\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4394 - mae: 0.5770 - val_loss: 0.3336 - val_mae: 0.4569\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4846 - mae: 0.5702 - val_loss: 0.3760 - val_mae: 0.4820\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4934 - mae: 0.5650 - val_loss: 0.4627 - val_mae: 0.5428\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4580 - mae: 0.5654 - val_loss: 0.4006 - val_mae: 0.5036\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4081 - mae: 0.5282 - val_loss: 0.4652 - val_mae: 0.5359\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4227 - mae: 0.5487 - val_loss: 0.5240 - val_mae: 0.5701\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4444 - mae: 0.5437 - val_loss: 0.3957 - val_mae: 0.4903\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3750 - mae: 0.5105 - val_loss: 0.4101 - val_mae: 0.4904\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3179 - mae: 0.4962 - val_loss: 0.3581 - val_mae: 0.4650\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3095 - mae: 0.4818 - val_loss: 0.3516 - val_mae: 0.4556\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2852 - mae: 0.4775 - val_loss: 0.3703 - val_mae: 0.4708\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2752 - mae: 0.4676 - val_loss: 0.4091 - val_mae: 0.4964\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2681 - mae: 0.4755 - val_loss: 0.3918 - val_mae: 0.4841\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3207 - mae: 0.4631 - val_loss: 0.3587 - val_mae: 0.4666\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3491 - mae: 0.4665 - val_loss: 0.4208 - val_mae: 0.4999\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2882 - mae: 0.4456 - val_loss: 0.3739 - val_mae: 0.4736\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2902 - mae: 0.4627 - val_loss: 0.3696 - val_mae: 0.4696\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3147 - mae: 0.4713 - val_loss: 0.3856 - val_mae: 0.4790\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3082 - mae: 0.4429 - val_loss: 0.3873 - val_mae: 0.4826\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2288 - mae: 0.4361 - val_loss: 0.3547 - val_mae: 0.4630\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2497 - mae: 0.4257 - val_loss: 0.3906 - val_mae: 0.4813\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2346 - mae: 0.4292 - val_loss: 0.3587 - val_mae: 0.4669\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2088 - mae: 0.4080 - val_loss: 0.3502 - val_mae: 0.4611\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2261 - mae: 0.4139 - val_loss: 0.3807 - val_mae: 0.4762\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2087 - mae: 0.3918 - val_loss: 0.3848 - val_mae: 0.4838\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2389 - mae: 0.3957 - val_loss: 0.3593 - val_mae: 0.4658\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2003 - mae: 0.3798 - val_loss: 0.3713 - val_mae: 0.4663\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2934 - mae: 0.4189 - val_loss: 0.3649 - val_mae: 0.4657\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1985 - mae: 0.3749 - val_loss: 0.3327 - val_mae: 0.4494\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2066 - mae: 0.3856 - val_loss: 0.3578 - val_mae: 0.4658\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2052 - mae: 0.3731 - val_loss: 0.3723 - val_mae: 0.4740\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2060 - mae: 0.3647 - val_loss: 0.4017 - val_mae: 0.4853\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1693 - mae: 0.3708 - val_loss: 0.3764 - val_mae: 0.4771\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1878 - mae: 0.3643 - val_loss: 0.3297 - val_mae: 0.4503\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1786 - mae: 0.3569 - val_loss: 0.3763 - val_mae: 0.4823\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1611 - mae: 0.3636 - val_loss: 0.3404 - val_mae: 0.4567\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1746 - mae: 0.3603 - val_loss: 0.3673 - val_mae: 0.4754\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1914 - mae: 0.3530 - val_loss: 0.3818 - val_mae: 0.4861\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1486 - mae: 0.3419 - val_loss: 0.3699 - val_mae: 0.4719\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1912 - mae: 0.3417 - val_loss: 0.3654 - val_mae: 0.4710\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1544 - mae: 0.3464 - val_loss: 0.3908 - val_mae: 0.4897\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 4.1155 - mae: 1.4720 - val_loss: 1.3059 - val_mae: 0.8898\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3101 - mae: 0.8721 - val_loss: 0.6047 - val_mae: 0.6016\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0444 - mae: 0.8095 - val_loss: 0.5671 - val_mae: 0.6034\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7538 - mae: 0.7408 - val_loss: 0.5071 - val_mae: 0.5787\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6777 - mae: 0.7075 - val_loss: 0.4695 - val_mae: 0.5453\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5996 - mae: 0.6561 - val_loss: 0.4871 - val_mae: 0.5583\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6746 - mae: 0.6221 - val_loss: 0.4946 - val_mae: 0.5659\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5297 - mae: 0.6350 - val_loss: 0.4459 - val_mae: 0.5350\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4819 - mae: 0.5807 - val_loss: 0.4739 - val_mae: 0.5467\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4602 - mae: 0.5648 - val_loss: 0.4994 - val_mae: 0.5467\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5224 - mae: 0.5787 - val_loss: 0.4448 - val_mae: 0.5261\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3635 - mae: 0.5250 - val_loss: 0.4027 - val_mae: 0.5041\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4567 - mae: 0.5475 - val_loss: 0.3946 - val_mae: 0.4981\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3921 - mae: 0.5002 - val_loss: 0.4247 - val_mae: 0.4990\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3624 - mae: 0.5184 - val_loss: 0.3912 - val_mae: 0.4898\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3629 - mae: 0.5123 - val_loss: 0.3586 - val_mae: 0.4695\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3938 - mae: 0.4968 - val_loss: 0.4587 - val_mae: 0.5414\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3709 - mae: 0.5188 - val_loss: 0.4374 - val_mae: 0.5140\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3552 - mae: 0.4901 - val_loss: 0.3868 - val_mae: 0.4918\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3407 - mae: 0.4763 - val_loss: 0.4012 - val_mae: 0.4983\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3492 - mae: 0.4831 - val_loss: 0.3946 - val_mae: 0.4960\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2859 - mae: 0.4671 - val_loss: 0.4001 - val_mae: 0.4869\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3020 - mae: 0.4588 - val_loss: 0.3491 - val_mae: 0.4678\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2937 - mae: 0.4573 - val_loss: 0.3982 - val_mae: 0.4950\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3786 - mae: 0.4879 - val_loss: 0.4058 - val_mae: 0.4919\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2713 - mae: 0.4511 - val_loss: 0.3696 - val_mae: 0.4799\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2384 - mae: 0.4337 - val_loss: 0.4015 - val_mae: 0.4972\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2244 - mae: 0.4070 - val_loss: 0.3632 - val_mae: 0.4680\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2216 - mae: 0.4049 - val_loss: 0.3702 - val_mae: 0.4692\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2496 - mae: 0.4054 - val_loss: 0.3941 - val_mae: 0.4867\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2565 - mae: 0.4107 - val_loss: 0.4026 - val_mae: 0.5009\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2489 - mae: 0.4231 - val_loss: 0.3601 - val_mae: 0.4651\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2415 - mae: 0.4150 - val_loss: 0.3578 - val_mae: 0.4637\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2265 - mae: 0.4034 - val_loss: 0.3451 - val_mae: 0.4503\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2183 - mae: 0.3880 - val_loss: 0.3861 - val_mae: 0.4887\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2185 - mae: 0.3979 - val_loss: 0.3773 - val_mae: 0.4805\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2449 - mae: 0.3998 - val_loss: 0.3837 - val_mae: 0.4809\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2173 - mae: 0.3913 - val_loss: 0.3908 - val_mae: 0.4825\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1767 - mae: 0.3771 - val_loss: 0.3793 - val_mae: 0.4744\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2267 - mae: 0.3765 - val_loss: 0.3775 - val_mae: 0.4836\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2001 - mae: 0.3801 - val_loss: 0.3739 - val_mae: 0.4819\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2058 - mae: 0.3693 - val_loss: 0.3732 - val_mae: 0.4766\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1918 - mae: 0.3745 - val_loss: 0.3803 - val_mae: 0.4804\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1971 - mae: 0.3539 - val_loss: 0.3834 - val_mae: 0.4825\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1880 - mae: 0.3775 - val_loss: 0.3874 - val_mae: 0.4832\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2151 - mae: 0.3656 - val_loss: 0.3660 - val_mae: 0.4695\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2041 - mae: 0.3607 - val_loss: 0.3716 - val_mae: 0.4766\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1869 - mae: 0.3693 - val_loss: 0.3875 - val_mae: 0.4858\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1631 - mae: 0.3503 - val_loss: 0.3662 - val_mae: 0.4706\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1686 - mae: 0.3317 - val_loss: 0.4205 - val_mae: 0.5033\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 3.2549 - mae: 1.3460 - val_loss: 4.5939 - val_mae: 2.0086\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.2332 - mae: 0.8280 - val_loss: 2.5991 - val_mae: 1.4680\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8295 - mae: 0.7570 - val_loss: 1.4830 - val_mae: 1.0663\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8193 - mae: 0.7507 - val_loss: 0.9142 - val_mae: 0.8083\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6951 - mae: 0.6950 - val_loss: 0.5989 - val_mae: 0.6280\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6414 - mae: 0.6696 - val_loss: 0.4857 - val_mae: 0.5522\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6295 - mae: 0.6520 - val_loss: 0.5912 - val_mae: 0.6231\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5334 - mae: 0.6556 - val_loss: 0.4535 - val_mae: 0.5365\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4943 - mae: 0.6105 - val_loss: 0.4375 - val_mae: 0.5309\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5710 - mae: 0.6072 - val_loss: 0.4472 - val_mae: 0.5312\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4927 - mae: 0.5639 - val_loss: 0.4159 - val_mae: 0.5115\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5143 - mae: 0.5519 - val_loss: 0.5108 - val_mae: 0.5734\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4665 - mae: 0.5596 - val_loss: 0.4779 - val_mae: 0.5564\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4071 - mae: 0.5397 - val_loss: 0.4002 - val_mae: 0.4965\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3835 - mae: 0.5191 - val_loss: 0.4410 - val_mae: 0.5259\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4604 - mae: 0.5296 - val_loss: 0.4239 - val_mae: 0.5146\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4507 - mae: 0.5239 - val_loss: 0.4321 - val_mae: 0.5239\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3931 - mae: 0.5241 - val_loss: 0.3597 - val_mae: 0.4736\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3702 - mae: 0.4896 - val_loss: 0.4047 - val_mae: 0.5002\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3241 - mae: 0.4934 - val_loss: 0.4050 - val_mae: 0.4973\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3013 - mae: 0.4868 - val_loss: 0.3922 - val_mae: 0.4899\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3313 - mae: 0.4947 - val_loss: 0.3498 - val_mae: 0.4609\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3165 - mae: 0.4700 - val_loss: 0.3657 - val_mae: 0.4760\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2795 - mae: 0.4710 - val_loss: 0.3470 - val_mae: 0.4638\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2714 - mae: 0.4397 - val_loss: 0.3568 - val_mae: 0.4661\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3510 - mae: 0.4669 - val_loss: 0.3547 - val_mae: 0.4671\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2673 - mae: 0.4562 - val_loss: 0.3616 - val_mae: 0.4747\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4276 - mae: 0.5526 - val_loss: 0.3877 - val_mae: 0.4876\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3032 - mae: 0.4595 - val_loss: 0.4075 - val_mae: 0.4916\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3375 - mae: 0.4718 - val_loss: 0.3733 - val_mae: 0.4786\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2892 - mae: 0.4457 - val_loss: 0.3545 - val_mae: 0.4627\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2934 - mae: 0.4420 - val_loss: 0.3892 - val_mae: 0.4835\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2548 - mae: 0.4347 - val_loss: 0.3618 - val_mae: 0.4672\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2326 - mae: 0.4179 - val_loss: 0.3531 - val_mae: 0.4628\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2431 - mae: 0.4139 - val_loss: 0.3471 - val_mae: 0.4596\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2494 - mae: 0.4180 - val_loss: 0.3789 - val_mae: 0.4773\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2418 - mae: 0.4158 - val_loss: 0.3566 - val_mae: 0.4718\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2341 - mae: 0.4152 - val_loss: 0.3512 - val_mae: 0.4637\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2292 - mae: 0.4004 - val_loss: 0.3403 - val_mae: 0.4572\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2696 - mae: 0.4041 - val_loss: 0.3245 - val_mae: 0.4472\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2269 - mae: 0.3906 - val_loss: 0.3627 - val_mae: 0.4696\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2324 - mae: 0.3951 - val_loss: 0.3485 - val_mae: 0.4577\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2071 - mae: 0.3904 - val_loss: 0.3509 - val_mae: 0.4610\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2484 - mae: 0.3913 - val_loss: 0.3331 - val_mae: 0.4518\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2279 - mae: 0.3854 - val_loss: 0.3499 - val_mae: 0.4603\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2289 - mae: 0.3879 - val_loss: 0.3454 - val_mae: 0.4629\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1936 - mae: 0.3785 - val_loss: 0.3618 - val_mae: 0.4695\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2152 - mae: 0.3776 - val_loss: 0.3668 - val_mae: 0.4774\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2510 - mae: 0.4096 - val_loss: 0.3886 - val_mae: 0.4919\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2175 - mae: 0.3793 - val_loss: 0.3490 - val_mae: 0.4617\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 10.1798 - mae: 2.9230 - val_loss: 5.4914 - val_mae: 2.1948\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1970 - mae: 1.2354 - val_loss: 2.7532 - val_mae: 1.4474\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4338 - mae: 0.8668 - val_loss: 1.1629 - val_mae: 0.8151\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2060 - mae: 0.8040 - val_loss: 0.4746 - val_mae: 0.5130\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0235 - mae: 0.7108 - val_loss: 0.3212 - val_mae: 0.4416\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7948 - mae: 0.6911 - val_loss: 0.4066 - val_mae: 0.4940\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6495 - mae: 0.6487 - val_loss: 0.3828 - val_mae: 0.4973\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6496 - mae: 0.6564 - val_loss: 0.3649 - val_mae: 0.4796\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6947 - mae: 0.6099 - val_loss: 0.5713 - val_mae: 0.5958\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5751 - mae: 0.6173 - val_loss: 0.4084 - val_mae: 0.5088\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5514 - mae: 0.6107 - val_loss: 0.4486 - val_mae: 0.5330\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5111 - mae: 0.5844 - val_loss: 0.4458 - val_mae: 0.5370\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5194 - mae: 0.5775 - val_loss: 0.4767 - val_mae: 0.5525\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4441 - mae: 0.5625 - val_loss: 0.4466 - val_mae: 0.5276\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5120 - mae: 0.5655 - val_loss: 0.4607 - val_mae: 0.5270\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4171 - mae: 0.5437 - val_loss: 0.3849 - val_mae: 0.4810\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4105 - mae: 0.5333 - val_loss: 0.3862 - val_mae: 0.4929\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3915 - mae: 0.5174 - val_loss: 0.3440 - val_mae: 0.4745\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4640 - mae: 0.5156 - val_loss: 0.3609 - val_mae: 0.4820\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3818 - mae: 0.5129 - val_loss: 0.3613 - val_mae: 0.4719\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4230 - mae: 0.5158 - val_loss: 0.3483 - val_mae: 0.4697\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4062 - mae: 0.5221 - val_loss: 0.3631 - val_mae: 0.4804\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3236 - mae: 0.4661 - val_loss: 0.3682 - val_mae: 0.4793\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3033 - mae: 0.4663 - val_loss: 0.3752 - val_mae: 0.4861\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3187 - mae: 0.4674 - val_loss: 0.3945 - val_mae: 0.5006\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2634 - mae: 0.4456 - val_loss: 0.3473 - val_mae: 0.4678\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3265 - mae: 0.4547 - val_loss: 0.3364 - val_mae: 0.4594\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2884 - mae: 0.4571 - val_loss: 0.3224 - val_mae: 0.4487\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2659 - mae: 0.4230 - val_loss: 0.3271 - val_mae: 0.4562\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2758 - mae: 0.4323 - val_loss: 0.3375 - val_mae: 0.4636\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2687 - mae: 0.4216 - val_loss: 0.4148 - val_mae: 0.4998\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2940 - mae: 0.4488 - val_loss: 0.3751 - val_mae: 0.4829\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2652 - mae: 0.4194 - val_loss: 0.3301 - val_mae: 0.4503\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2319 - mae: 0.4011 - val_loss: 0.3869 - val_mae: 0.4845\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2339 - mae: 0.4206 - val_loss: 0.3312 - val_mae: 0.4487\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2937 - mae: 0.4282 - val_loss: 0.3690 - val_mae: 0.4831\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2500 - mae: 0.4245 - val_loss: 0.3378 - val_mae: 0.4642\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2582 - mae: 0.4135 - val_loss: 0.3443 - val_mae: 0.4626\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2397 - mae: 0.4105 - val_loss: 0.4485 - val_mae: 0.5188\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2514 - mae: 0.4145 - val_loss: 0.3466 - val_mae: 0.4613\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2562 - mae: 0.4205 - val_loss: 0.3815 - val_mae: 0.4817\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3142 - mae: 0.4490 - val_loss: 0.4013 - val_mae: 0.4911\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3412 - mae: 0.4526 - val_loss: 0.3639 - val_mae: 0.4735\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2660 - mae: 0.4117 - val_loss: 0.3803 - val_mae: 0.4808\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2335 - mae: 0.4066 - val_loss: 0.3931 - val_mae: 0.4900\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2295 - mae: 0.3944 - val_loss: 0.3480 - val_mae: 0.4582\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2514 - mae: 0.4130 - val_loss: 0.3594 - val_mae: 0.4730\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2164 - mae: 0.3894 - val_loss: 0.3289 - val_mae: 0.4483\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1939 - mae: 0.3646 - val_loss: 0.3713 - val_mae: 0.4703\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1936 - mae: 0.3777 - val_loss: 0.4106 - val_mae: 0.4943\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 3.8047 - mae: 1.6950 - val_loss: 2.6552 - val_mae: 1.4616\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2197 - mae: 0.8806 - val_loss: 0.8438 - val_mae: 0.7120\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9118 - mae: 0.7836 - val_loss: 0.5263 - val_mae: 0.5802\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.7486 - mae: 0.6905 - val_loss: 0.4844 - val_mae: 0.5682\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6244 - mae: 0.6894 - val_loss: 0.4805 - val_mae: 0.5589\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6551 - mae: 0.6877 - val_loss: 0.4982 - val_mae: 0.5720\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6659 - mae: 0.6346 - val_loss: 0.5230 - val_mae: 0.5876\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5128 - mae: 0.6210 - val_loss: 0.5969 - val_mae: 0.6154\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4840 - mae: 0.6268 - val_loss: 0.5985 - val_mae: 0.6157\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4602 - mae: 0.6125 - val_loss: 0.5014 - val_mae: 0.5657\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5014 - mae: 0.5780 - val_loss: 0.4079 - val_mae: 0.5058\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4892 - mae: 0.5552 - val_loss: 0.4096 - val_mae: 0.5114\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4282 - mae: 0.5273 - val_loss: 0.4639 - val_mae: 0.5480\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4652 - mae: 0.5491 - val_loss: 0.4507 - val_mae: 0.5303\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3921 - mae: 0.5444 - val_loss: 0.4526 - val_mae: 0.5459\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3451 - mae: 0.5250 - val_loss: 0.4498 - val_mae: 0.5390\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3917 - mae: 0.5154 - val_loss: 0.3959 - val_mae: 0.5035\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3429 - mae: 0.5124 - val_loss: 0.3951 - val_mae: 0.4977\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4066 - mae: 0.5110 - val_loss: 0.4174 - val_mae: 0.5187\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3319 - mae: 0.4797 - val_loss: 0.4488 - val_mae: 0.5328\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3403 - mae: 0.4723 - val_loss: 0.4079 - val_mae: 0.4996\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3293 - mae: 0.4804 - val_loss: 0.3864 - val_mae: 0.4840\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2884 - mae: 0.4853 - val_loss: 0.4311 - val_mae: 0.5165\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3801 - mae: 0.4816 - val_loss: 0.3886 - val_mae: 0.4906\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3625 - mae: 0.4776 - val_loss: 0.3720 - val_mae: 0.4831\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3064 - mae: 0.4745 - val_loss: 0.3922 - val_mae: 0.4903\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2982 - mae: 0.4574 - val_loss: 0.3951 - val_mae: 0.4928\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3495 - mae: 0.4712 - val_loss: 0.4197 - val_mae: 0.5110\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3118 - mae: 0.4640 - val_loss: 0.3465 - val_mae: 0.4663\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2638 - mae: 0.4198 - val_loss: 0.3543 - val_mae: 0.4642\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2812 - mae: 0.4412 - val_loss: 0.3871 - val_mae: 0.4934\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2628 - mae: 0.4372 - val_loss: 0.3710 - val_mae: 0.4734\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2285 - mae: 0.4186 - val_loss: 0.4002 - val_mae: 0.4948\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2349 - mae: 0.4296 - val_loss: 0.3826 - val_mae: 0.4838\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2251 - mae: 0.4044 - val_loss: 0.3836 - val_mae: 0.4854\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2658 - mae: 0.4382 - val_loss: 0.4529 - val_mae: 0.5259\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2222 - mae: 0.4070 - val_loss: 0.3717 - val_mae: 0.4716\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2736 - mae: 0.4137 - val_loss: 0.3597 - val_mae: 0.4661\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2407 - mae: 0.4095 - val_loss: 0.3466 - val_mae: 0.4607\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2413 - mae: 0.4041 - val_loss: 0.3860 - val_mae: 0.4891\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2048 - mae: 0.3961 - val_loss: 0.3577 - val_mae: 0.4656\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2014 - mae: 0.3882 - val_loss: 0.3842 - val_mae: 0.4837\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1860 - mae: 0.3789 - val_loss: 0.3744 - val_mae: 0.4738\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2055 - mae: 0.3861 - val_loss: 0.3574 - val_mae: 0.4572\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1895 - mae: 0.3759 - val_loss: 0.3974 - val_mae: 0.4825\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1911 - mae: 0.3855 - val_loss: 0.3568 - val_mae: 0.4577\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2064 - mae: 0.3870 - val_loss: 0.3913 - val_mae: 0.4865\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2123 - mae: 0.3749 - val_loss: 0.3820 - val_mae: 0.4762\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1923 - mae: 0.3728 - val_loss: 0.3699 - val_mae: 0.4675\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1829 - mae: 0.3536 - val_loss: 0.3709 - val_mae: 0.4650\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3721 - mae: 0.4704\n",
            "Test MAE for Vocabulary: 0.48242101073265076\n",
            "Training model for SentenceStructure...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 7.6881 - mae: 2.3645 - val_loss: 3.5017 - val_mae: 1.7214\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4785 - mae: 1.1309 - val_loss: 1.1128 - val_mae: 0.8698\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3576 - mae: 0.8362 - val_loss: 0.5821 - val_mae: 0.6166\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1604 - mae: 0.8314 - val_loss: 0.5283 - val_mae: 0.5886\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8924 - mae: 0.8159 - val_loss: 0.5775 - val_mae: 0.6107\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9846 - mae: 0.7985 - val_loss: 0.5255 - val_mae: 0.5816\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6791 - mae: 0.7270 - val_loss: 0.5155 - val_mae: 0.5718\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7280 - mae: 0.7095 - val_loss: 0.5266 - val_mae: 0.5777\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7723 - mae: 0.6767 - val_loss: 0.6918 - val_mae: 0.6546\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6568 - mae: 0.7249 - val_loss: 0.5973 - val_mae: 0.6113\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5879 - mae: 0.6536 - val_loss: 0.5747 - val_mae: 0.6017\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6370 - mae: 0.6778 - val_loss: 0.5086 - val_mae: 0.5702\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5711 - mae: 0.6284 - val_loss: 0.5413 - val_mae: 0.5922\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6061 - mae: 0.6455 - val_loss: 0.5477 - val_mae: 0.5905\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5328 - mae: 0.6038 - val_loss: 0.5136 - val_mae: 0.5736\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5399 - mae: 0.6278 - val_loss: 0.6174 - val_mae: 0.6314\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4702 - mae: 0.6134 - val_loss: 0.5066 - val_mae: 0.5694\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4707 - mae: 0.5941 - val_loss: 0.5226 - val_mae: 0.5765\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4960 - mae: 0.5905 - val_loss: 0.6013 - val_mae: 0.6130\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5290 - mae: 0.5890 - val_loss: 0.5486 - val_mae: 0.5918\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5468 - mae: 0.5719 - val_loss: 0.5300 - val_mae: 0.5756\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4272 - mae: 0.5650 - val_loss: 0.5513 - val_mae: 0.5894\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.4527 - mae: 0.5946 - val_loss: 0.5531 - val_mae: 0.5894\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3922 - mae: 0.5316 - val_loss: 0.5918 - val_mae: 0.6072\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5096 - mae: 0.5596 - val_loss: 0.6764 - val_mae: 0.6393\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5703 - mae: 0.5562 - val_loss: 0.6008 - val_mae: 0.6147\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8087 - mae: 0.5975 - val_loss: 0.5530 - val_mae: 0.5911\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3653 - mae: 0.5577 - val_loss: 0.5573 - val_mae: 0.5918\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4012 - mae: 0.5493 - val_loss: 0.5116 - val_mae: 0.5697\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4274 - mae: 0.5198 - val_loss: 0.5373 - val_mae: 0.5808\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3987 - mae: 0.5267 - val_loss: 0.6061 - val_mae: 0.6127\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3605 - mae: 0.5298 - val_loss: 0.5240 - val_mae: 0.5739\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3755 - mae: 0.5070 - val_loss: 0.6554 - val_mae: 0.6439\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3537 - mae: 0.5256 - val_loss: 0.5630 - val_mae: 0.5919\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3327 - mae: 0.5083 - val_loss: 0.5522 - val_mae: 0.5871\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3371 - mae: 0.5034 - val_loss: 0.5483 - val_mae: 0.5847\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3744 - mae: 0.4897 - val_loss: 0.5630 - val_mae: 0.5883\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3734 - mae: 0.4839 - val_loss: 0.5388 - val_mae: 0.5852\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2990 - mae: 0.4994 - val_loss: 0.5365 - val_mae: 0.5811\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3037 - mae: 0.4889 - val_loss: 0.5487 - val_mae: 0.5900\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5277 - mae: 0.4716 - val_loss: 0.5860 - val_mae: 0.6016\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2923 - mae: 0.4703 - val_loss: 0.5554 - val_mae: 0.5905\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2632 - mae: 0.4678 - val_loss: 0.6124 - val_mae: 0.6166\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4167 - mae: 0.4589 - val_loss: 0.5502 - val_mae: 0.5919\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2777 - mae: 0.4551 - val_loss: 0.5790 - val_mae: 0.6035\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2997 - mae: 0.4399 - val_loss: 0.5854 - val_mae: 0.6021\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3986 - mae: 0.4630 - val_loss: 0.5575 - val_mae: 0.5956\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2922 - mae: 0.4493 - val_loss: 0.5364 - val_mae: 0.5812\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2530 - mae: 0.4509 - val_loss: 0.5355 - val_mae: 0.5789\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2446 - mae: 0.4385 - val_loss: 0.5038 - val_mae: 0.5700\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 3.5706 - mae: 1.5186 - val_loss: 2.9175 - val_mae: 1.4920\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.3162 - mae: 0.9674 - val_loss: 1.0875 - val_mae: 0.8216\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0523 - mae: 0.8967 - val_loss: 0.8090 - val_mae: 0.6914\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9140 - mae: 0.8519 - val_loss: 0.6688 - val_mae: 0.6560\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0462 - mae: 0.8071 - val_loss: 0.7477 - val_mae: 0.6900\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0172 - mae: 0.7993 - val_loss: 0.7997 - val_mae: 0.6916\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9462 - mae: 0.7687 - val_loss: 0.7339 - val_mae: 0.6803\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6761 - mae: 0.7192 - val_loss: 0.7733 - val_mae: 0.7040\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6443 - mae: 0.6928 - val_loss: 0.7004 - val_mae: 0.6709\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8285 - mae: 0.6975 - val_loss: 0.7073 - val_mae: 0.6595\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7959 - mae: 0.6613 - val_loss: 0.7067 - val_mae: 0.6807\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6598 - mae: 0.6942 - val_loss: 0.6806 - val_mae: 0.6625\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5842 - mae: 0.6431 - val_loss: 0.5741 - val_mae: 0.6027\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6337 - mae: 0.6442 - val_loss: 0.7364 - val_mae: 0.6793\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6731 - mae: 0.6960 - val_loss: 0.6351 - val_mae: 0.6331\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7612 - mae: 0.6783 - val_loss: 0.6146 - val_mae: 0.6207\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5569 - mae: 0.6186 - val_loss: 0.6285 - val_mae: 0.6311\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6249 - mae: 0.6282 - val_loss: 0.6257 - val_mae: 0.6303\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7025 - mae: 0.5810 - val_loss: 0.7097 - val_mae: 0.6509\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7305 - mae: 0.6504 - val_loss: 0.6208 - val_mae: 0.6210\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6022 - mae: 0.6191 - val_loss: 0.5892 - val_mae: 0.6015\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4473 - mae: 0.5791 - val_loss: 0.5882 - val_mae: 0.6024\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4868 - mae: 0.5781 - val_loss: 0.6201 - val_mae: 0.6204\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5065 - mae: 0.6113 - val_loss: 0.5953 - val_mae: 0.6128\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5584 - mae: 0.5681 - val_loss: 0.6432 - val_mae: 0.6343\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4212 - mae: 0.5593 - val_loss: 0.6051 - val_mae: 0.6125\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5292 - mae: 0.5854 - val_loss: 0.5886 - val_mae: 0.6085\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4186 - mae: 0.5626 - val_loss: 0.5937 - val_mae: 0.6142\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7256 - mae: 0.5939 - val_loss: 0.5575 - val_mae: 0.5893\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6813 - mae: 0.5741 - val_loss: 0.5566 - val_mae: 0.5967\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4870 - mae: 0.5756 - val_loss: 0.6330 - val_mae: 0.6289\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4233 - mae: 0.5552 - val_loss: 0.5874 - val_mae: 0.6053\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4283 - mae: 0.5414 - val_loss: 0.5873 - val_mae: 0.6043\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3295 - mae: 0.5425 - val_loss: 0.5914 - val_mae: 0.6006\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4022 - mae: 0.5390 - val_loss: 0.5788 - val_mae: 0.5998\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4057 - mae: 0.5365 - val_loss: 0.5844 - val_mae: 0.6087\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5849 - mae: 0.5199 - val_loss: 0.5669 - val_mae: 0.5950\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3750 - mae: 0.5140 - val_loss: 0.5746 - val_mae: 0.6022\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4080 - mae: 0.5041 - val_loss: 0.6660 - val_mae: 0.6467\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4028 - mae: 0.5352 - val_loss: 0.6032 - val_mae: 0.6148\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4460 - mae: 0.5054 - val_loss: 0.6318 - val_mae: 0.6284\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3630 - mae: 0.5311 - val_loss: 0.6263 - val_mae: 0.6216\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3705 - mae: 0.5097 - val_loss: 0.5844 - val_mae: 0.6028\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3238 - mae: 0.4976 - val_loss: 0.6021 - val_mae: 0.6159\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3609 - mae: 0.4910 - val_loss: 0.5743 - val_mae: 0.5965\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2927 - mae: 0.4686 - val_loss: 0.6229 - val_mae: 0.6215\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4560 - mae: 0.4921 - val_loss: 0.5580 - val_mae: 0.5913\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3203 - mae: 0.5044 - val_loss: 0.6047 - val_mae: 0.6128\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4317 - mae: 0.4770 - val_loss: 0.5764 - val_mae: 0.5983\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3021 - mae: 0.4593 - val_loss: 0.5825 - val_mae: 0.6063\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 6.9414 - mae: 2.2787 - val_loss: 5.3121 - val_mae: 2.1518\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.1240 - mae: 1.2981 - val_loss: 2.9125 - val_mae: 1.5373\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.4895 - mae: 1.0872 - val_loss: 1.6270 - val_mae: 1.0799\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.6876 - mae: 0.9359 - val_loss: 0.9472 - val_mae: 0.7737\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1315 - mae: 0.8843 - val_loss: 0.7637 - val_mae: 0.7103\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2158 - mae: 0.9509 - val_loss: 0.7146 - val_mae: 0.6820\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0147 - mae: 0.8725 - val_loss: 0.5914 - val_mae: 0.6122\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.9573 - mae: 0.8023 - val_loss: 0.6556 - val_mae: 0.6437\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3939 - mae: 0.8183 - val_loss: 0.6649 - val_mae: 0.6463\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1364 - mae: 0.7636 - val_loss: 0.7042 - val_mae: 0.6602\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1809 - mae: 0.7922 - val_loss: 0.6285 - val_mae: 0.6319\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1221 - mae: 0.7529 - val_loss: 1.0115 - val_mae: 0.8173\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9206 - mae: 0.8221 - val_loss: 0.6659 - val_mae: 0.6612\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.3259 - mae: 0.7612 - val_loss: 0.6448 - val_mae: 0.6511\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7001 - mae: 0.7185 - val_loss: 0.5810 - val_mae: 0.6136\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7440 - mae: 0.7100 - val_loss: 0.6696 - val_mae: 0.6557\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7636 - mae: 0.7158 - val_loss: 0.6673 - val_mae: 0.6492\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6136 - mae: 0.6808 - val_loss: 0.7073 - val_mae: 0.6741\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7878 - mae: 0.7459 - val_loss: 0.6231 - val_mae: 0.6321\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6717 - mae: 0.6693 - val_loss: 0.6041 - val_mae: 0.6209\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6571 - mae: 0.6625 - val_loss: 0.7132 - val_mae: 0.6653\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8370 - mae: 0.6930 - val_loss: 0.5428 - val_mae: 0.5875\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5319 - mae: 0.6578 - val_loss: 0.5737 - val_mae: 0.6026\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8843 - mae: 0.6535 - val_loss: 0.6650 - val_mae: 0.6518\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7055 - mae: 0.6491 - val_loss: 0.6660 - val_mae: 0.6527\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5075 - mae: 0.6232 - val_loss: 0.6142 - val_mae: 0.6192\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5152 - mae: 0.6600 - val_loss: 0.5997 - val_mae: 0.6185\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4967 - mae: 0.6046 - val_loss: 0.6015 - val_mae: 0.6198\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4425 - mae: 0.6167 - val_loss: 0.7631 - val_mae: 0.6896\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8678 - mae: 0.6944 - val_loss: 0.5721 - val_mae: 0.6033\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4680 - mae: 0.6111 - val_loss: 0.6237 - val_mae: 0.6310\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9796 - mae: 0.6583 - val_loss: 0.5872 - val_mae: 0.6110\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4630 - mae: 0.5917 - val_loss: 0.5887 - val_mae: 0.6070\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4283 - mae: 0.5716 - val_loss: 0.6166 - val_mae: 0.6231\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4456 - mae: 0.5950 - val_loss: 0.5246 - val_mae: 0.5746\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6922 - mae: 0.5926 - val_loss: 0.5414 - val_mae: 0.5886\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4479 - mae: 0.5432 - val_loss: 0.6535 - val_mae: 0.6390\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4651 - mae: 0.6122 - val_loss: 0.5941 - val_mae: 0.6157\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5344 - mae: 0.5839 - val_loss: 0.6087 - val_mae: 0.6184\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4589 - mae: 0.6054 - val_loss: 0.5750 - val_mae: 0.6001\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7382 - mae: 0.5898 - val_loss: 0.5544 - val_mae: 0.5886\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4406 - mae: 0.5666 - val_loss: 0.5417 - val_mae: 0.5909\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4814 - mae: 0.5672 - val_loss: 0.5685 - val_mae: 0.6002\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9668 - mae: 0.7220 - val_loss: 0.6356 - val_mae: 0.6330\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5234 - mae: 0.6278 - val_loss: 0.5987 - val_mae: 0.6192\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7644 - mae: 0.5966 - val_loss: 0.5899 - val_mae: 0.6154\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4450 - mae: 0.6075 - val_loss: 0.5699 - val_mae: 0.6031\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6008 - mae: 0.6204 - val_loss: 0.5649 - val_mae: 0.5985\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4990 - mae: 0.5856 - val_loss: 0.6124 - val_mae: 0.6265\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4764 - mae: 0.5843 - val_loss: 0.6149 - val_mae: 0.6190\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 9.1265 - mae: 2.2702 - val_loss: 3.8644 - val_mae: 1.8073\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.7463 - mae: 1.2299 - val_loss: 1.2104 - val_mae: 0.9071\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3374 - mae: 0.9599 - val_loss: 0.5859 - val_mae: 0.5940\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9129 - mae: 0.8163 - val_loss: 0.4762 - val_mae: 0.5577\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9311 - mae: 0.7898 - val_loss: 0.5133 - val_mae: 0.5866\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1265 - mae: 0.8150 - val_loss: 0.5840 - val_mae: 0.6179\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8353 - mae: 0.7925 - val_loss: 0.7290 - val_mae: 0.6990\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4266 - mae: 0.8055 - val_loss: 0.7944 - val_mae: 0.7220\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9463 - mae: 0.7806 - val_loss: 0.7461 - val_mae: 0.7011\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3116 - mae: 0.7085 - val_loss: 0.7100 - val_mae: 0.6870\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1747 - mae: 0.7509 - val_loss: 0.6032 - val_mae: 0.6347\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8012 - mae: 0.7027 - val_loss: 0.6707 - val_mae: 0.6482\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7961 - mae: 0.6976 - val_loss: 0.6752 - val_mae: 0.6553\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8692 - mae: 0.6711 - val_loss: 0.6480 - val_mae: 0.6483\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6315 - mae: 0.6493 - val_loss: 0.5088 - val_mae: 0.5725\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8602 - mae: 0.6545 - val_loss: 0.5618 - val_mae: 0.6051\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5452 - mae: 0.6317 - val_loss: 0.6427 - val_mae: 0.6488\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6023 - mae: 0.6387 - val_loss: 0.5676 - val_mae: 0.6043\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5858 - mae: 0.6422 - val_loss: 0.6097 - val_mae: 0.6324\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4537 - mae: 0.6187 - val_loss: 0.5513 - val_mae: 0.5973\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5045 - mae: 0.6405 - val_loss: 0.5789 - val_mae: 0.6129\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5445 - mae: 0.6154 - val_loss: 0.5725 - val_mae: 0.6123\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5077 - mae: 0.6040 - val_loss: 0.6016 - val_mae: 0.6216\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5796 - mae: 0.6114 - val_loss: 0.5955 - val_mae: 0.6163\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5419 - mae: 0.6305 - val_loss: 0.5904 - val_mae: 0.6156\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5834 - mae: 0.5764 - val_loss: 0.6366 - val_mae: 0.6494\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4709 - mae: 0.5928 - val_loss: 0.6225 - val_mae: 0.6428\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4819 - mae: 0.5760 - val_loss: 0.5893 - val_mae: 0.6232\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4225 - mae: 0.5820 - val_loss: 0.5549 - val_mae: 0.6015\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5666 - mae: 0.5670 - val_loss: 0.5253 - val_mae: 0.5809\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3946 - mae: 0.5453 - val_loss: 0.6121 - val_mae: 0.6322\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3842 - mae: 0.5562 - val_loss: 0.5473 - val_mae: 0.5996\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6282 - mae: 0.5996 - val_loss: 0.6207 - val_mae: 0.6409\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4555 - mae: 0.5835 - val_loss: 0.5488 - val_mae: 0.5966\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4142 - mae: 0.5466 - val_loss: 0.5276 - val_mae: 0.5870\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6253 - mae: 0.5790 - val_loss: 0.5627 - val_mae: 0.6070\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4485 - mae: 0.5616 - val_loss: 0.5307 - val_mae: 0.5939\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7008 - mae: 0.5618 - val_loss: 0.5410 - val_mae: 0.6029\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3834 - mae: 0.5274 - val_loss: 0.5069 - val_mae: 0.5796\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3701 - mae: 0.5300 - val_loss: 0.5552 - val_mae: 0.6045\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3844 - mae: 0.5199 - val_loss: 0.5806 - val_mae: 0.6173\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3601 - mae: 0.5191 - val_loss: 0.5333 - val_mae: 0.5852\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5105 - mae: 0.5420 - val_loss: 0.6782 - val_mae: 0.6663\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4321 - mae: 0.5393 - val_loss: 0.5771 - val_mae: 0.6218\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4150 - mae: 0.5499 - val_loss: 0.5328 - val_mae: 0.5917\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4865 - mae: 0.5341 - val_loss: 0.5001 - val_mae: 0.5697\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.3654 - mae: 0.5273 - val_loss: 0.5590 - val_mae: 0.6029\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3141 - mae: 0.5124 - val_loss: 0.5301 - val_mae: 0.5849\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3024 - mae: 0.4853 - val_loss: 0.5543 - val_mae: 0.5991\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3384 - mae: 0.4870 - val_loss: 0.5513 - val_mae: 0.5967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 3.7998 - mae: 1.6845 - val_loss: 2.6250 - val_mae: 1.4031\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.6227 - mae: 1.0405 - val_loss: 0.9269 - val_mae: 0.7550\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0311 - mae: 0.8787 - val_loss: 0.6682 - val_mae: 0.6340\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.8462 - mae: 0.8355 - val_loss: 0.6416 - val_mae: 0.6242\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4501 - mae: 0.8733 - val_loss: 0.7257 - val_mae: 0.6672\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5288 - mae: 0.8306 - val_loss: 0.6726 - val_mae: 0.6406\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9485 - mae: 0.8048 - val_loss: 0.8023 - val_mae: 0.7053\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4969 - mae: 0.8839 - val_loss: 0.8143 - val_mae: 0.7176\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0036 - mae: 0.8003 - val_loss: 0.7228 - val_mae: 0.6790\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8570 - mae: 0.8054 - val_loss: 0.6675 - val_mae: 0.6473\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.1837 - mae: 0.7872 - val_loss: 0.6923 - val_mae: 0.6574\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4080 - mae: 0.7254 - val_loss: 0.9498 - val_mae: 0.7721\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9938 - mae: 0.8356 - val_loss: 1.0642 - val_mae: 0.8298\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8706 - mae: 0.8194 - val_loss: 0.7944 - val_mae: 0.7018\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8176 - mae: 0.7753 - val_loss: 1.5120 - val_mae: 0.9299\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9373 - mae: 0.8076 - val_loss: 1.0906 - val_mae: 0.7683\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1304 - mae: 0.7905 - val_loss: 0.6994 - val_mae: 0.6668\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2389 - mae: 0.7494 - val_loss: 0.6793 - val_mae: 0.6550\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7447 - mae: 0.7279 - val_loss: 0.6936 - val_mae: 0.6614\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5989 - mae: 0.7078 - val_loss: 0.6313 - val_mae: 0.6222\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1186 - mae: 0.7153 - val_loss: 0.6432 - val_mae: 0.6229\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5967 - mae: 0.6908 - val_loss: 0.6275 - val_mae: 0.6275\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7396 - mae: 0.6604 - val_loss: 0.6813 - val_mae: 0.6562\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5251 - mae: 0.6531 - val_loss: 0.7255 - val_mae: 0.6595\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7172 - mae: 0.7160 - val_loss: 1.0053 - val_mae: 0.7362\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.8802 - mae: 0.7017 - val_loss: 0.6632 - val_mae: 0.6334\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2737 - mae: 0.7033 - val_loss: 0.6134 - val_mae: 0.6151\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5952 - mae: 0.6926 - val_loss: 0.7004 - val_mae: 0.6678\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9622 - mae: 0.6970 - val_loss: 0.6356 - val_mae: 0.6285\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5138 - mae: 0.6357 - val_loss: 0.7799 - val_mae: 0.6884\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7329 - mae: 0.7565 - val_loss: 0.6258 - val_mae: 0.6219\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5743 - mae: 0.6695 - val_loss: 0.6519 - val_mae: 0.6240\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6357 - mae: 0.6805 - val_loss: 0.6337 - val_mae: 0.6308\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6439 - mae: 0.6419 - val_loss: 0.6138 - val_mae: 0.6275\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6145 - mae: 0.6539 - val_loss: 0.6258 - val_mae: 0.6303\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4960 - mae: 0.6274 - val_loss: 0.6111 - val_mae: 0.6215\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7045 - mae: 0.6089 - val_loss: 0.5767 - val_mae: 0.5916\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4168 - mae: 0.6012 - val_loss: 0.6725 - val_mae: 0.6515\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7161 - mae: 0.6846 - val_loss: 0.8897 - val_mae: 0.7645\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7326 - mae: 0.6514 - val_loss: 0.6970 - val_mae: 0.6670\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7607 - mae: 0.6594 - val_loss: 0.6105 - val_mae: 0.6161\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4721 - mae: 0.6067 - val_loss: 0.8538 - val_mae: 0.6990\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5938 - mae: 0.6762 - val_loss: 0.6674 - val_mae: 0.6410\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6090 - mae: 0.6332 - val_loss: 0.5871 - val_mae: 0.6022\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7438 - mae: 0.5882 - val_loss: 0.7443 - val_mae: 0.6843\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8889 - mae: 0.7201 - val_loss: 0.7659 - val_mae: 0.6693\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3281 - mae: 0.6596 - val_loss: 0.6238 - val_mae: 0.6139\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2859 - mae: 0.6031 - val_loss: 0.6022 - val_mae: 0.6047\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7372 - mae: 0.6388 - val_loss: 0.5638 - val_mae: 0.5919\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5337 - mae: 0.5804 - val_loss: 0.6046 - val_mae: 0.6152\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5943 - mae: 0.6036\n",
            "Test MAE for SentenceStructure: 0.6240664720535278\n",
            "Training model for AU...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 11.5414 - mae: 3.3502 - val_loss: 4.6758 - val_mae: 2.0224\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.7066 - mae: 1.6403 - val_loss: 0.8009 - val_mae: 0.7144\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5672 - mae: 1.0548 - val_loss: 0.4750 - val_mae: 0.5459\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.1846 - mae: 0.8928 - val_loss: 0.5222 - val_mae: 0.5852\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.0012 - mae: 0.8152 - val_loss: 0.5444 - val_mae: 0.5974\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9531 - mae: 0.7603 - val_loss: 0.5073 - val_mae: 0.5689\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7809 - mae: 0.7326 - val_loss: 0.5421 - val_mae: 0.5486\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7091 - mae: 0.6987 - val_loss: 0.5959 - val_mae: 0.5933\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5796 - mae: 0.6691 - val_loss: 0.5537 - val_mae: 0.5789\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5976 - mae: 0.6635 - val_loss: 0.5784 - val_mae: 0.6011\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6410 - mae: 0.6716 - val_loss: 0.4689 - val_mae: 0.5349\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6095 - mae: 0.6310 - val_loss: 0.5152 - val_mae: 0.5717\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6111 - mae: 0.6432 - val_loss: 0.4689 - val_mae: 0.5483\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4923 - mae: 0.5904 - val_loss: 0.5159 - val_mae: 0.5772\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5553 - mae: 0.6097 - val_loss: 0.5267 - val_mae: 0.5808\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4376 - mae: 0.5823 - val_loss: 0.4965 - val_mae: 0.5573\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.4574 - mae: 0.5746 - val_loss: 0.4739 - val_mae: 0.5419\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4328 - mae: 0.6032 - val_loss: 0.5237 - val_mae: 0.5693\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3915 - mae: 0.5308 - val_loss: 0.4437 - val_mae: 0.5254\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4160 - mae: 0.5483 - val_loss: 0.4462 - val_mae: 0.5286\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3859 - mae: 0.5255 - val_loss: 0.4140 - val_mae: 0.5116\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3504 - mae: 0.5131 - val_loss: 0.4639 - val_mae: 0.5372\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4211 - mae: 0.5323 - val_loss: 0.4109 - val_mae: 0.5088\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3857 - mae: 0.5121 - val_loss: 0.4171 - val_mae: 0.5089\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3321 - mae: 0.4939 - val_loss: 0.4276 - val_mae: 0.5167\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3687 - mae: 0.4941 - val_loss: 0.4263 - val_mae: 0.5159\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3083 - mae: 0.4943 - val_loss: 0.4603 - val_mae: 0.5364\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3331 - mae: 0.4945 - val_loss: 0.4185 - val_mae: 0.5154\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3031 - mae: 0.4718 - val_loss: 0.4083 - val_mae: 0.5043\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3144 - mae: 0.4761 - val_loss: 0.4283 - val_mae: 0.5146\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3428 - mae: 0.4756 - val_loss: 0.3921 - val_mae: 0.4888\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3013 - mae: 0.4719 - val_loss: 0.3859 - val_mae: 0.4857\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2797 - mae: 0.4542 - val_loss: 0.4297 - val_mae: 0.5199\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3055 - mae: 0.4723 - val_loss: 0.4099 - val_mae: 0.5097\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2518 - mae: 0.4422 - val_loss: 0.4041 - val_mae: 0.5090\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4311 - mae: 0.6300 - val_loss: 0.4353 - val_mae: 0.5364\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3327 - mae: 0.4972 - val_loss: 0.3974 - val_mae: 0.5064\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3186 - mae: 0.4559 - val_loss: 0.3974 - val_mae: 0.5040\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2956 - mae: 0.4535 - val_loss: 0.4091 - val_mae: 0.5110\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2391 - mae: 0.4235 - val_loss: 0.4382 - val_mae: 0.5219\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2642 - mae: 0.4136 - val_loss: 0.4010 - val_mae: 0.5007\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2595 - mae: 0.4222 - val_loss: 0.4011 - val_mae: 0.4979\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2364 - mae: 0.4149 - val_loss: 0.3982 - val_mae: 0.4955\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2609 - mae: 0.4092 - val_loss: 0.3999 - val_mae: 0.5019\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2141 - mae: 0.4117 - val_loss: 0.4746 - val_mae: 0.5481\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2099 - mae: 0.3873 - val_loss: 0.3879 - val_mae: 0.4931\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2203 - mae: 0.3927 - val_loss: 0.4415 - val_mae: 0.5236\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2262 - mae: 0.4096 - val_loss: 0.4154 - val_mae: 0.5139\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2288 - mae: 0.4042 - val_loss: 0.4261 - val_mae: 0.5179\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2152 - mae: 0.3918 - val_loss: 0.4576 - val_mae: 0.5404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 11.0572 - mae: 2.8824 - val_loss: 3.3566 - val_mae: 1.6736\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6965 - mae: 1.1491 - val_loss: 0.7107 - val_mae: 0.6458\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0476 - mae: 0.9033 - val_loss: 0.4444 - val_mae: 0.5355\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9414 - mae: 0.7978 - val_loss: 0.4022 - val_mae: 0.5131\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9804 - mae: 0.7790 - val_loss: 0.4278 - val_mae: 0.5224\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8344 - mae: 0.7326 - val_loss: 0.4109 - val_mae: 0.5157\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7093 - mae: 0.6841 - val_loss: 0.4112 - val_mae: 0.5139\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7565 - mae: 0.6547 - val_loss: 0.4382 - val_mae: 0.5211\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6076 - mae: 0.6559 - val_loss: 0.4170 - val_mae: 0.5088\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5492 - mae: 0.6429 - val_loss: 0.4339 - val_mae: 0.5116\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5250 - mae: 0.6109 - val_loss: 0.4514 - val_mae: 0.5286\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5073 - mae: 0.6097 - val_loss: 0.5482 - val_mae: 0.5743\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5236 - mae: 0.5924 - val_loss: 0.5005 - val_mae: 0.5536\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4728 - mae: 0.5996 - val_loss: 0.4700 - val_mae: 0.5328\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5536 - mae: 0.5896 - val_loss: 0.4140 - val_mae: 0.5133\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4029 - mae: 0.5641 - val_loss: 0.4150 - val_mae: 0.5028\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4424 - mae: 0.5593 - val_loss: 0.4406 - val_mae: 0.5151\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4835 - mae: 0.5534 - val_loss: 0.4474 - val_mae: 0.5280\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4745 - mae: 0.5543 - val_loss: 0.4934 - val_mae: 0.5439\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5358 - mae: 0.5661 - val_loss: 0.3830 - val_mae: 0.4933\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6359 - mae: 0.5494 - val_loss: 0.4179 - val_mae: 0.5170\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3302 - mae: 0.5200 - val_loss: 0.4681 - val_mae: 0.5368\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5355 - mae: 0.5544 - val_loss: 0.4142 - val_mae: 0.5061\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3979 - mae: 0.5266 - val_loss: 0.4095 - val_mae: 0.5068\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3759 - mae: 0.5087 - val_loss: 0.4575 - val_mae: 0.5374\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4091 - mae: 0.5330 - val_loss: 0.4080 - val_mae: 0.5042\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3558 - mae: 0.4883 - val_loss: 0.4352 - val_mae: 0.5198\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3369 - mae: 0.4980 - val_loss: 0.4227 - val_mae: 0.5168\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3514 - mae: 0.5023 - val_loss: 0.4663 - val_mae: 0.5371\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2945 - mae: 0.4884 - val_loss: 0.4676 - val_mae: 0.5322\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3064 - mae: 0.4904 - val_loss: 0.3933 - val_mae: 0.4971\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3363 - mae: 0.4791 - val_loss: 0.4236 - val_mae: 0.5144\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2856 - mae: 0.4877 - val_loss: 0.5090 - val_mae: 0.5591\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4147 - mae: 0.5012 - val_loss: 0.3994 - val_mae: 0.4966\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2729 - mae: 0.4524 - val_loss: 0.4380 - val_mae: 0.5210\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3345 - mae: 0.4674 - val_loss: 0.4108 - val_mae: 0.5091\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3361 - mae: 0.4653 - val_loss: 0.4160 - val_mae: 0.5088\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3359 - mae: 0.4538 - val_loss: 0.4376 - val_mae: 0.5227\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3536 - mae: 0.4408 - val_loss: 0.3982 - val_mae: 0.4972\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2530 - mae: 0.4277 - val_loss: 0.4084 - val_mae: 0.5009\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2373 - mae: 0.4374 - val_loss: 0.3774 - val_mae: 0.4902\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4277 - mae: 0.6016 - val_loss: 0.4004 - val_mae: 0.4939\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3074 - mae: 0.4515 - val_loss: 0.4435 - val_mae: 0.5194\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3274 - mae: 0.4307 - val_loss: 0.4175 - val_mae: 0.5007\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2624 - mae: 0.4361 - val_loss: 0.4145 - val_mae: 0.5033\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2713 - mae: 0.4363 - val_loss: 0.4050 - val_mae: 0.4922\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2109 - mae: 0.4000 - val_loss: 0.3952 - val_mae: 0.4946\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2718 - mae: 0.4234 - val_loss: 0.4037 - val_mae: 0.5040\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2659 - mae: 0.4039 - val_loss: 0.3973 - val_mae: 0.5030\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3000 - mae: 0.4100 - val_loss: 0.4718 - val_mae: 0.5405\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 10.9740 - mae: 3.3712 - val_loss: 4.7724 - val_mae: 2.0535\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.7925 - mae: 1.2469 - val_loss: 1.2257 - val_mae: 0.8995\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0560 - mae: 0.8766 - val_loss: 0.7087 - val_mae: 0.6228\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8889 - mae: 0.7810 - val_loss: 0.4090 - val_mae: 0.5043\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8441 - mae: 0.7725 - val_loss: 0.3723 - val_mae: 0.4740\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7559 - mae: 0.6768 - val_loss: 0.3781 - val_mae: 0.4830\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6339 - mae: 0.6705 - val_loss: 0.6177 - val_mae: 0.6248\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6821 - mae: 0.7296 - val_loss: 0.4341 - val_mae: 0.5174\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5654 - mae: 0.6320 - val_loss: 0.5071 - val_mae: 0.5582\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6106 - mae: 0.6275 - val_loss: 0.4685 - val_mae: 0.5402\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4434 - mae: 0.5879 - val_loss: 0.3846 - val_mae: 0.4917\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4951 - mae: 0.5899 - val_loss: 0.3932 - val_mae: 0.5002\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5317 - mae: 0.5905 - val_loss: 0.4049 - val_mae: 0.5047\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4289 - mae: 0.5505 - val_loss: 0.4250 - val_mae: 0.5189\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4665 - mae: 0.5861 - val_loss: 0.4736 - val_mae: 0.5363\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5382 - mae: 0.6270 - val_loss: 0.4858 - val_mae: 0.5518\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5532 - mae: 0.5848 - val_loss: 0.3916 - val_mae: 0.4924\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4697 - mae: 0.5960 - val_loss: 0.4118 - val_mae: 0.5031\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4899 - mae: 0.5534 - val_loss: 0.5025 - val_mae: 0.5491\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4238 - mae: 0.5384 - val_loss: 0.4353 - val_mae: 0.5133\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4309 - mae: 0.5439 - val_loss: 0.4026 - val_mae: 0.4885\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3399 - mae: 0.5229 - val_loss: 0.3558 - val_mae: 0.4650\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3674 - mae: 0.5153 - val_loss: 0.4061 - val_mae: 0.4973\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3413 - mae: 0.5132 - val_loss: 0.3520 - val_mae: 0.4621\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3494 - mae: 0.5197 - val_loss: 0.3896 - val_mae: 0.4914\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3249 - mae: 0.4886 - val_loss: 0.3541 - val_mae: 0.4627\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3256 - mae: 0.4799 - val_loss: 0.4002 - val_mae: 0.4978\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3720 - mae: 0.5123 - val_loss: 0.3783 - val_mae: 0.4846\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3016 - mae: 0.4849 - val_loss: 0.3581 - val_mae: 0.4727\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3300 - mae: 0.4842 - val_loss: 0.4316 - val_mae: 0.5089\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3188 - mae: 0.4834 - val_loss: 0.3694 - val_mae: 0.4770\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2708 - mae: 0.4637 - val_loss: 0.3825 - val_mae: 0.4837\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2958 - mae: 0.4636 - val_loss: 0.3667 - val_mae: 0.4743\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3377 - mae: 0.4643 - val_loss: 0.3717 - val_mae: 0.4748\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2341 - mae: 0.4380 - val_loss: 0.4124 - val_mae: 0.4945\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2970 - mae: 0.4379 - val_loss: 0.3706 - val_mae: 0.4734\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2779 - mae: 0.4249 - val_loss: 0.3659 - val_mae: 0.4685\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2355 - mae: 0.4313 - val_loss: 0.3961 - val_mae: 0.4941\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3149 - mae: 0.4386 - val_loss: 0.3815 - val_mae: 0.4843\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2612 - mae: 0.4244 - val_loss: 0.3631 - val_mae: 0.4742\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2703 - mae: 0.4196 - val_loss: 0.3629 - val_mae: 0.4719\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3235 - mae: 0.4329 - val_loss: 0.3944 - val_mae: 0.4882\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2659 - mae: 0.4223 - val_loss: 0.4058 - val_mae: 0.4923\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2688 - mae: 0.4491 - val_loss: 0.4990 - val_mae: 0.5465\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2570 - mae: 0.4321 - val_loss: 0.3674 - val_mae: 0.4682\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2807 - mae: 0.4311 - val_loss: 0.3620 - val_mae: 0.4670\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2638 - mae: 0.4086 - val_loss: 0.3602 - val_mae: 0.4685\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2165 - mae: 0.4065 - val_loss: 0.3733 - val_mae: 0.4739\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1991 - mae: 0.3864 - val_loss: 0.3847 - val_mae: 0.4827\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2420 - mae: 0.3870 - val_loss: 0.3504 - val_mae: 0.4594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.6039 - mae: 1.5032 - val_loss: 1.9696 - val_mae: 1.1824\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1839 - mae: 0.8722 - val_loss: 0.5144 - val_mae: 0.5543\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2675 - mae: 0.8364 - val_loss: 0.6668 - val_mae: 0.6454\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0999 - mae: 0.7714 - val_loss: 0.5777 - val_mae: 0.5927\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8654 - mae: 0.7114 - val_loss: 0.4545 - val_mae: 0.5331\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7062 - mae: 0.6836 - val_loss: 0.4684 - val_mae: 0.5418\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5490 - mae: 0.6397 - val_loss: 0.5231 - val_mae: 0.5734\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6977 - mae: 0.6698 - val_loss: 0.4946 - val_mae: 0.5593\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.5215 - mae: 0.6217 - val_loss: 0.5176 - val_mae: 0.5788\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5826 - mae: 0.6308 - val_loss: 0.4500 - val_mae: 0.5333\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5250 - mae: 0.5798 - val_loss: 0.4939 - val_mae: 0.5608\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5630 - mae: 0.6165 - val_loss: 0.4651 - val_mae: 0.5433\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6179 - mae: 0.5874 - val_loss: 0.5331 - val_mae: 0.5923\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4228 - mae: 0.5460 - val_loss: 0.5252 - val_mae: 0.5827\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5535 - mae: 0.6079 - val_loss: 0.4561 - val_mae: 0.5414\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4840 - mae: 0.5699 - val_loss: 0.4379 - val_mae: 0.5342\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4073 - mae: 0.5466 - val_loss: 0.4483 - val_mae: 0.5396\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4873 - mae: 0.5437 - val_loss: 0.4928 - val_mae: 0.5716\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4661 - mae: 0.5385 - val_loss: 0.4324 - val_mae: 0.5372\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3764 - mae: 0.5536 - val_loss: 0.4511 - val_mae: 0.5458\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3684 - mae: 0.5138 - val_loss: 0.4245 - val_mae: 0.5270\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4349 - mae: 0.5200 - val_loss: 0.3990 - val_mae: 0.5109\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4013 - mae: 0.5103 - val_loss: 0.4136 - val_mae: 0.5178\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3576 - mae: 0.4964 - val_loss: 0.4254 - val_mae: 0.5171\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3696 - mae: 0.5012 - val_loss: 0.4162 - val_mae: 0.5215\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3484 - mae: 0.5136 - val_loss: 0.4225 - val_mae: 0.5186\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4828 - mae: 0.5031 - val_loss: 0.4250 - val_mae: 0.5155\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3557 - mae: 0.4891 - val_loss: 0.4498 - val_mae: 0.5385\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3938 - mae: 0.4945 - val_loss: 0.4156 - val_mae: 0.5095\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4149 - mae: 0.5557 - val_loss: 0.4470 - val_mae: 0.5302\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4034 - mae: 0.5148 - val_loss: 0.4186 - val_mae: 0.5072\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3842 - mae: 0.5058 - val_loss: 0.4267 - val_mae: 0.5176\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3962 - mae: 0.5001 - val_loss: 0.4124 - val_mae: 0.5019\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4221 - mae: 0.4873 - val_loss: 0.4358 - val_mae: 0.5202\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4006 - mae: 0.4795 - val_loss: 0.4506 - val_mae: 0.5328\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3678 - mae: 0.4788 - val_loss: 0.4255 - val_mae: 0.5168\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3658 - mae: 0.4824 - val_loss: 0.4508 - val_mae: 0.5298\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2925 - mae: 0.4545 - val_loss: 0.3966 - val_mae: 0.4982\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.2959 - mae: 0.4632 - val_loss: 0.4060 - val_mae: 0.5045\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3001 - mae: 0.4554 - val_loss: 0.4166 - val_mae: 0.5129\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3323 - mae: 0.4515 - val_loss: 0.4319 - val_mae: 0.5221\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3245 - mae: 0.4597 - val_loss: 0.4114 - val_mae: 0.5139\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3168 - mae: 0.4415 - val_loss: 0.4095 - val_mae: 0.5109\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4338 - mae: 0.5262 - val_loss: 0.4629 - val_mae: 0.5367\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2941 - mae: 0.4423 - val_loss: 0.3995 - val_mae: 0.5011\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3229 - mae: 0.4686 - val_loss: 0.3868 - val_mae: 0.4871\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3133 - mae: 0.4464 - val_loss: 0.4050 - val_mae: 0.4985\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3171 - mae: 0.4567 - val_loss: 0.3947 - val_mae: 0.4955\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2821 - mae: 0.4316 - val_loss: 0.4263 - val_mae: 0.5178\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2579 - mae: 0.4114 - val_loss: 0.3988 - val_mae: 0.4963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 7.2635 - mae: 2.5775 - val_loss: 5.3094 - val_mae: 2.1399\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.8547 - mae: 1.0786 - val_loss: 2.1465 - val_mae: 1.2390\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1048 - mae: 0.8492 - val_loss: 1.1581 - val_mae: 0.8580\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9512 - mae: 0.7650 - val_loss: 0.6850 - val_mae: 0.6485\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7135 - mae: 0.7320 - val_loss: 0.5059 - val_mae: 0.5711\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7535 - mae: 0.7330 - val_loss: 0.4294 - val_mae: 0.5092\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7469 - mae: 0.6697 - val_loss: 0.4474 - val_mae: 0.5248\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6792 - mae: 0.6448 - val_loss: 0.4868 - val_mae: 0.5583\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5996 - mae: 0.6458 - val_loss: 0.4607 - val_mae: 0.5366\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.4858 - mae: 0.6098 - val_loss: 0.4172 - val_mae: 0.5094\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5084 - mae: 0.6061 - val_loss: 0.4729 - val_mae: 0.5453\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5333 - mae: 0.6246 - val_loss: 0.4868 - val_mae: 0.5510\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5102 - mae: 0.5902 - val_loss: 0.4220 - val_mae: 0.5149\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5419 - mae: 0.5981 - val_loss: 0.4672 - val_mae: 0.5463\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5619 - mae: 0.5850 - val_loss: 0.4629 - val_mae: 0.5407\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4352 - mae: 0.5733 - val_loss: 0.4297 - val_mae: 0.5179\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4755 - mae: 0.6008 - val_loss: 0.4462 - val_mae: 0.5332\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4507 - mae: 0.5464 - val_loss: 0.4153 - val_mae: 0.5139\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4499 - mae: 0.5383 - val_loss: 0.4429 - val_mae: 0.5344\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4337 - mae: 0.5431 - val_loss: 0.4092 - val_mae: 0.5114\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5145 - mae: 0.5444 - val_loss: 0.4539 - val_mae: 0.5362\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4737 - mae: 0.5575 - val_loss: 0.5176 - val_mae: 0.5744\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3699 - mae: 0.5316 - val_loss: 0.4540 - val_mae: 0.5338\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3870 - mae: 0.5196 - val_loss: 0.4275 - val_mae: 0.5220\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3885 - mae: 0.5028 - val_loss: 0.4326 - val_mae: 0.5303\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4280 - mae: 0.5107 - val_loss: 0.4410 - val_mae: 0.5308\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3654 - mae: 0.5096 - val_loss: 0.4489 - val_mae: 0.5387\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4108 - mae: 0.5205 - val_loss: 0.4909 - val_mae: 0.5619\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3619 - mae: 0.5025 - val_loss: 0.4416 - val_mae: 0.5356\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3277 - mae: 0.5053 - val_loss: 0.4656 - val_mae: 0.5525\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3154 - mae: 0.4883 - val_loss: 0.4167 - val_mae: 0.5264\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3587 - mae: 0.4933 - val_loss: 0.4410 - val_mae: 0.5413\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3386 - mae: 0.5079 - val_loss: 0.3977 - val_mae: 0.5079\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2782 - mae: 0.4681 - val_loss: 0.4008 - val_mae: 0.5098\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2689 - mae: 0.4615 - val_loss: 0.4064 - val_mae: 0.5153\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2927 - mae: 0.4539 - val_loss: 0.3980 - val_mae: 0.5072\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3396 - mae: 0.4550 - val_loss: 0.4938 - val_mae: 0.5550\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3462 - mae: 0.4553 - val_loss: 0.4480 - val_mae: 0.5322\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2760 - mae: 0.4660 - val_loss: 0.4179 - val_mae: 0.5045\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3803 - mae: 0.4937 - val_loss: 0.3869 - val_mae: 0.4956\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2870 - mae: 0.4451 - val_loss: 0.3929 - val_mae: 0.4974\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3170 - mae: 0.4290 - val_loss: 0.3861 - val_mae: 0.5008\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2509 - mae: 0.4304 - val_loss: 0.3978 - val_mae: 0.5034\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3341 - mae: 0.4279 - val_loss: 0.3932 - val_mae: 0.5082\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2308 - mae: 0.4063 - val_loss: 0.4009 - val_mae: 0.5068\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3046 - mae: 0.4270 - val_loss: 0.4394 - val_mae: 0.5416\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2960 - mae: 0.4290 - val_loss: 0.3849 - val_mae: 0.5004\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3181 - mae: 0.4252 - val_loss: 0.3830 - val_mae: 0.4946\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2442 - mae: 0.4189 - val_loss: 0.4239 - val_mae: 0.5261\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3407 - mae: 0.4254 - val_loss: 0.3942 - val_mae: 0.5058\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4020 - mae: 0.4699\n",
            "Test MAE for AU: 0.5083559155464172\n",
            "Training model for TS...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 2.3186 - mae: 1.2418 - val_loss: 1.8526 - val_mae: 1.2197\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.0488 - mae: 0.7855 - val_loss: 0.7473 - val_mae: 0.6944\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7712 - mae: 0.6883 - val_loss: 0.4604 - val_mae: 0.5390\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6292 - mae: 0.6439 - val_loss: 0.4487 - val_mae: 0.5422\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5565 - mae: 0.6207 - val_loss: 0.4863 - val_mae: 0.5519\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5274 - mae: 0.6140 - val_loss: 0.4787 - val_mae: 0.5414\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4664 - mae: 0.5736 - val_loss: 0.4490 - val_mae: 0.5223\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4513 - mae: 0.5641 - val_loss: 0.5114 - val_mae: 0.5584\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4286 - mae: 0.5452 - val_loss: 0.4555 - val_mae: 0.5278\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3784 - mae: 0.5078 - val_loss: 0.4521 - val_mae: 0.5310\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3659 - mae: 0.5233 - val_loss: 0.5380 - val_mae: 0.5822\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3542 - mae: 0.5100 - val_loss: 0.4617 - val_mae: 0.5268\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3011 - mae: 0.4740 - val_loss: 0.4278 - val_mae: 0.5034\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3123 - mae: 0.4616 - val_loss: 0.4458 - val_mae: 0.5104\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3148 - mae: 0.4700 - val_loss: 0.5294 - val_mae: 0.5698\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2833 - mae: 0.4428 - val_loss: 0.4911 - val_mae: 0.5426\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2710 - mae: 0.4395 - val_loss: 0.4533 - val_mae: 0.5218\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2589 - mae: 0.4423 - val_loss: 0.5042 - val_mae: 0.5502\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2448 - mae: 0.4210 - val_loss: 0.4619 - val_mae: 0.5305\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2386 - mae: 0.4219 - val_loss: 0.4531 - val_mae: 0.5235\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2257 - mae: 0.4115 - val_loss: 0.4448 - val_mae: 0.5138\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2215 - mae: 0.4035 - val_loss: 0.4854 - val_mae: 0.5400\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2071 - mae: 0.3920 - val_loss: 0.4380 - val_mae: 0.5153\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2099 - mae: 0.4019 - val_loss: 0.4471 - val_mae: 0.5216\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1846 - mae: 0.3825 - val_loss: 0.4362 - val_mae: 0.5122\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2083 - mae: 0.3900 - val_loss: 0.4554 - val_mae: 0.5190\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1895 - mae: 0.3772 - val_loss: 0.4099 - val_mae: 0.4994\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1786 - mae: 0.3628 - val_loss: 0.4817 - val_mae: 0.5434\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1998 - mae: 0.3612 - val_loss: 0.4755 - val_mae: 0.5409\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1793 - mae: 0.3577 - val_loss: 0.4393 - val_mae: 0.5126\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1807 - mae: 0.3576 - val_loss: 0.4506 - val_mae: 0.5230\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1510 - mae: 0.3404 - val_loss: 0.4497 - val_mae: 0.5174\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1595 - mae: 0.3378 - val_loss: 0.4889 - val_mae: 0.5450\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1796 - mae: 0.3599 - val_loss: 0.4773 - val_mae: 0.5385\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1587 - mae: 0.3388 - val_loss: 0.4840 - val_mae: 0.5396\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1528 - mae: 0.3394 - val_loss: 0.5293 - val_mae: 0.5625\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1467 - mae: 0.3309 - val_loss: 0.4429 - val_mae: 0.5173\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1310 - mae: 0.3128 - val_loss: 0.4491 - val_mae: 0.5167\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1374 - mae: 0.3127 - val_loss: 0.4654 - val_mae: 0.5312\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1339 - mae: 0.3094 - val_loss: 0.4617 - val_mae: 0.5321\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1449 - mae: 0.3131 - val_loss: 0.4638 - val_mae: 0.5227\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1569 - mae: 0.3502 - val_loss: 0.4278 - val_mae: 0.5078\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1174 - mae: 0.2952 - val_loss: 0.4401 - val_mae: 0.5154\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1343 - mae: 0.3058 - val_loss: 0.4356 - val_mae: 0.5147\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1217 - mae: 0.3064 - val_loss: 0.4159 - val_mae: 0.4992\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1031 - mae: 0.2816 - val_loss: 0.4284 - val_mae: 0.5004\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1202 - mae: 0.2891 - val_loss: 0.4533 - val_mae: 0.5189\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1203 - mae: 0.2997 - val_loss: 0.4628 - val_mae: 0.5249\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1315 - mae: 0.2882 - val_loss: 0.4859 - val_mae: 0.5385\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1271 - mae: 0.3193 - val_loss: 0.4373 - val_mae: 0.5119\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.2806 - mae: 1.4918 - val_loss: 1.3792 - val_mae: 0.9713\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9701 - mae: 0.7707 - val_loss: 0.7247 - val_mae: 0.6601\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7660 - mae: 0.7184 - val_loss: 0.6873 - val_mae: 0.6481\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6613 - mae: 0.6613 - val_loss: 0.6162 - val_mae: 0.6069\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5946 - mae: 0.6050 - val_loss: 0.4686 - val_mae: 0.5290\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5137 - mae: 0.6014 - val_loss: 0.4324 - val_mae: 0.5153\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4523 - mae: 0.5561 - val_loss: 0.4538 - val_mae: 0.5178\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3999 - mae: 0.5270 - val_loss: 0.4516 - val_mae: 0.5179\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4023 - mae: 0.5306 - val_loss: 0.4530 - val_mae: 0.5181\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3668 - mae: 0.5214 - val_loss: 0.4741 - val_mae: 0.5306\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3587 - mae: 0.5133 - val_loss: 0.4791 - val_mae: 0.5315\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3300 - mae: 0.5004 - val_loss: 0.4711 - val_mae: 0.5324\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3297 - mae: 0.4978 - val_loss: 0.4489 - val_mae: 0.5127\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2891 - mae: 0.4533 - val_loss: 0.4694 - val_mae: 0.5299\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3137 - mae: 0.4511 - val_loss: 0.4706 - val_mae: 0.5196\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2620 - mae: 0.4419 - val_loss: 0.4575 - val_mae: 0.5195\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2620 - mae: 0.4450 - val_loss: 0.4882 - val_mae: 0.5324\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2300 - mae: 0.4284 - val_loss: 0.4671 - val_mae: 0.5302\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2370 - mae: 0.4035 - val_loss: 0.4467 - val_mae: 0.5181\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2297 - mae: 0.3980 - val_loss: 0.4645 - val_mae: 0.5307\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2146 - mae: 0.3978 - val_loss: 0.4538 - val_mae: 0.5207\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2189 - mae: 0.3986 - val_loss: 0.4727 - val_mae: 0.5369\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2168 - mae: 0.3895 - val_loss: 0.4572 - val_mae: 0.5263\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1991 - mae: 0.3825 - val_loss: 0.4564 - val_mae: 0.5229\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2068 - mae: 0.3811 - val_loss: 0.4640 - val_mae: 0.5252\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1979 - mae: 0.3703 - val_loss: 0.4570 - val_mae: 0.5238\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1869 - mae: 0.3699 - val_loss: 0.4668 - val_mae: 0.5230\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1870 - mae: 0.3753 - val_loss: 0.4838 - val_mae: 0.5404\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1913 - mae: 0.3655 - val_loss: 0.4632 - val_mae: 0.5186\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1817 - mae: 0.3752 - val_loss: 0.4925 - val_mae: 0.5329\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1644 - mae: 0.3557 - val_loss: 0.4533 - val_mae: 0.5173\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1663 - mae: 0.3519 - val_loss: 0.4352 - val_mae: 0.5063\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1550 - mae: 0.3365 - val_loss: 0.4393 - val_mae: 0.5070\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1608 - mae: 0.3380 - val_loss: 0.4506 - val_mae: 0.5120\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1546 - mae: 0.3294 - val_loss: 0.4957 - val_mae: 0.5403\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1486 - mae: 0.3161 - val_loss: 0.4776 - val_mae: 0.5351\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1366 - mae: 0.3213 - val_loss: 0.4584 - val_mae: 0.5213\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1582 - mae: 0.3382 - val_loss: 0.4622 - val_mae: 0.5262\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1457 - mae: 0.3255 - val_loss: 0.4921 - val_mae: 0.5452\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1434 - mae: 0.3266 - val_loss: 0.4566 - val_mae: 0.5181\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1606 - mae: 0.3474 - val_loss: 0.4741 - val_mae: 0.5281\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1772 - mae: 0.3591 - val_loss: 0.4487 - val_mae: 0.5139\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1346 - mae: 0.3027 - val_loss: 0.4641 - val_mae: 0.5267\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1592 - mae: 0.3431 - val_loss: 0.4361 - val_mae: 0.5081\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1426 - mae: 0.3036 - val_loss: 0.4903 - val_mae: 0.5375\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1420 - mae: 0.3173 - val_loss: 0.4961 - val_mae: 0.5395\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1285 - mae: 0.2899 - val_loss: 0.4848 - val_mae: 0.5348\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1273 - mae: 0.2897 - val_loss: 0.5189 - val_mae: 0.5497\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1408 - mae: 0.3088 - val_loss: 0.4707 - val_mae: 0.5233\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1202 - mae: 0.2841 - val_loss: 0.4620 - val_mae: 0.5231\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.3955 - mae: 1.1725 - val_loss: 2.5532 - val_mae: 1.4475\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9674 - mae: 0.7819 - val_loss: 1.2069 - val_mae: 0.9494\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7353 - mae: 0.6666 - val_loss: 0.7842 - val_mae: 0.7449\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6759 - mae: 0.6471 - val_loss: 0.6244 - val_mae: 0.6528\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5432 - mae: 0.6195 - val_loss: 0.5486 - val_mae: 0.5947\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6435 - mae: 0.6489 - val_loss: 0.5214 - val_mae: 0.5686\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.5421 - mae: 0.5942 - val_loss: 0.5050 - val_mae: 0.5587\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5060 - mae: 0.5845 - val_loss: 0.4158 - val_mae: 0.4951\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4118 - mae: 0.5479 - val_loss: 0.4443 - val_mae: 0.5230\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4187 - mae: 0.5444 - val_loss: 0.4401 - val_mae: 0.5190\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4137 - mae: 0.5422 - val_loss: 0.4336 - val_mae: 0.5151\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3464 - mae: 0.5005 - val_loss: 0.4556 - val_mae: 0.5327\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3687 - mae: 0.5185 - val_loss: 0.4206 - val_mae: 0.5072\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3450 - mae: 0.5002 - val_loss: 0.4409 - val_mae: 0.5259\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3275 - mae: 0.4892 - val_loss: 0.4449 - val_mae: 0.5227\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3018 - mae: 0.4576 - val_loss: 0.4009 - val_mae: 0.4925\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2862 - mae: 0.4406 - val_loss: 0.3869 - val_mae: 0.4858\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2971 - mae: 0.4605 - val_loss: 0.4002 - val_mae: 0.4879\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2432 - mae: 0.4311 - val_loss: 0.4109 - val_mae: 0.4972\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2687 - mae: 0.4386 - val_loss: 0.3828 - val_mae: 0.4832\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2664 - mae: 0.4421 - val_loss: 0.4167 - val_mae: 0.5066\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2162 - mae: 0.4116 - val_loss: 0.4424 - val_mae: 0.5211\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2445 - mae: 0.4327 - val_loss: 0.4032 - val_mae: 0.4951\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2379 - mae: 0.4362 - val_loss: 0.4232 - val_mae: 0.5076\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2319 - mae: 0.4210 - val_loss: 0.3807 - val_mae: 0.4822\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2109 - mae: 0.4019 - val_loss: 0.3943 - val_mae: 0.4893\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2320 - mae: 0.3879 - val_loss: 0.3938 - val_mae: 0.4869\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2065 - mae: 0.3865 - val_loss: 0.3747 - val_mae: 0.4784\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2265 - mae: 0.3962 - val_loss: 0.3902 - val_mae: 0.4896\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2152 - mae: 0.3967 - val_loss: 0.3705 - val_mae: 0.4785\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1809 - mae: 0.3668 - val_loss: 0.3956 - val_mae: 0.4924\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1778 - mae: 0.3645 - val_loss: 0.4068 - val_mae: 0.4997\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1828 - mae: 0.3739 - val_loss: 0.3696 - val_mae: 0.4774\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1827 - mae: 0.3664 - val_loss: 0.3805 - val_mae: 0.4814\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1840 - mae: 0.3630 - val_loss: 0.3783 - val_mae: 0.4820\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1835 - mae: 0.3468 - val_loss: 0.3698 - val_mae: 0.4774\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1705 - mae: 0.3407 - val_loss: 0.3610 - val_mae: 0.4702\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1675 - mae: 0.3376 - val_loss: 0.3813 - val_mae: 0.4866\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1640 - mae: 0.3418 - val_loss: 0.4026 - val_mae: 0.4998\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1749 - mae: 0.3473 - val_loss: 0.3774 - val_mae: 0.4791\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1546 - mae: 0.3311 - val_loss: 0.3649 - val_mae: 0.4714\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1308 - mae: 0.3134 - val_loss: 0.3713 - val_mae: 0.4796\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1482 - mae: 0.3300 - val_loss: 0.3716 - val_mae: 0.4762\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1477 - mae: 0.3150 - val_loss: 0.3744 - val_mae: 0.4752\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1625 - mae: 0.3170 - val_loss: 0.4174 - val_mae: 0.5062\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1536 - mae: 0.3282 - val_loss: 0.3846 - val_mae: 0.4816\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1325 - mae: 0.3099 - val_loss: 0.3683 - val_mae: 0.4729\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1361 - mae: 0.3073 - val_loss: 0.3961 - val_mae: 0.4896\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1371 - mae: 0.3140 - val_loss: 0.3759 - val_mae: 0.4809\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1322 - mae: 0.3057 - val_loss: 0.3754 - val_mae: 0.4809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.8904 - mae: 1.0178 - val_loss: 2.5604 - val_mae: 1.4353\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9592 - mae: 0.7512 - val_loss: 1.1506 - val_mae: 0.8953\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7012 - mae: 0.6668 - val_loss: 0.6918 - val_mae: 0.6431\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6534 - mae: 0.6305 - val_loss: 0.5174 - val_mae: 0.5798\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5483 - mae: 0.6012 - val_loss: 0.5225 - val_mae: 0.5905\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4771 - mae: 0.5861 - val_loss: 0.4950 - val_mae: 0.5557\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5091 - mae: 0.5866 - val_loss: 0.4850 - val_mae: 0.5592\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4321 - mae: 0.5467 - val_loss: 0.4635 - val_mae: 0.5333\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3822 - mae: 0.5340 - val_loss: 0.4652 - val_mae: 0.5380\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.3877 - mae: 0.5198 - val_loss: 0.4486 - val_mae: 0.5242\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3356 - mae: 0.4839 - val_loss: 0.4798 - val_mae: 0.5461\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3246 - mae: 0.4834 - val_loss: 0.5014 - val_mae: 0.5613\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3327 - mae: 0.4887 - val_loss: 0.4541 - val_mae: 0.5337\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3194 - mae: 0.4756 - val_loss: 0.4869 - val_mae: 0.5565\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3123 - mae: 0.4748 - val_loss: 0.4703 - val_mae: 0.5390\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2673 - mae: 0.4428 - val_loss: 0.4782 - val_mae: 0.5439\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2675 - mae: 0.4508 - val_loss: 0.4468 - val_mae: 0.5220\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2593 - mae: 0.4295 - val_loss: 0.4534 - val_mae: 0.5207\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2629 - mae: 0.4277 - val_loss: 0.4332 - val_mae: 0.5158\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2681 - mae: 0.4342 - val_loss: 0.4541 - val_mae: 0.5310\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2313 - mae: 0.4094 - val_loss: 0.4563 - val_mae: 0.5292\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2369 - mae: 0.3976 - val_loss: 0.4276 - val_mae: 0.5024\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2993 - mae: 0.4491 - val_loss: 0.4686 - val_mae: 0.5328\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2572 - mae: 0.4307 - val_loss: 0.4290 - val_mae: 0.5090\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2123 - mae: 0.3891 - val_loss: 0.4393 - val_mae: 0.5117\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2705 - mae: 0.4316 - val_loss: 0.4755 - val_mae: 0.5400\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2217 - mae: 0.3973 - val_loss: 0.4486 - val_mae: 0.5219\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2216 - mae: 0.3955 - val_loss: 0.4370 - val_mae: 0.5104\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2168 - mae: 0.3981 - val_loss: 0.4360 - val_mae: 0.5122\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2096 - mae: 0.3727 - val_loss: 0.4196 - val_mae: 0.5009\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1949 - mae: 0.3755 - val_loss: 0.4350 - val_mae: 0.5112\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1992 - mae: 0.3748 - val_loss: 0.4131 - val_mae: 0.4961\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1702 - mae: 0.3503 - val_loss: 0.4380 - val_mae: 0.5103\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1766 - mae: 0.3583 - val_loss: 0.4425 - val_mae: 0.5176\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1807 - mae: 0.3536 - val_loss: 0.4195 - val_mae: 0.5035\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1621 - mae: 0.3363 - val_loss: 0.4269 - val_mae: 0.5110\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1804 - mae: 0.3527 - val_loss: 0.4632 - val_mae: 0.5387\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1745 - mae: 0.3517 - val_loss: 0.4307 - val_mae: 0.5076\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1837 - mae: 0.3651 - val_loss: 0.4287 - val_mae: 0.5040\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1677 - mae: 0.3382 - val_loss: 0.4433 - val_mae: 0.5137\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1596 - mae: 0.3412 - val_loss: 0.4499 - val_mae: 0.5199\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1586 - mae: 0.3442 - val_loss: 0.4091 - val_mae: 0.5009\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1599 - mae: 0.3311 - val_loss: 0.4358 - val_mae: 0.5163\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1565 - mae: 0.3359 - val_loss: 0.4141 - val_mae: 0.5020\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1425 - mae: 0.3150 - val_loss: 0.4221 - val_mae: 0.5086\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1396 - mae: 0.3068 - val_loss: 0.4374 - val_mae: 0.5131\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1403 - mae: 0.3167 - val_loss: 0.4201 - val_mae: 0.5062\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1749 - mae: 0.3212 - val_loss: 0.4394 - val_mae: 0.5169\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1477 - mae: 0.3108 - val_loss: 0.4599 - val_mae: 0.5327\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1410 - mae: 0.3059 - val_loss: 0.4179 - val_mae: 0.5066\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 4.3156 - mae: 1.8252 - val_loss: 2.1645 - val_mae: 1.3241\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9568 - mae: 0.8033 - val_loss: 0.8846 - val_mae: 0.7746\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7318 - mae: 0.6956 - val_loss: 0.5487 - val_mae: 0.5949\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6050 - mae: 0.6336 - val_loss: 0.4301 - val_mae: 0.5328\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5193 - mae: 0.5982 - val_loss: 0.4525 - val_mae: 0.5401\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4814 - mae: 0.6018 - val_loss: 0.4040 - val_mae: 0.5115\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4893 - mae: 0.5816 - val_loss: 0.4035 - val_mae: 0.5083\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4483 - mae: 0.5581 - val_loss: 0.4008 - val_mae: 0.5034\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3921 - mae: 0.5289 - val_loss: 0.4068 - val_mae: 0.5089\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4264 - mae: 0.5243 - val_loss: 0.4268 - val_mae: 0.5255\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3411 - mae: 0.4886 - val_loss: 0.3965 - val_mae: 0.5006\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3004 - mae: 0.4853 - val_loss: 0.4200 - val_mae: 0.5230\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3144 - mae: 0.4810 - val_loss: 0.4082 - val_mae: 0.5127\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3026 - mae: 0.4772 - val_loss: 0.4111 - val_mae: 0.5125\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2955 - mae: 0.4517 - val_loss: 0.4284 - val_mae: 0.5236\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3015 - mae: 0.4545 - val_loss: 0.4286 - val_mae: 0.5193\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2786 - mae: 0.4455 - val_loss: 0.4199 - val_mae: 0.5134\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2938 - mae: 0.4329 - val_loss: 0.4440 - val_mae: 0.5291\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2849 - mae: 0.4541 - val_loss: 0.4412 - val_mae: 0.5302\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2665 - mae: 0.4364 - val_loss: 0.4358 - val_mae: 0.5256\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2326 - mae: 0.4073 - val_loss: 0.4503 - val_mae: 0.5371\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2151 - mae: 0.4024 - val_loss: 0.4374 - val_mae: 0.5200\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2260 - mae: 0.4099 - val_loss: 0.4038 - val_mae: 0.4995\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2034 - mae: 0.3927 - val_loss: 0.4249 - val_mae: 0.5131\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1832 - mae: 0.3640 - val_loss: 0.4261 - val_mae: 0.5122\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1873 - mae: 0.3686 - val_loss: 0.4254 - val_mae: 0.5076\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2202 - mae: 0.3875 - val_loss: 0.4591 - val_mae: 0.5336\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1974 - mae: 0.3834 - val_loss: 0.4223 - val_mae: 0.5157\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1968 - mae: 0.3729 - val_loss: 0.4217 - val_mae: 0.5090\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1849 - mae: 0.3785 - val_loss: 0.4595 - val_mae: 0.5294\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1862 - mae: 0.3653 - val_loss: 0.4526 - val_mae: 0.5263\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1749 - mae: 0.3554 - val_loss: 0.4255 - val_mae: 0.5109\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1883 - mae: 0.3584 - val_loss: 0.4425 - val_mae: 0.5182\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1740 - mae: 0.3508 - val_loss: 0.4312 - val_mae: 0.5157\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1503 - mae: 0.3430 - val_loss: 0.4290 - val_mae: 0.5146\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1583 - mae: 0.3346 - val_loss: 0.4437 - val_mae: 0.5244\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1335 - mae: 0.3201 - val_loss: 0.4223 - val_mae: 0.5064\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1355 - mae: 0.3125 - val_loss: 0.4061 - val_mae: 0.4982\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1370 - mae: 0.3075 - val_loss: 0.4083 - val_mae: 0.4967\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1699 - mae: 0.3301 - val_loss: 0.3986 - val_mae: 0.4936\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1576 - mae: 0.3236 - val_loss: 0.4191 - val_mae: 0.5059\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1480 - mae: 0.3245 - val_loss: 0.4459 - val_mae: 0.5202\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1591 - mae: 0.3393 - val_loss: 0.4233 - val_mae: 0.5073\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1491 - mae: 0.3230 - val_loss: 0.4227 - val_mae: 0.5057\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1297 - mae: 0.3092 - val_loss: 0.4289 - val_mae: 0.5058\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1231 - mae: 0.2952 - val_loss: 0.4024 - val_mae: 0.4949\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1322 - mae: 0.2976 - val_loss: 0.4182 - val_mae: 0.4997\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1218 - mae: 0.2917 - val_loss: 0.4005 - val_mae: 0.4878\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1329 - mae: 0.3070 - val_loss: 0.4158 - val_mae: 0.5014\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1242 - mae: 0.2928 - val_loss: 0.4150 - val_mae: 0.5011\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4539 - mae: 0.5106\n",
            "Test MAE for TS: 0.5171229243278503\n",
            "Training model for ID...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 6.2046 - mae: 2.3767 - val_loss: 3.9661 - val_mae: 1.8601\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3269 - mae: 0.9485 - val_loss: 1.6878 - val_mae: 1.1695\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0848 - mae: 0.8390 - val_loss: 0.8807 - val_mae: 0.7981\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8148 - mae: 0.7300 - val_loss: 0.6255 - val_mae: 0.6490\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7516 - mae: 0.7364 - val_loss: 0.4593 - val_mae: 0.5327\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7889 - mae: 0.7054 - val_loss: 0.4512 - val_mae: 0.5257\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5652 - mae: 0.6562 - val_loss: 0.4565 - val_mae: 0.5192\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6039 - mae: 0.6435 - val_loss: 0.4283 - val_mae: 0.5097\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.5862 - mae: 0.6171 - val_loss: 0.4036 - val_mae: 0.4964\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5068 - mae: 0.5894 - val_loss: 0.5000 - val_mae: 0.5516\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4681 - mae: 0.5752 - val_loss: 0.4495 - val_mae: 0.5214\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4170 - mae: 0.5569 - val_loss: 0.4769 - val_mae: 0.5375\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4649 - mae: 0.5593 - val_loss: 0.4830 - val_mae: 0.5441\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4096 - mae: 0.5566 - val_loss: 0.4469 - val_mae: 0.5322\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3447 - mae: 0.5043 - val_loss: 0.4551 - val_mae: 0.5297\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3568 - mae: 0.5115 - val_loss: 0.4061 - val_mae: 0.5024\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3026 - mae: 0.4842 - val_loss: 0.4191 - val_mae: 0.5080\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3260 - mae: 0.4843 - val_loss: 0.5315 - val_mae: 0.5719\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3666 - mae: 0.5155 - val_loss: 0.4281 - val_mae: 0.5124\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3178 - mae: 0.4787 - val_loss: 0.4516 - val_mae: 0.5307\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3088 - mae: 0.4752 - val_loss: 0.4423 - val_mae: 0.5199\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2867 - mae: 0.4576 - val_loss: 0.4790 - val_mae: 0.5488\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2893 - mae: 0.4543 - val_loss: 0.4772 - val_mae: 0.5481\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2956 - mae: 0.4488 - val_loss: 0.4622 - val_mae: 0.5356\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2980 - mae: 0.4653 - val_loss: 0.4672 - val_mae: 0.5394\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2634 - mae: 0.4435 - val_loss: 0.5018 - val_mae: 0.5622\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2540 - mae: 0.4481 - val_loss: 0.4671 - val_mae: 0.5415\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2508 - mae: 0.4279 - val_loss: 0.5066 - val_mae: 0.5629\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2253 - mae: 0.4281 - val_loss: 0.4625 - val_mae: 0.5372\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2463 - mae: 0.4280 - val_loss: 0.4997 - val_mae: 0.5561\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2398 - mae: 0.4286 - val_loss: 0.4448 - val_mae: 0.5186\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2363 - mae: 0.4111 - val_loss: 0.4513 - val_mae: 0.5260\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2396 - mae: 0.4157 - val_loss: 0.4793 - val_mae: 0.5452\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1894 - mae: 0.3750 - val_loss: 0.4531 - val_mae: 0.5288\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2187 - mae: 0.3978 - val_loss: 0.5110 - val_mae: 0.5628\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2231 - mae: 0.3987 - val_loss: 0.4677 - val_mae: 0.5404\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2055 - mae: 0.3872 - val_loss: 0.4563 - val_mae: 0.5300\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2205 - mae: 0.3762 - val_loss: 0.4638 - val_mae: 0.5324\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2137 - mae: 0.3769 - val_loss: 0.4808 - val_mae: 0.5435\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1709 - mae: 0.3653 - val_loss: 0.4520 - val_mae: 0.5281\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1926 - mae: 0.3719 - val_loss: 0.4592 - val_mae: 0.5319\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1921 - mae: 0.3672 - val_loss: 0.4356 - val_mae: 0.5249\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2184 - mae: 0.3822 - val_loss: 0.4664 - val_mae: 0.5420\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1698 - mae: 0.3557 - val_loss: 0.4812 - val_mae: 0.5443\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1704 - mae: 0.3420 - val_loss: 0.5142 - val_mae: 0.5627\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1643 - mae: 0.3480 - val_loss: 0.4415 - val_mae: 0.5187\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1757 - mae: 0.3354 - val_loss: 0.4835 - val_mae: 0.5441\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1727 - mae: 0.3506 - val_loss: 0.4298 - val_mae: 0.5091\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1513 - mae: 0.3445 - val_loss: 0.4243 - val_mae: 0.5080\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1645 - mae: 0.3356 - val_loss: 0.4772 - val_mae: 0.5435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 5.3393 - mae: 2.2297 - val_loss: 3.3229 - val_mae: 1.6789\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.4319 - mae: 0.9902 - val_loss: 1.1738 - val_mae: 0.9353\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2226 - mae: 0.7887 - val_loss: 0.7713 - val_mae: 0.7215\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8076 - mae: 0.7539 - val_loss: 0.6702 - val_mae: 0.6573\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8322 - mae: 0.7138 - val_loss: 0.5156 - val_mae: 0.5629\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7947 - mae: 0.7062 - val_loss: 0.5134 - val_mae: 0.5581\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7181 - mae: 0.6818 - val_loss: 0.5150 - val_mae: 0.5551\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5535 - mae: 0.6358 - val_loss: 0.5196 - val_mae: 0.5537\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5726 - mae: 0.6305 - val_loss: 0.5397 - val_mae: 0.5636\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5357 - mae: 0.5987 - val_loss: 0.6202 - val_mae: 0.6194\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4675 - mae: 0.5877 - val_loss: 0.5877 - val_mae: 0.5921\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5583 - mae: 0.6070 - val_loss: 0.4966 - val_mae: 0.5528\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4969 - mae: 0.5891 - val_loss: 0.5189 - val_mae: 0.5598\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4289 - mae: 0.5548 - val_loss: 0.4838 - val_mae: 0.5398\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4586 - mae: 0.5485 - val_loss: 0.5414 - val_mae: 0.5730\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4467 - mae: 0.5457 - val_loss: 0.5074 - val_mae: 0.5569\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3466 - mae: 0.5199 - val_loss: 0.5298 - val_mae: 0.5629\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4080 - mae: 0.5343 - val_loss: 0.5001 - val_mae: 0.5539\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4795 - mae: 0.5083 - val_loss: 0.5092 - val_mae: 0.5591\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3227 - mae: 0.4952 - val_loss: 0.4693 - val_mae: 0.5315\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3182 - mae: 0.4871 - val_loss: 0.5386 - val_mae: 0.5639\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3058 - mae: 0.4829 - val_loss: 0.4881 - val_mae: 0.5379\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3961 - mae: 0.5452 - val_loss: 0.4564 - val_mae: 0.5260\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3146 - mae: 0.4677 - val_loss: 0.4297 - val_mae: 0.5068\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2970 - mae: 0.4586 - val_loss: 0.4705 - val_mae: 0.5339\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2723 - mae: 0.4537 - val_loss: 0.4714 - val_mae: 0.5390\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2749 - mae: 0.4407 - val_loss: 0.4420 - val_mae: 0.5092\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3012 - mae: 0.4459 - val_loss: 0.4595 - val_mae: 0.5231\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2476 - mae: 0.4301 - val_loss: 0.4854 - val_mae: 0.5405\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2392 - mae: 0.4320 - val_loss: 0.4350 - val_mae: 0.5092\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2342 - mae: 0.4316 - val_loss: 0.4648 - val_mae: 0.5267\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2366 - mae: 0.4344 - val_loss: 0.4449 - val_mae: 0.5093\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2585 - mae: 0.4097 - val_loss: 0.4604 - val_mae: 0.5212\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2410 - mae: 0.4159 - val_loss: 0.5661 - val_mae: 0.5874\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2918 - mae: 0.4283 - val_loss: 0.4505 - val_mae: 0.5139\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2003 - mae: 0.3929 - val_loss: 0.4661 - val_mae: 0.5206\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2276 - mae: 0.4124 - val_loss: 0.4489 - val_mae: 0.5107\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2094 - mae: 0.3894 - val_loss: 0.4750 - val_mae: 0.5284\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1891 - mae: 0.3888 - val_loss: 0.4388 - val_mae: 0.5124\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2546 - mae: 0.4113 - val_loss: 0.5057 - val_mae: 0.5481\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2134 - mae: 0.3986 - val_loss: 0.4719 - val_mae: 0.5299\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1814 - mae: 0.3712 - val_loss: 0.4544 - val_mae: 0.5183\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1875 - mae: 0.3681 - val_loss: 0.4475 - val_mae: 0.5167\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1908 - mae: 0.3808 - val_loss: 0.4381 - val_mae: 0.5082\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1860 - mae: 0.3885 - val_loss: 0.4411 - val_mae: 0.5181\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1997 - mae: 0.3734 - val_loss: 0.4273 - val_mae: 0.5082\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1733 - mae: 0.3644 - val_loss: 0.4491 - val_mae: 0.5200\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2051 - mae: 0.3768 - val_loss: 0.4465 - val_mae: 0.5169\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1802 - mae: 0.3562 - val_loss: 0.4473 - val_mae: 0.5183\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1764 - mae: 0.3641 - val_loss: 0.4670 - val_mae: 0.5322\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.2544 - mae: 1.9103 - val_loss: 2.4880 - val_mae: 1.4383\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.6626 - mae: 0.9211 - val_loss: 0.7141 - val_mae: 0.7052\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1211 - mae: 0.8163 - val_loss: 0.4466 - val_mae: 0.5380\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9339 - mae: 0.7514 - val_loss: 0.3455 - val_mae: 0.4729\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8171 - mae: 0.6975 - val_loss: 0.3467 - val_mae: 0.4671\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9341 - mae: 0.6926 - val_loss: 0.4347 - val_mae: 0.5163\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7201 - mae: 0.6691 - val_loss: 0.4121 - val_mae: 0.4997\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5839 - mae: 0.6316 - val_loss: 0.3831 - val_mae: 0.4904\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5581 - mae: 0.6038 - val_loss: 0.4258 - val_mae: 0.5171\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5101 - mae: 0.6175 - val_loss: 0.3772 - val_mae: 0.4783\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4770 - mae: 0.5663 - val_loss: 0.4026 - val_mae: 0.4987\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.4636 - mae: 0.5626 - val_loss: 0.4156 - val_mae: 0.5050\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4159 - mae: 0.5625 - val_loss: 0.4489 - val_mae: 0.5249\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4124 - mae: 0.5531 - val_loss: 0.4219 - val_mae: 0.5111\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5162 - mae: 0.5714 - val_loss: 0.4364 - val_mae: 0.5212\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4355 - mae: 0.5293 - val_loss: 0.4720 - val_mae: 0.5406\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3820 - mae: 0.5201 - val_loss: 0.3933 - val_mae: 0.4939\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3847 - mae: 0.4999 - val_loss: 0.4065 - val_mae: 0.5053\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3414 - mae: 0.5310 - val_loss: 0.4220 - val_mae: 0.5141\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3178 - mae: 0.4989 - val_loss: 0.5003 - val_mae: 0.5668\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4350 - mae: 0.6062 - val_loss: 0.4176 - val_mae: 0.5161\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3359 - mae: 0.4880 - val_loss: 0.4301 - val_mae: 0.5300\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4043 - mae: 0.5138 - val_loss: 0.4033 - val_mae: 0.5077\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2975 - mae: 0.4743 - val_loss: 0.3800 - val_mae: 0.4892\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3525 - mae: 0.4894 - val_loss: 0.4002 - val_mae: 0.4995\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2795 - mae: 0.4617 - val_loss: 0.3898 - val_mae: 0.4919\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3061 - mae: 0.4687 - val_loss: 0.4066 - val_mae: 0.5108\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2824 - mae: 0.4528 - val_loss: 0.3951 - val_mae: 0.4964\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3025 - mae: 0.4529 - val_loss: 0.3978 - val_mae: 0.4983\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2776 - mae: 0.4419 - val_loss: 0.3973 - val_mae: 0.4957\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2579 - mae: 0.4343 - val_loss: 0.3922 - val_mae: 0.4869\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2442 - mae: 0.4272 - val_loss: 0.4305 - val_mae: 0.5179\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2325 - mae: 0.4224 - val_loss: 0.3886 - val_mae: 0.4880\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2803 - mae: 0.4165 - val_loss: 0.4001 - val_mae: 0.4964\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2409 - mae: 0.4340 - val_loss: 0.4096 - val_mae: 0.5000\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2742 - mae: 0.4366 - val_loss: 0.4003 - val_mae: 0.4921\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2100 - mae: 0.4130 - val_loss: 0.3840 - val_mae: 0.4834\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2176 - mae: 0.4170 - val_loss: 0.3617 - val_mae: 0.4695\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2307 - mae: 0.3964 - val_loss: 0.3751 - val_mae: 0.4735\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2112 - mae: 0.3971 - val_loss: 0.3680 - val_mae: 0.4736\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2261 - mae: 0.4037 - val_loss: 0.3924 - val_mae: 0.4838\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2133 - mae: 0.3815 - val_loss: 0.3787 - val_mae: 0.4772\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1877 - mae: 0.3812 - val_loss: 0.3822 - val_mae: 0.4795\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1763 - mae: 0.3779 - val_loss: 0.3707 - val_mae: 0.4731\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1916 - mae: 0.3778 - val_loss: 0.4081 - val_mae: 0.5048\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2278 - mae: 0.3799 - val_loss: 0.3728 - val_mae: 0.4691\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1812 - mae: 0.3690 - val_loss: 0.3776 - val_mae: 0.4706\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1872 - mae: 0.3745 - val_loss: 0.4033 - val_mae: 0.4936\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1989 - mae: 0.3708 - val_loss: 0.4029 - val_mae: 0.4893\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1654 - mae: 0.3522 - val_loss: 0.3823 - val_mae: 0.4803\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 4.9512 - mae: 2.1392 - val_loss: 2.8471 - val_mae: 1.5337\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1684 - mae: 0.8421 - val_loss: 1.1129 - val_mae: 0.8921\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9047 - mae: 0.7556 - val_loss: 0.5919 - val_mae: 0.6057\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8614 - mae: 0.6766 - val_loss: 0.3970 - val_mae: 0.4988\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7089 - mae: 0.6922 - val_loss: 0.3865 - val_mae: 0.4974\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7766 - mae: 0.6764 - val_loss: 0.4591 - val_mae: 0.5410\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5513 - mae: 0.6218 - val_loss: 0.4714 - val_mae: 0.5410\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5722 - mae: 0.6310 - val_loss: 0.4514 - val_mae: 0.5304\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5240 - mae: 0.5976 - val_loss: 0.4747 - val_mae: 0.5393\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4520 - mae: 0.5661 - val_loss: 0.4705 - val_mae: 0.5349\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4258 - mae: 0.5483 - val_loss: 0.5349 - val_mae: 0.5763\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4027 - mae: 0.5474 - val_loss: 0.5192 - val_mae: 0.5629\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4120 - mae: 0.5522 - val_loss: 0.4991 - val_mae: 0.5366\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3904 - mae: 0.5140 - val_loss: 0.5264 - val_mae: 0.5663\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3701 - mae: 0.5297 - val_loss: 0.6200 - val_mae: 0.6227\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3681 - mae: 0.5264 - val_loss: 0.4791 - val_mae: 0.5424\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3333 - mae: 0.4983 - val_loss: 0.4657 - val_mae: 0.5454\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3531 - mae: 0.4736 - val_loss: 0.4680 - val_mae: 0.5457\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3072 - mae: 0.4971 - val_loss: 0.4972 - val_mae: 0.5618\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3816 - mae: 0.5133 - val_loss: 0.5250 - val_mae: 0.5717\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3339 - mae: 0.4767 - val_loss: 0.4324 - val_mae: 0.5254\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3293 - mae: 0.4823 - val_loss: 0.4433 - val_mae: 0.5254\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2729 - mae: 0.4587 - val_loss: 0.4286 - val_mae: 0.5159\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3227 - mae: 0.4580 - val_loss: 0.4440 - val_mae: 0.5300\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2590 - mae: 0.4533 - val_loss: 0.4388 - val_mae: 0.5233\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3169 - mae: 0.4754 - val_loss: 0.4252 - val_mae: 0.5096\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2817 - mae: 0.4341 - val_loss: 0.4616 - val_mae: 0.5335\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2689 - mae: 0.4439 - val_loss: 0.4423 - val_mae: 0.5188\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2770 - mae: 0.4501 - val_loss: 0.4501 - val_mae: 0.5237\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2638 - mae: 0.4341 - val_loss: 0.4534 - val_mae: 0.5237\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2311 - mae: 0.4157 - val_loss: 0.4269 - val_mae: 0.5077\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2330 - mae: 0.4090 - val_loss: 0.4465 - val_mae: 0.5325\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3146 - mae: 0.4837 - val_loss: 0.4486 - val_mae: 0.5276\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2564 - mae: 0.4294 - val_loss: 0.4552 - val_mae: 0.5281\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2370 - mae: 0.4103 - val_loss: 0.4256 - val_mae: 0.5067\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2509 - mae: 0.4198 - val_loss: 0.4529 - val_mae: 0.5279\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2285 - mae: 0.4082 - val_loss: 0.4792 - val_mae: 0.5434\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2205 - mae: 0.4043 - val_loss: 0.4381 - val_mae: 0.5157\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2104 - mae: 0.4018 - val_loss: 0.4681 - val_mae: 0.5359\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2044 - mae: 0.3941 - val_loss: 0.4425 - val_mae: 0.5188\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1918 - mae: 0.3792 - val_loss: 0.4207 - val_mae: 0.4993\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1790 - mae: 0.3745 - val_loss: 0.4273 - val_mae: 0.5087\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1751 - mae: 0.3705 - val_loss: 0.4823 - val_mae: 0.5434\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1882 - mae: 0.3790 - val_loss: 0.4620 - val_mae: 0.5209\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1843 - mae: 0.3677 - val_loss: 0.4424 - val_mae: 0.5092\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1857 - mae: 0.3727 - val_loss: 0.4519 - val_mae: 0.5130\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1725 - mae: 0.3536 - val_loss: 0.5032 - val_mae: 0.5492\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1814 - mae: 0.3548 - val_loss: 0.4379 - val_mae: 0.5127\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1866 - mae: 0.3537 - val_loss: 0.4302 - val_mae: 0.5054\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1994 - mae: 0.3641 - val_loss: 0.4363 - val_mae: 0.5080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 7.8166 - mae: 2.5048 - val_loss: 5.0643 - val_mae: 2.0978\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6668 - mae: 1.1475 - val_loss: 2.4110 - val_mae: 1.3871\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0475 - mae: 0.8824 - val_loss: 1.1331 - val_mae: 0.9238\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.9774 - mae: 0.8185 - val_loss: 0.7104 - val_mae: 0.7048\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8330 - mae: 0.7641 - val_loss: 0.4687 - val_mae: 0.5493\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7648 - mae: 0.7005 - val_loss: 0.4422 - val_mae: 0.5255\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6776 - mae: 0.6788 - val_loss: 0.4153 - val_mae: 0.5063\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6907 - mae: 0.6538 - val_loss: 0.4595 - val_mae: 0.5367\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6463 - mae: 0.6514 - val_loss: 0.5053 - val_mae: 0.5579\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5174 - mae: 0.6076 - val_loss: 0.4443 - val_mae: 0.5290\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5674 - mae: 0.6249 - val_loss: 0.5202 - val_mae: 0.5695\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.4668 - mae: 0.5927 - val_loss: 0.4575 - val_mae: 0.5345\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5799 - mae: 0.6140 - val_loss: 0.4299 - val_mae: 0.5201\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4935 - mae: 0.5653 - val_loss: 0.4537 - val_mae: 0.5353\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4422 - mae: 0.5425 - val_loss: 0.4608 - val_mae: 0.5415\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3862 - mae: 0.5643 - val_loss: 0.4530 - val_mae: 0.5357\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4192 - mae: 0.5359 - val_loss: 0.4198 - val_mae: 0.5100\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3705 - mae: 0.5224 - val_loss: 0.4554 - val_mae: 0.5340\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3797 - mae: 0.5291 - val_loss: 0.4540 - val_mae: 0.5332\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3516 - mae: 0.5248 - val_loss: 0.4154 - val_mae: 0.5078\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3639 - mae: 0.5229 - val_loss: 0.4644 - val_mae: 0.5357\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3031 - mae: 0.4934 - val_loss: 0.4426 - val_mae: 0.5216\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3102 - mae: 0.4889 - val_loss: 0.4690 - val_mae: 0.5451\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2885 - mae: 0.4919 - val_loss: 0.3990 - val_mae: 0.4910\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3058 - mae: 0.4700 - val_loss: 0.3770 - val_mae: 0.4840\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3252 - mae: 0.4865 - val_loss: 0.3953 - val_mae: 0.4941\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2750 - mae: 0.4590 - val_loss: 0.4240 - val_mae: 0.5117\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3148 - mae: 0.4686 - val_loss: 0.4362 - val_mae: 0.5174\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2471 - mae: 0.4588 - val_loss: 0.4429 - val_mae: 0.5285\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2689 - mae: 0.4541 - val_loss: 0.4271 - val_mae: 0.5144\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2804 - mae: 0.4483 - val_loss: 0.4442 - val_mae: 0.5250\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2471 - mae: 0.4496 - val_loss: 0.4046 - val_mae: 0.5010\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2075 - mae: 0.4149 - val_loss: 0.4110 - val_mae: 0.5035\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2315 - mae: 0.4317 - val_loss: 0.3916 - val_mae: 0.4886\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2920 - mae: 0.4382 - val_loss: 0.4436 - val_mae: 0.5269\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2525 - mae: 0.4355 - val_loss: 0.4350 - val_mae: 0.5218\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2236 - mae: 0.4260 - val_loss: 0.4756 - val_mae: 0.5459\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2180 - mae: 0.4211 - val_loss: 0.4151 - val_mae: 0.4997\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2115 - mae: 0.4065 - val_loss: 0.4276 - val_mae: 0.5163\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2055 - mae: 0.4111 - val_loss: 0.4280 - val_mae: 0.5111\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2202 - mae: 0.4358 - val_loss: 0.4312 - val_mae: 0.5140\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1991 - mae: 0.4047 - val_loss: 0.3972 - val_mae: 0.4882\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2904 - mae: 0.4279 - val_loss: 0.4587 - val_mae: 0.5301\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2492 - mae: 0.4325 - val_loss: 0.4444 - val_mae: 0.5156\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2477 - mae: 0.4348 - val_loss: 0.4548 - val_mae: 0.5258\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1881 - mae: 0.3898 - val_loss: 0.4912 - val_mae: 0.5519\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1833 - mae: 0.3873 - val_loss: 0.4184 - val_mae: 0.5001\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1899 - mae: 0.3832 - val_loss: 0.4207 - val_mae: 0.4995\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2234 - mae: 0.4029 - val_loss: 0.4438 - val_mae: 0.5229\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1919 - mae: 0.3899 - val_loss: 0.4364 - val_mae: 0.5167\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4434 - mae: 0.5201\n",
            "Test MAE for ID: 0.5520631670951843\n",
            "Training model for CS/PD...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 5.0446 - mae: 1.9937 - val_loss: 2.3567 - val_mae: 1.3906\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2522 - mae: 0.8830 - val_loss: 1.1869 - val_mae: 0.9350\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8842 - mae: 0.7620 - val_loss: 0.5822 - val_mae: 0.6224\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7991 - mae: 0.7107 - val_loss: 0.4683 - val_mae: 0.5467\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6483 - mae: 0.6518 - val_loss: 0.3864 - val_mae: 0.4780\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5550 - mae: 0.6312 - val_loss: 0.4000 - val_mae: 0.4889\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5051 - mae: 0.5883 - val_loss: 0.3989 - val_mae: 0.4862\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4839 - mae: 0.5928 - val_loss: 0.4677 - val_mae: 0.5360\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4473 - mae: 0.5733 - val_loss: 0.4513 - val_mae: 0.5252\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3502 - mae: 0.5174 - val_loss: 0.4388 - val_mae: 0.5053\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4037 - mae: 0.5328 - val_loss: 0.4251 - val_mae: 0.4992\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4020 - mae: 0.5380 - val_loss: 0.4722 - val_mae: 0.5289\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3658 - mae: 0.5145 - val_loss: 0.4488 - val_mae: 0.5049\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3153 - mae: 0.4953 - val_loss: 0.4067 - val_mae: 0.4865\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3097 - mae: 0.4774 - val_loss: 0.4106 - val_mae: 0.4849\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2982 - mae: 0.4444 - val_loss: 0.4088 - val_mae: 0.4850\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2867 - mae: 0.4575 - val_loss: 0.3922 - val_mae: 0.4765\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2893 - mae: 0.4618 - val_loss: 0.4063 - val_mae: 0.4817\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2676 - mae: 0.4394 - val_loss: 0.3892 - val_mae: 0.4767\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2865 - mae: 0.4487 - val_loss: 0.4194 - val_mae: 0.4896\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2529 - mae: 0.4353 - val_loss: 0.4361 - val_mae: 0.4969\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2675 - mae: 0.4357 - val_loss: 0.4000 - val_mae: 0.4759\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2346 - mae: 0.4220 - val_loss: 0.4005 - val_mae: 0.4732\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2341 - mae: 0.4098 - val_loss: 0.4027 - val_mae: 0.4766\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2393 - mae: 0.4164 - val_loss: 0.4153 - val_mae: 0.4793\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2262 - mae: 0.4066 - val_loss: 0.4390 - val_mae: 0.4970\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2037 - mae: 0.3863 - val_loss: 0.4261 - val_mae: 0.4915\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2033 - mae: 0.3863 - val_loss: 0.4006 - val_mae: 0.4798\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1904 - mae: 0.3684 - val_loss: 0.4044 - val_mae: 0.4789\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1734 - mae: 0.3521 - val_loss: 0.4328 - val_mae: 0.4992\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1929 - mae: 0.3752 - val_loss: 0.3841 - val_mae: 0.4671\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1653 - mae: 0.3393 - val_loss: 0.4024 - val_mae: 0.4820\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1812 - mae: 0.3595 - val_loss: 0.3989 - val_mae: 0.4744\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1609 - mae: 0.3407 - val_loss: 0.4093 - val_mae: 0.4766\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1795 - mae: 0.3531 - val_loss: 0.4105 - val_mae: 0.4777\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1482 - mae: 0.3317 - val_loss: 0.3868 - val_mae: 0.4653\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1670 - mae: 0.3462 - val_loss: 0.4014 - val_mae: 0.4752\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1447 - mae: 0.3286 - val_loss: 0.4165 - val_mae: 0.4779\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1631 - mae: 0.3361 - val_loss: 0.4184 - val_mae: 0.4804\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1612 - mae: 0.3308 - val_loss: 0.4180 - val_mae: 0.4806\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1413 - mae: 0.3173 - val_loss: 0.4095 - val_mae: 0.4785\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1335 - mae: 0.3087 - val_loss: 0.4060 - val_mae: 0.4707\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1333 - mae: 0.3110 - val_loss: 0.4145 - val_mae: 0.4793\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1268 - mae: 0.3019 - val_loss: 0.4091 - val_mae: 0.4682\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1307 - mae: 0.3034 - val_loss: 0.4016 - val_mae: 0.4752\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1298 - mae: 0.3006 - val_loss: 0.3994 - val_mae: 0.4727\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1301 - mae: 0.2913 - val_loss: 0.4313 - val_mae: 0.4846\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1341 - mae: 0.3031 - val_loss: 0.3827 - val_mae: 0.4562\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1255 - mae: 0.2989 - val_loss: 0.3996 - val_mae: 0.4689\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1265 - mae: 0.2982 - val_loss: 0.4470 - val_mae: 0.5037\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 7.2814 - mae: 2.4861 - val_loss: 2.3635 - val_mae: 1.4090\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1978 - mae: 0.9015 - val_loss: 0.9151 - val_mae: 0.7814\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8500 - mae: 0.7423 - val_loss: 0.5938 - val_mae: 0.6248\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6375 - mae: 0.6759 - val_loss: 0.4030 - val_mae: 0.4973\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6098 - mae: 0.6534 - val_loss: 0.3768 - val_mae: 0.4824\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5083 - mae: 0.6184 - val_loss: 0.3798 - val_mae: 0.4826\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4817 - mae: 0.5832 - val_loss: 0.4148 - val_mae: 0.4959\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4571 - mae: 0.5709 - val_loss: 0.4054 - val_mae: 0.4937\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4126 - mae: 0.5502 - val_loss: 0.3983 - val_mae: 0.4917\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4296 - mae: 0.5493 - val_loss: 0.3726 - val_mae: 0.4706\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3735 - mae: 0.5158 - val_loss: 0.3977 - val_mae: 0.4778\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3457 - mae: 0.5026 - val_loss: 0.3893 - val_mae: 0.4699\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3425 - mae: 0.4844 - val_loss: 0.3589 - val_mae: 0.4552\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3210 - mae: 0.4859 - val_loss: 0.3618 - val_mae: 0.4561\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3330 - mae: 0.4799 - val_loss: 0.3849 - val_mae: 0.4661\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2653 - mae: 0.4451 - val_loss: 0.3720 - val_mae: 0.4595\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2825 - mae: 0.4384 - val_loss: 0.3827 - val_mae: 0.4631\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2838 - mae: 0.4392 - val_loss: 0.3635 - val_mae: 0.4566\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2239 - mae: 0.4140 - val_loss: 0.4089 - val_mae: 0.4818\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2541 - mae: 0.4345 - val_loss: 0.4146 - val_mae: 0.4909\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2592 - mae: 0.4348 - val_loss: 0.3849 - val_mae: 0.4725\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2337 - mae: 0.4109 - val_loss: 0.3755 - val_mae: 0.4609\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2173 - mae: 0.4101 - val_loss: 0.4018 - val_mae: 0.4721\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2070 - mae: 0.3893 - val_loss: 0.3734 - val_mae: 0.4520\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1894 - mae: 0.3861 - val_loss: 0.3860 - val_mae: 0.4663\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1839 - mae: 0.3637 - val_loss: 0.3796 - val_mae: 0.4614\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1773 - mae: 0.3639 - val_loss: 0.3831 - val_mae: 0.4642\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1644 - mae: 0.3519 - val_loss: 0.4094 - val_mae: 0.4717\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1586 - mae: 0.3535 - val_loss: 0.3954 - val_mae: 0.4693\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1893 - mae: 0.3648 - val_loss: 0.3918 - val_mae: 0.4643\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1722 - mae: 0.3587 - val_loss: 0.3881 - val_mae: 0.4669\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1816 - mae: 0.3581 - val_loss: 0.3907 - val_mae: 0.4677\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1651 - mae: 0.3446 - val_loss: 0.3805 - val_mae: 0.4665\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1466 - mae: 0.3286 - val_loss: 0.3660 - val_mae: 0.4557\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1655 - mae: 0.3408 - val_loss: 0.3837 - val_mae: 0.4710\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1423 - mae: 0.3244 - val_loss: 0.3891 - val_mae: 0.4652\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1577 - mae: 0.3432 - val_loss: 0.3835 - val_mae: 0.4677\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1402 - mae: 0.3259 - val_loss: 0.3876 - val_mae: 0.4657\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1377 - mae: 0.3340 - val_loss: 0.3864 - val_mae: 0.4664\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1284 - mae: 0.3014 - val_loss: 0.3929 - val_mae: 0.4652\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1262 - mae: 0.3002 - val_loss: 0.3901 - val_mae: 0.4675\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1205 - mae: 0.3116 - val_loss: 0.3916 - val_mae: 0.4648\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1361 - mae: 0.3123 - val_loss: 0.4228 - val_mae: 0.4755\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1407 - mae: 0.3056 - val_loss: 0.3856 - val_mae: 0.4670\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1249 - mae: 0.3015 - val_loss: 0.3882 - val_mae: 0.4618\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1120 - mae: 0.2826 - val_loss: 0.3815 - val_mae: 0.4609\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1026 - mae: 0.2860 - val_loss: 0.3718 - val_mae: 0.4539\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1084 - mae: 0.2873 - val_loss: 0.3729 - val_mae: 0.4560\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1040 - mae: 0.2688 - val_loss: 0.3887 - val_mae: 0.4580\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1083 - mae: 0.2834 - val_loss: 0.4370 - val_mae: 0.4829\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 7.1344 - mae: 2.6023 - val_loss: 2.0887 - val_mae: 1.3352\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3067 - mae: 0.9359 - val_loss: 0.7487 - val_mae: 0.7379\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9816 - mae: 0.7783 - val_loss: 0.4433 - val_mae: 0.5159\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7491 - mae: 0.6800 - val_loss: 0.3695 - val_mae: 0.4503\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5999 - mae: 0.6347 - val_loss: 0.3852 - val_mae: 0.4854\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5552 - mae: 0.6058 - val_loss: 0.3929 - val_mae: 0.5033\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4825 - mae: 0.5814 - val_loss: 0.4107 - val_mae: 0.5176\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4706 - mae: 0.5942 - val_loss: 0.3911 - val_mae: 0.5091\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4123 - mae: 0.5379 - val_loss: 0.3887 - val_mae: 0.4995\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4187 - mae: 0.5479 - val_loss: 0.3647 - val_mae: 0.4871\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3856 - mae: 0.5267 - val_loss: 0.3792 - val_mae: 0.4914\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3483 - mae: 0.5225 - val_loss: 0.3643 - val_mae: 0.4793\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3287 - mae: 0.5002 - val_loss: 0.3626 - val_mae: 0.4771\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3504 - mae: 0.4991 - val_loss: 0.3804 - val_mae: 0.4961\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3142 - mae: 0.4822 - val_loss: 0.3769 - val_mae: 0.4863\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2912 - mae: 0.4708 - val_loss: 0.3888 - val_mae: 0.4950\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2968 - mae: 0.4777 - val_loss: 0.3818 - val_mae: 0.4887\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2913 - mae: 0.4748 - val_loss: 0.3738 - val_mae: 0.4823\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2652 - mae: 0.4521 - val_loss: 0.3552 - val_mae: 0.4721\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2723 - mae: 0.4566 - val_loss: 0.3486 - val_mae: 0.4630\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2305 - mae: 0.4078 - val_loss: 0.3558 - val_mae: 0.4655\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2356 - mae: 0.4115 - val_loss: 0.3714 - val_mae: 0.4787\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2093 - mae: 0.4011 - val_loss: 0.3735 - val_mae: 0.4753\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2210 - mae: 0.4076 - val_loss: 0.3540 - val_mae: 0.4620\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1964 - mae: 0.3816 - val_loss: 0.3534 - val_mae: 0.4627\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2281 - mae: 0.4215 - val_loss: 0.3423 - val_mae: 0.4592\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2094 - mae: 0.4018 - val_loss: 0.3326 - val_mae: 0.4525\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2017 - mae: 0.3898 - val_loss: 0.3236 - val_mae: 0.4420\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1915 - mae: 0.3817 - val_loss: 0.3483 - val_mae: 0.4527\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2082 - mae: 0.3895 - val_loss: 0.3373 - val_mae: 0.4531\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2449 - mae: 0.4213 - val_loss: 0.3368 - val_mae: 0.4486\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2035 - mae: 0.3941 - val_loss: 0.3609 - val_mae: 0.4623\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1806 - mae: 0.3761 - val_loss: 0.3811 - val_mae: 0.4775\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1775 - mae: 0.3707 - val_loss: 0.3175 - val_mae: 0.4380\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1850 - mae: 0.3734 - val_loss: 0.3365 - val_mae: 0.4489\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1649 - mae: 0.3477 - val_loss: 0.3331 - val_mae: 0.4448\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1728 - mae: 0.3495 - val_loss: 0.3852 - val_mae: 0.4795\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1786 - mae: 0.3786 - val_loss: 0.3501 - val_mae: 0.4546\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1674 - mae: 0.3463 - val_loss: 0.3484 - val_mae: 0.4536\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1559 - mae: 0.3376 - val_loss: 0.3602 - val_mae: 0.4600\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1383 - mae: 0.3289 - val_loss: 0.3505 - val_mae: 0.4570\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1516 - mae: 0.3388 - val_loss: 0.3513 - val_mae: 0.4551\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1264 - mae: 0.3095 - val_loss: 0.3351 - val_mae: 0.4464\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1407 - mae: 0.3269 - val_loss: 0.3304 - val_mae: 0.4434\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1445 - mae: 0.3291 - val_loss: 0.3648 - val_mae: 0.4610\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1389 - mae: 0.3175 - val_loss: 0.3460 - val_mae: 0.4521\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1278 - mae: 0.3123 - val_loss: 0.3583 - val_mae: 0.4567\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1126 - mae: 0.2971 - val_loss: 0.3443 - val_mae: 0.4484\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1143 - mae: 0.3006 - val_loss: 0.3403 - val_mae: 0.4465\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1335 - mae: 0.3056 - val_loss: 0.3422 - val_mae: 0.4499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 3.1913 - mae: 1.5569 - val_loss: 1.3040 - val_mae: 0.9865\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9169 - mae: 0.7895 - val_loss: 0.5202 - val_mae: 0.5779\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7302 - mae: 0.7005 - val_loss: 0.4624 - val_mae: 0.4812\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6071 - mae: 0.6500 - val_loss: 0.4644 - val_mae: 0.4946\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5656 - mae: 0.5991 - val_loss: 0.4097 - val_mae: 0.4916\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4810 - mae: 0.5767 - val_loss: 0.4189 - val_mae: 0.5027\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4210 - mae: 0.5726 - val_loss: 0.4186 - val_mae: 0.5054\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4044 - mae: 0.5459 - val_loss: 0.3974 - val_mae: 0.4864\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4247 - mae: 0.5333 - val_loss: 0.4054 - val_mae: 0.4892\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3591 - mae: 0.5272 - val_loss: 0.4127 - val_mae: 0.4960\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3849 - mae: 0.5244 - val_loss: 0.3897 - val_mae: 0.4731\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3202 - mae: 0.4962 - val_loss: 0.3657 - val_mae: 0.4628\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3222 - mae: 0.4802 - val_loss: 0.3889 - val_mae: 0.4846\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2837 - mae: 0.4606 - val_loss: 0.3888 - val_mae: 0.4762\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2673 - mae: 0.4454 - val_loss: 0.3926 - val_mae: 0.4722\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2799 - mae: 0.4612 - val_loss: 0.3881 - val_mae: 0.4798\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3608 - mae: 0.5108 - val_loss: 0.4154 - val_mae: 0.5002\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2826 - mae: 0.4595 - val_loss: 0.4187 - val_mae: 0.4799\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2822 - mae: 0.4610 - val_loss: 0.3910 - val_mae: 0.4757\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2483 - mae: 0.4332 - val_loss: 0.3658 - val_mae: 0.4635\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2549 - mae: 0.4180 - val_loss: 0.3844 - val_mae: 0.4716\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2302 - mae: 0.4132 - val_loss: 0.3740 - val_mae: 0.4728\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2086 - mae: 0.3985 - val_loss: 0.3953 - val_mae: 0.4759\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2224 - mae: 0.3963 - val_loss: 0.3761 - val_mae: 0.4663\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2142 - mae: 0.3984 - val_loss: 0.3700 - val_mae: 0.4623\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2081 - mae: 0.3895 - val_loss: 0.3569 - val_mae: 0.4608\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1829 - mae: 0.3674 - val_loss: 0.3724 - val_mae: 0.4637\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2018 - mae: 0.3831 - val_loss: 0.3733 - val_mae: 0.4665\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1885 - mae: 0.3711 - val_loss: 0.3998 - val_mae: 0.4742\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1807 - mae: 0.3699 - val_loss: 0.3715 - val_mae: 0.4628\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2489 - mae: 0.4355 - val_loss: 0.4178 - val_mae: 0.4881\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2045 - mae: 0.3863 - val_loss: 0.3796 - val_mae: 0.4749\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2120 - mae: 0.3831 - val_loss: 0.3777 - val_mae: 0.4730\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1926 - mae: 0.3855 - val_loss: 0.3694 - val_mae: 0.4655\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1625 - mae: 0.3426 - val_loss: 0.3614 - val_mae: 0.4627\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1554 - mae: 0.3416 - val_loss: 0.3727 - val_mae: 0.4605\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1598 - mae: 0.3490 - val_loss: 0.3629 - val_mae: 0.4612\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1699 - mae: 0.3607 - val_loss: 0.3716 - val_mae: 0.4598\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1510 - mae: 0.3394 - val_loss: 0.3749 - val_mae: 0.4630\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1616 - mae: 0.3380 - val_loss: 0.3854 - val_mae: 0.4700\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1476 - mae: 0.3325 - val_loss: 0.3807 - val_mae: 0.4631\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1363 - mae: 0.3231 - val_loss: 0.3589 - val_mae: 0.4618\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1508 - mae: 0.3331 - val_loss: 0.3663 - val_mae: 0.4587\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1296 - mae: 0.3130 - val_loss: 0.3778 - val_mae: 0.4660\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1190 - mae: 0.3035 - val_loss: 0.3786 - val_mae: 0.4642\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1362 - mae: 0.3241 - val_loss: 0.3665 - val_mae: 0.4570\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1205 - mae: 0.2958 - val_loss: 0.3684 - val_mae: 0.4639\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1233 - mae: 0.3115 - val_loss: 0.3644 - val_mae: 0.4558\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1096 - mae: 0.2895 - val_loss: 0.3682 - val_mae: 0.4591\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1208 - mae: 0.3025 - val_loss: 0.3784 - val_mae: 0.4665\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 2.2343 - mae: 1.1294 - val_loss: 2.3633 - val_mae: 1.3673\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.8259 - mae: 0.7300 - val_loss: 0.9045 - val_mae: 0.7348\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7326 - mae: 0.6753 - val_loss: 0.5944 - val_mae: 0.6160\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5583 - mae: 0.6227 - val_loss: 0.4679 - val_mae: 0.5537\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5206 - mae: 0.5901 - val_loss: 0.4811 - val_mae: 0.5498\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5053 - mae: 0.5942 - val_loss: 0.4533 - val_mae: 0.5273\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4112 - mae: 0.5426 - val_loss: 0.5254 - val_mae: 0.5679\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4412 - mae: 0.5539 - val_loss: 0.4700 - val_mae: 0.5404\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3381 - mae: 0.5040 - val_loss: 0.4378 - val_mae: 0.5176\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3502 - mae: 0.5054 - val_loss: 0.4865 - val_mae: 0.5407\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3845 - mae: 0.5341 - val_loss: 0.4744 - val_mae: 0.5284\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3299 - mae: 0.4847 - val_loss: 0.4336 - val_mae: 0.5103\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3253 - mae: 0.4784 - val_loss: 0.4522 - val_mae: 0.5263\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3090 - mae: 0.4770 - val_loss: 0.4398 - val_mae: 0.5179\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2841 - mae: 0.4608 - val_loss: 0.4773 - val_mae: 0.5450\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2931 - mae: 0.4793 - val_loss: 0.4464 - val_mae: 0.5213\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2725 - mae: 0.4432 - val_loss: 0.4554 - val_mae: 0.5227\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2873 - mae: 0.4290 - val_loss: 0.4413 - val_mae: 0.5146\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2233 - mae: 0.4058 - val_loss: 0.4128 - val_mae: 0.5009\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2338 - mae: 0.4125 - val_loss: 0.4277 - val_mae: 0.5080\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2160 - mae: 0.4039 - val_loss: 0.4423 - val_mae: 0.5194\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2014 - mae: 0.3936 - val_loss: 0.4783 - val_mae: 0.5365\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2036 - mae: 0.4042 - val_loss: 0.4540 - val_mae: 0.5244\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2028 - mae: 0.3916 - val_loss: 0.4446 - val_mae: 0.5191\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2025 - mae: 0.3982 - val_loss: 0.4165 - val_mae: 0.5060\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1961 - mae: 0.3795 - val_loss: 0.4273 - val_mae: 0.5140\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2213 - mae: 0.4104 - val_loss: 0.4594 - val_mae: 0.5315\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1962 - mae: 0.3849 - val_loss: 0.4327 - val_mae: 0.5106\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1829 - mae: 0.3684 - val_loss: 0.4645 - val_mae: 0.5334\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2140 - mae: 0.3927 - val_loss: 0.4198 - val_mae: 0.5048\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1943 - mae: 0.3851 - val_loss: 0.4179 - val_mae: 0.5072\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2431 - mae: 0.4308 - val_loss: 0.4302 - val_mae: 0.5043\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1915 - mae: 0.3747 - val_loss: 0.4391 - val_mae: 0.5123\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1929 - mae: 0.3741 - val_loss: 0.4183 - val_mae: 0.4937\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1745 - mae: 0.3579 - val_loss: 0.4326 - val_mae: 0.5071\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1674 - mae: 0.3566 - val_loss: 0.4126 - val_mae: 0.4925\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1569 - mae: 0.3333 - val_loss: 0.4256 - val_mae: 0.5006\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1483 - mae: 0.3405 - val_loss: 0.4144 - val_mae: 0.4947\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1394 - mae: 0.3139 - val_loss: 0.3985 - val_mae: 0.4814\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1464 - mae: 0.3291 - val_loss: 0.4434 - val_mae: 0.5127\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1482 - mae: 0.3197 - val_loss: 0.4158 - val_mae: 0.4972\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1450 - mae: 0.3164 - val_loss: 0.4064 - val_mae: 0.4914\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1314 - mae: 0.3122 - val_loss: 0.4382 - val_mae: 0.5067\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1358 - mae: 0.2977 - val_loss: 0.4168 - val_mae: 0.4964\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1517 - mae: 0.3386 - val_loss: 0.4364 - val_mae: 0.5082\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1374 - mae: 0.3158 - val_loss: 0.4238 - val_mae: 0.4988\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1208 - mae: 0.3077 - val_loss: 0.4309 - val_mae: 0.4985\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1149 - mae: 0.2959 - val_loss: 0.4607 - val_mae: 0.5205\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1192 - mae: 0.2996 - val_loss: 0.4097 - val_mae: 0.4865\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1253 - mae: 0.3038 - val_loss: 0.4394 - val_mae: 0.5042\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4395 - mae: 0.4978\n",
            "Test MAE for CS/PD: 0.5135272741317749\n",
            "Training model for Coh...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 3.9806 - mae: 1.7766 - val_loss: 2.4818 - val_mae: 1.4803\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9889 - mae: 0.8323 - val_loss: 1.3245 - val_mae: 1.0322\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8091 - mae: 0.7405 - val_loss: 0.6839 - val_mae: 0.6789\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6142 - mae: 0.6785 - val_loss: 0.6610 - val_mae: 0.6719\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5927 - mae: 0.6533 - val_loss: 0.4424 - val_mae: 0.5519\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5596 - mae: 0.6097 - val_loss: 0.4151 - val_mae: 0.5178\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4413 - mae: 0.5852 - val_loss: 0.3496 - val_mae: 0.4764\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4163 - mae: 0.5631 - val_loss: 0.3006 - val_mae: 0.4387\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4376 - mae: 0.5446 - val_loss: 0.3891 - val_mae: 0.4893\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4266 - mae: 0.5578 - val_loss: 0.3534 - val_mae: 0.4708\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3270 - mae: 0.5166 - val_loss: 0.3241 - val_mae: 0.4511\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3546 - mae: 0.5432 - val_loss: 0.3751 - val_mae: 0.4837\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3650 - mae: 0.5549 - val_loss: 0.3444 - val_mae: 0.4614\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3093 - mae: 0.5143 - val_loss: 0.3705 - val_mae: 0.4823\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3002 - mae: 0.4935 - val_loss: 0.3362 - val_mae: 0.4612\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2594 - mae: 0.4634 - val_loss: 0.3307 - val_mae: 0.4532\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3021 - mae: 0.4782 - val_loss: 0.3144 - val_mae: 0.4412\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2855 - mae: 0.4510 - val_loss: 0.3362 - val_mae: 0.4593\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2761 - mae: 0.4519 - val_loss: 0.3119 - val_mae: 0.4461\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2438 - mae: 0.4423 - val_loss: 0.3261 - val_mae: 0.4522\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3044 - mae: 0.4538 - val_loss: 0.2991 - val_mae: 0.4363\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2407 - mae: 0.4261 - val_loss: 0.3054 - val_mae: 0.4463\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2356 - mae: 0.4338 - val_loss: 0.3226 - val_mae: 0.4418\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2254 - mae: 0.4278 - val_loss: 0.2967 - val_mae: 0.4354\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2121 - mae: 0.4211 - val_loss: 0.2945 - val_mae: 0.4364\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2147 - mae: 0.4233 - val_loss: 0.2970 - val_mae: 0.4361\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2713 - mae: 0.4165 - val_loss: 0.3083 - val_mae: 0.4446\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2171 - mae: 0.4078 - val_loss: 0.2776 - val_mae: 0.4247\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1878 - mae: 0.3861 - val_loss: 0.3170 - val_mae: 0.4524\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1824 - mae: 0.4006 - val_loss: 0.2860 - val_mae: 0.4229\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2021 - mae: 0.3838 - val_loss: 0.3062 - val_mae: 0.4384\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2042 - mae: 0.3730 - val_loss: 0.3000 - val_mae: 0.4349\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1777 - mae: 0.3786 - val_loss: 0.2640 - val_mae: 0.4111\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1882 - mae: 0.3702 - val_loss: 0.2679 - val_mae: 0.4101\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1711 - mae: 0.3618 - val_loss: 0.3254 - val_mae: 0.4456\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1783 - mae: 0.3723 - val_loss: 0.2712 - val_mae: 0.4104\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1685 - mae: 0.3518 - val_loss: 0.2705 - val_mae: 0.4063\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1637 - mae: 0.3456 - val_loss: 0.2911 - val_mae: 0.4274\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1537 - mae: 0.3551 - val_loss: 0.2733 - val_mae: 0.4139\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1558 - mae: 0.3425 - val_loss: 0.2940 - val_mae: 0.4297\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1309 - mae: 0.3461 - val_loss: 0.2763 - val_mae: 0.4116\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1474 - mae: 0.3464 - val_loss: 0.2833 - val_mae: 0.4200\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1293 - mae: 0.3324 - val_loss: 0.2640 - val_mae: 0.4060\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1650 - mae: 0.3495 - val_loss: 0.2758 - val_mae: 0.4159\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1433 - mae: 0.3450 - val_loss: 0.2866 - val_mae: 0.4258\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1348 - mae: 0.3246 - val_loss: 0.2945 - val_mae: 0.4284\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1326 - mae: 0.3359 - val_loss: 0.2957 - val_mae: 0.4317\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1260 - mae: 0.3257 - val_loss: 0.2817 - val_mae: 0.4239\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1471 - mae: 0.3211 - val_loss: 0.3608 - val_mae: 0.4598\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1351 - mae: 0.3356 - val_loss: 0.2943 - val_mae: 0.4265\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 3.7692 - mae: 1.5031 - val_loss: 1.0377 - val_mae: 0.8917\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2052 - mae: 0.8525 - val_loss: 0.2900 - val_mae: 0.4450\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.9306 - mae: 0.7805 - val_loss: 0.3866 - val_mae: 0.5068\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6474 - mae: 0.6932 - val_loss: 0.3407 - val_mae: 0.4812\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5660 - mae: 0.6488 - val_loss: 0.3490 - val_mae: 0.4703\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5249 - mae: 0.6260 - val_loss: 0.3276 - val_mae: 0.4634\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4992 - mae: 0.5981 - val_loss: 0.3181 - val_mae: 0.4565\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5049 - mae: 0.5904 - val_loss: 0.3529 - val_mae: 0.4762\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4376 - mae: 0.5635 - val_loss: 0.3715 - val_mae: 0.4909\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4287 - mae: 0.5794 - val_loss: 0.3234 - val_mae: 0.4590\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4133 - mae: 0.5423 - val_loss: 0.3269 - val_mae: 0.4635\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3552 - mae: 0.5368 - val_loss: 0.2966 - val_mae: 0.4386\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3817 - mae: 0.5156 - val_loss: 0.3274 - val_mae: 0.4579\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3463 - mae: 0.5048 - val_loss: 0.3669 - val_mae: 0.4814\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2810 - mae: 0.4771 - val_loss: 0.3458 - val_mae: 0.4717\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3131 - mae: 0.4892 - val_loss: 0.3497 - val_mae: 0.4775\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2710 - mae: 0.4729 - val_loss: 0.3061 - val_mae: 0.4503\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2690 - mae: 0.4609 - val_loss: 0.3642 - val_mae: 0.4832\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2884 - mae: 0.4790 - val_loss: 0.2994 - val_mae: 0.4453\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1884 - mae: 0.4429 - val_loss: 0.3928 - val_mae: 0.5017\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2487 - mae: 0.4421 - val_loss: 0.3057 - val_mae: 0.4450\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2704 - mae: 0.4489 - val_loss: 0.3022 - val_mae: 0.4363\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2557 - mae: 0.4461 - val_loss: 0.3201 - val_mae: 0.4583\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2466 - mae: 0.4523 - val_loss: 0.3306 - val_mae: 0.4600\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2317 - mae: 0.4284 - val_loss: 0.2927 - val_mae: 0.4267\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2465 - mae: 0.4351 - val_loss: 0.2966 - val_mae: 0.4285\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2390 - mae: 0.4414 - val_loss: 0.3314 - val_mae: 0.4656\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2160 - mae: 0.4168 - val_loss: 0.2933 - val_mae: 0.4411\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2285 - mae: 0.4041 - val_loss: 0.3124 - val_mae: 0.4540\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2006 - mae: 0.4008 - val_loss: 0.3043 - val_mae: 0.4455\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2163 - mae: 0.4122 - val_loss: 0.2801 - val_mae: 0.4306\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2046 - mae: 0.3893 - val_loss: 0.2867 - val_mae: 0.4315\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1690 - mae: 0.3843 - val_loss: 0.3050 - val_mae: 0.4479\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1893 - mae: 0.3899 - val_loss: 0.3270 - val_mae: 0.4606\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1777 - mae: 0.4010 - val_loss: 0.2942 - val_mae: 0.4318\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1683 - mae: 0.3843 - val_loss: 0.2995 - val_mae: 0.4338\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1633 - mae: 0.3603 - val_loss: 0.3054 - val_mae: 0.4364\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1984 - mae: 0.3794 - val_loss: 0.2966 - val_mae: 0.4331\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1431 - mae: 0.3579 - val_loss: 0.3211 - val_mae: 0.4398\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1814 - mae: 0.3556 - val_loss: 0.3233 - val_mae: 0.4490\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1405 - mae: 0.3518 - val_loss: 0.3141 - val_mae: 0.4417\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1323 - mae: 0.3477 - val_loss: 0.2839 - val_mae: 0.4228\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1506 - mae: 0.3393 - val_loss: 0.2952 - val_mae: 0.4375\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1351 - mae: 0.3383 - val_loss: 0.2914 - val_mae: 0.4224\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1525 - mae: 0.3435 - val_loss: 0.3151 - val_mae: 0.4432\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1297 - mae: 0.3402 - val_loss: 0.3026 - val_mae: 0.4300\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.1415 - mae: 0.3433 - val_loss: 0.2991 - val_mae: 0.4275\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1348 - mae: 0.3297 - val_loss: 0.2937 - val_mae: 0.4242\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1482 - mae: 0.3366 - val_loss: 0.3201 - val_mae: 0.4472\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1141 - mae: 0.3221 - val_loss: 0.2892 - val_mae: 0.4185\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.6912 - mae: 1.7018 - val_loss: 1.6200 - val_mae: 1.1775\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1552 - mae: 0.9387 - val_loss: 0.6225 - val_mae: 0.6478\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8024 - mae: 0.7767 - val_loss: 0.4350 - val_mae: 0.5374\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6291 - mae: 0.6737 - val_loss: 0.3773 - val_mae: 0.5103\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5183 - mae: 0.6331 - val_loss: 0.4122 - val_mae: 0.5321\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4513 - mae: 0.6128 - val_loss: 0.2899 - val_mae: 0.4267\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4564 - mae: 0.5996 - val_loss: 0.3244 - val_mae: 0.4532\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.4454 - mae: 0.5825 - val_loss: 0.3010 - val_mae: 0.4319\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3735 - mae: 0.5259 - val_loss: 0.3146 - val_mae: 0.4435\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3600 - mae: 0.5108 - val_loss: 0.3261 - val_mae: 0.4476\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3853 - mae: 0.5389 - val_loss: 0.2885 - val_mae: 0.4144\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2972 - mae: 0.4989 - val_loss: 0.3492 - val_mae: 0.4661\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3088 - mae: 0.5006 - val_loss: 0.3062 - val_mae: 0.4305\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3027 - mae: 0.4966 - val_loss: 0.3178 - val_mae: 0.4472\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4125 - mae: 0.6439 - val_loss: 0.2912 - val_mae: 0.4392\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3120 - mae: 0.4936 - val_loss: 0.3410 - val_mae: 0.4624\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3122 - mae: 0.4799 - val_loss: 0.3047 - val_mae: 0.4361\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2719 - mae: 0.4597 - val_loss: 0.2846 - val_mae: 0.4094\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3025 - mae: 0.4700 - val_loss: 0.3174 - val_mae: 0.4438\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2346 - mae: 0.4395 - val_loss: 0.2780 - val_mae: 0.4153\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2366 - mae: 0.4340 - val_loss: 0.3447 - val_mae: 0.4668\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2422 - mae: 0.4426 - val_loss: 0.3137 - val_mae: 0.4414\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2447 - mae: 0.4468 - val_loss: 0.3001 - val_mae: 0.4305\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2178 - mae: 0.4069 - val_loss: 0.3106 - val_mae: 0.4401\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2191 - mae: 0.4116 - val_loss: 0.2687 - val_mae: 0.4111\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2950 - mae: 0.4324 - val_loss: 0.2949 - val_mae: 0.4283\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2337 - mae: 0.4005 - val_loss: 0.2865 - val_mae: 0.4214\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1872 - mae: 0.4151 - val_loss: 0.2908 - val_mae: 0.4312\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1766 - mae: 0.3898 - val_loss: 0.2905 - val_mae: 0.4303\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2214 - mae: 0.3996 - val_loss: 0.2839 - val_mae: 0.4211\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1877 - mae: 0.3766 - val_loss: 0.2764 - val_mae: 0.4193\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2371 - mae: 0.3914 - val_loss: 0.2712 - val_mae: 0.4109\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1828 - mae: 0.3738 - val_loss: 0.2739 - val_mae: 0.4131\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1597 - mae: 0.3773 - val_loss: 0.2896 - val_mae: 0.4251\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1737 - mae: 0.3897 - val_loss: 0.3038 - val_mae: 0.4320\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1715 - mae: 0.3735 - val_loss: 0.2683 - val_mae: 0.4068\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1915 - mae: 0.3818 - val_loss: 0.3325 - val_mae: 0.4573\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1793 - mae: 0.3662 - val_loss: 0.2731 - val_mae: 0.4094\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1783 - mae: 0.3481 - val_loss: 0.2874 - val_mae: 0.4242\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1967 - mae: 0.3595 - val_loss: 0.2803 - val_mae: 0.4174\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1593 - mae: 0.3563 - val_loss: 0.2814 - val_mae: 0.4182\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1532 - mae: 0.3517 - val_loss: 0.2686 - val_mae: 0.4040\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1694 - mae: 0.3522 - val_loss: 0.2757 - val_mae: 0.4122\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1402 - mae: 0.3405 - val_loss: 0.2679 - val_mae: 0.4076\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1481 - mae: 0.3489 - val_loss: 0.2745 - val_mae: 0.4119\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1447 - mae: 0.3319 - val_loss: 0.2779 - val_mae: 0.4106\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1366 - mae: 0.3234 - val_loss: 0.2716 - val_mae: 0.4090\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1360 - mae: 0.3282 - val_loss: 0.2774 - val_mae: 0.4084\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1474 - mae: 0.3271 - val_loss: 0.2796 - val_mae: 0.4096\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1394 - mae: 0.3315 - val_loss: 0.2831 - val_mae: 0.4122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 2.9111 - mae: 1.4040 - val_loss: 1.2959 - val_mae: 1.0136\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1394 - mae: 0.7898 - val_loss: 0.3205 - val_mae: 0.4231\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8669 - mae: 0.7690 - val_loss: 0.3030 - val_mae: 0.4575\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7953 - mae: 0.6662 - val_loss: 0.2932 - val_mae: 0.4451\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6704 - mae: 0.6482 - val_loss: 0.3384 - val_mae: 0.4736\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5235 - mae: 0.5915 - val_loss: 0.4082 - val_mae: 0.5159\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5075 - mae: 0.5860 - val_loss: 0.4349 - val_mae: 0.5303\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5273 - mae: 0.5954 - val_loss: 0.3686 - val_mae: 0.4885\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.4632 - mae: 0.5680 - val_loss: 0.3485 - val_mae: 0.4735\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4352 - mae: 0.5328 - val_loss: 0.4828 - val_mae: 0.5577\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3822 - mae: 0.5348 - val_loss: 0.4087 - val_mae: 0.5131\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3279 - mae: 0.5133 - val_loss: 0.3757 - val_mae: 0.4813\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3735 - mae: 0.5241 - val_loss: 0.3441 - val_mae: 0.4681\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3256 - mae: 0.4998 - val_loss: 0.3868 - val_mae: 0.4892\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4055 - mae: 0.5013 - val_loss: 0.3589 - val_mae: 0.4801\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3438 - mae: 0.4956 - val_loss: 0.3662 - val_mae: 0.4815\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2952 - mae: 0.4749 - val_loss: 0.3816 - val_mae: 0.4929\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2926 - mae: 0.4675 - val_loss: 0.3768 - val_mae: 0.4932\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2932 - mae: 0.4770 - val_loss: 0.3078 - val_mae: 0.4524\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2805 - mae: 0.4443 - val_loss: 0.3376 - val_mae: 0.4623\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2523 - mae: 0.4567 - val_loss: 0.3656 - val_mae: 0.4820\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2585 - mae: 0.4318 - val_loss: 0.3553 - val_mae: 0.4710\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2564 - mae: 0.4259 - val_loss: 0.3196 - val_mae: 0.4514\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2585 - mae: 0.4383 - val_loss: 0.3252 - val_mae: 0.4583\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2613 - mae: 0.4373 - val_loss: 0.3144 - val_mae: 0.4497\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2281 - mae: 0.4135 - val_loss: 0.3297 - val_mae: 0.4536\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2040 - mae: 0.3994 - val_loss: 0.3111 - val_mae: 0.4461\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2605 - mae: 0.4087 - val_loss: 0.3424 - val_mae: 0.4577\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2141 - mae: 0.4130 - val_loss: 0.2908 - val_mae: 0.4309\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2187 - mae: 0.4009 - val_loss: 0.2972 - val_mae: 0.4311\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1966 - mae: 0.3890 - val_loss: 0.2868 - val_mae: 0.4233\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1910 - mae: 0.3788 - val_loss: 0.2825 - val_mae: 0.4215\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1933 - mae: 0.3795 - val_loss: 0.2905 - val_mae: 0.4256\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1846 - mae: 0.3801 - val_loss: 0.3008 - val_mae: 0.4296\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1874 - mae: 0.3880 - val_loss: 0.2894 - val_mae: 0.4231\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2361 - mae: 0.4129 - val_loss: 0.3288 - val_mae: 0.4522\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2042 - mae: 0.4018 - val_loss: 0.2939 - val_mae: 0.4275\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1884 - mae: 0.3792 - val_loss: 0.2702 - val_mae: 0.4084\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2117 - mae: 0.3848 - val_loss: 0.2909 - val_mae: 0.4205\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1612 - mae: 0.3685 - val_loss: 0.2645 - val_mae: 0.4031\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1713 - mae: 0.3582 - val_loss: 0.2768 - val_mae: 0.4159\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1860 - mae: 0.3634 - val_loss: 0.2839 - val_mae: 0.4217\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1503 - mae: 0.3550 - val_loss: 0.2732 - val_mae: 0.4096\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1398 - mae: 0.3374 - val_loss: 0.2700 - val_mae: 0.4063\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1533 - mae: 0.3509 - val_loss: 0.2681 - val_mae: 0.4110\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1338 - mae: 0.3334 - val_loss: 0.2807 - val_mae: 0.4144\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1515 - mae: 0.3431 - val_loss: 0.2623 - val_mae: 0.3997\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1378 - mae: 0.3219 - val_loss: 0.2856 - val_mae: 0.4175\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1521 - mae: 0.3420 - val_loss: 0.3076 - val_mae: 0.4379\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1502 - mae: 0.3434 - val_loss: 0.2848 - val_mae: 0.4190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.9672 - mae: 1.5647 - val_loss: 1.2851 - val_mae: 1.0246\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.0734 - mae: 0.8716 - val_loss: 0.4329 - val_mae: 0.5317\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7433 - mae: 0.7416 - val_loss: 0.3654 - val_mae: 0.5015\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5729 - mae: 0.6593 - val_loss: 0.4006 - val_mae: 0.5127\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.6066 - mae: 0.6622 - val_loss: 0.3583 - val_mae: 0.4754\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5438 - mae: 0.6521 - val_loss: 0.4295 - val_mae: 0.5208\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4262 - mae: 0.5879 - val_loss: 0.4537 - val_mae: 0.5336\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8465 - mae: 0.6979 - val_loss: 0.4052 - val_mae: 0.5084\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4998 - mae: 0.6056 - val_loss: 0.4165 - val_mae: 0.5075\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5232 - mae: 0.6333 - val_loss: 0.4935 - val_mae: 0.5654\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4736 - mae: 0.5829 - val_loss: 0.3586 - val_mae: 0.4721\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3624 - mae: 0.5455 - val_loss: 0.4314 - val_mae: 0.5184\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3861 - mae: 0.5630 - val_loss: 0.3795 - val_mae: 0.4820\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3510 - mae: 0.5163 - val_loss: 0.3258 - val_mae: 0.4485\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3406 - mae: 0.4995 - val_loss: 0.3135 - val_mae: 0.4347\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3971 - mae: 0.5039 - val_loss: 0.3390 - val_mae: 0.4533\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3065 - mae: 0.4924 - val_loss: 0.3424 - val_mae: 0.4541\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2928 - mae: 0.4715 - val_loss: 0.4019 - val_mae: 0.4995\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3959 - mae: 0.5111 - val_loss: 0.3524 - val_mae: 0.4587\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2494 - mae: 0.4855 - val_loss: 0.3088 - val_mae: 0.4245\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2784 - mae: 0.4642 - val_loss: 0.3015 - val_mae: 0.4241\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2335 - mae: 0.4370 - val_loss: 0.3221 - val_mae: 0.4363\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2602 - mae: 0.4462 - val_loss: 0.2842 - val_mae: 0.4122\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2404 - mae: 0.4355 - val_loss: 0.3222 - val_mae: 0.4419\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2547 - mae: 0.4505 - val_loss: 0.3099 - val_mae: 0.4322\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2154 - mae: 0.4218 - val_loss: 0.2927 - val_mae: 0.4180\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2083 - mae: 0.4109 - val_loss: 0.3300 - val_mae: 0.4483\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2244 - mae: 0.4343 - val_loss: 0.3027 - val_mae: 0.4283\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2083 - mae: 0.4218 - val_loss: 0.2939 - val_mae: 0.4212\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2215 - mae: 0.4080 - val_loss: 0.2983 - val_mae: 0.4244\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2065 - mae: 0.4166 - val_loss: 0.2838 - val_mae: 0.4154\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1922 - mae: 0.3891 - val_loss: 0.2916 - val_mae: 0.4256\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1994 - mae: 0.3900 - val_loss: 0.2760 - val_mae: 0.4139\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1927 - mae: 0.3924 - val_loss: 0.2786 - val_mae: 0.4149\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1784 - mae: 0.3867 - val_loss: 0.2838 - val_mae: 0.4178\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1909 - mae: 0.3952 - val_loss: 0.2894 - val_mae: 0.4206\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1952 - mae: 0.3772 - val_loss: 0.2946 - val_mae: 0.4199\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1772 - mae: 0.3786 - val_loss: 0.2784 - val_mae: 0.4137\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1746 - mae: 0.3804 - val_loss: 0.2786 - val_mae: 0.4143\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1508 - mae: 0.3692 - val_loss: 0.2888 - val_mae: 0.4255\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2316 - mae: 0.4433 - val_loss: 0.3266 - val_mae: 0.4516\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1850 - mae: 0.3885 - val_loss: 0.3063 - val_mae: 0.4417\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1773 - mae: 0.3771 - val_loss: 0.2732 - val_mae: 0.4142\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1748 - mae: 0.3790 - val_loss: 0.2990 - val_mae: 0.4289\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1641 - mae: 0.3624 - val_loss: 0.3020 - val_mae: 0.4305\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1757 - mae: 0.3619 - val_loss: 0.2917 - val_mae: 0.4282\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1505 - mae: 0.3487 - val_loss: 0.2702 - val_mae: 0.4060\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1577 - mae: 0.3466 - val_loss: 0.3020 - val_mae: 0.4366\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1512 - mae: 0.3451 - val_loss: 0.2844 - val_mae: 0.4188\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1282 - mae: 0.3382 - val_loss: 0.2721 - val_mae: 0.4080\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2505 - mae: 0.3803\n",
            "Test MAE for Coh: 0.3910144567489624\n",
            "Training model for Pa...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.4163 - mae: 1.1220 - val_loss: 0.4349 - val_mae: 0.5650\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6848 - mae: 0.6270 - val_loss: 0.3400 - val_mae: 0.4565\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.4734 - mae: 0.5159 - val_loss: 0.3051 - val_mae: 0.4315\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4182 - mae: 0.4978 - val_loss: 0.2890 - val_mae: 0.4391\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3931 - mae: 0.4888 - val_loss: 0.2955 - val_mae: 0.4471\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3785 - mae: 0.4694 - val_loss: 0.2941 - val_mae: 0.4514\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.3569 - mae: 0.4602 - val_loss: 0.3013 - val_mae: 0.4454\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3027 - mae: 0.4343 - val_loss: 0.3042 - val_mae: 0.4455\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2895 - mae: 0.4143 - val_loss: 0.3051 - val_mae: 0.4433\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2936 - mae: 0.4128 - val_loss: 0.3325 - val_mae: 0.4629\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2595 - mae: 0.3994 - val_loss: 0.3327 - val_mae: 0.4554\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2417 - mae: 0.3966 - val_loss: 0.3307 - val_mae: 0.4562\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2203 - mae: 0.3779 - val_loss: 0.3350 - val_mae: 0.4568\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2089 - mae: 0.3616 - val_loss: 0.3286 - val_mae: 0.4544\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1960 - mae: 0.3597 - val_loss: 0.3231 - val_mae: 0.4579\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1901 - mae: 0.3533 - val_loss: 0.3321 - val_mae: 0.4564\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1748 - mae: 0.3304 - val_loss: 0.3577 - val_mae: 0.4672\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1716 - mae: 0.3371 - val_loss: 0.3210 - val_mae: 0.4486\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1511 - mae: 0.3207 - val_loss: 0.3570 - val_mae: 0.4589\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1527 - mae: 0.3194 - val_loss: 0.3546 - val_mae: 0.4595\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1455 - mae: 0.3063 - val_loss: 0.3474 - val_mae: 0.4589\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1341 - mae: 0.3010 - val_loss: 0.3599 - val_mae: 0.4651\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1292 - mae: 0.2894 - val_loss: 0.3454 - val_mae: 0.4528\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1244 - mae: 0.2866 - val_loss: 0.3489 - val_mae: 0.4528\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1082 - mae: 0.2700 - val_loss: 0.3424 - val_mae: 0.4529\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1065 - mae: 0.2671 - val_loss: 0.3635 - val_mae: 0.4648\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1028 - mae: 0.2608 - val_loss: 0.3493 - val_mae: 0.4583\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1008 - mae: 0.2604 - val_loss: 0.3393 - val_mae: 0.4515\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1058 - mae: 0.2583 - val_loss: 0.3603 - val_mae: 0.4610\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0876 - mae: 0.2424 - val_loss: 0.3456 - val_mae: 0.4467\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0948 - mae: 0.2453 - val_loss: 0.3436 - val_mae: 0.4420\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0925 - mae: 0.2471 - val_loss: 0.3643 - val_mae: 0.4603\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0812 - mae: 0.2306 - val_loss: 0.3724 - val_mae: 0.4615\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0798 - mae: 0.2290 - val_loss: 0.3520 - val_mae: 0.4487\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0802 - mae: 0.2363 - val_loss: 0.3482 - val_mae: 0.4470\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0768 - mae: 0.2224 - val_loss: 0.3787 - val_mae: 0.4615\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0733 - mae: 0.2215 - val_loss: 0.3487 - val_mae: 0.4478\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0736 - mae: 0.2120 - val_loss: 0.3749 - val_mae: 0.4559\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0676 - mae: 0.2112 - val_loss: 0.3727 - val_mae: 0.4561\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0706 - mae: 0.2024 - val_loss: 0.3698 - val_mae: 0.4512\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0644 - mae: 0.2017 - val_loss: 0.3690 - val_mae: 0.4588\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0702 - mae: 0.2045 - val_loss: 0.4042 - val_mae: 0.4747\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0638 - mae: 0.2017 - val_loss: 0.3768 - val_mae: 0.4565\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0590 - mae: 0.1908 - val_loss: 0.3827 - val_mae: 0.4634\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0557 - mae: 0.1927 - val_loss: 0.3694 - val_mae: 0.4528\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0568 - mae: 0.1817 - val_loss: 0.3684 - val_mae: 0.4589\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0535 - mae: 0.1796 - val_loss: 0.3773 - val_mae: 0.4581\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0565 - mae: 0.1898 - val_loss: 0.3652 - val_mae: 0.4460\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0527 - mae: 0.1830 - val_loss: 0.3642 - val_mae: 0.4468\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0487 - mae: 0.1758 - val_loss: 0.3888 - val_mae: 0.4577\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 2.7296 - mae: 1.3072 - val_loss: 0.4869 - val_mae: 0.6016\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.6703 - mae: 0.6148 - val_loss: 0.3258 - val_mae: 0.4663\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5894 - mae: 0.5718 - val_loss: 0.2844 - val_mae: 0.4262\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4933 - mae: 0.5356 - val_loss: 0.2714 - val_mae: 0.4184\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3953 - mae: 0.4820 - val_loss: 0.2732 - val_mae: 0.4265\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4042 - mae: 0.4932 - val_loss: 0.2831 - val_mae: 0.4402\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3439 - mae: 0.4517 - val_loss: 0.2834 - val_mae: 0.4487\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3432 - mae: 0.4541 - val_loss: 0.2691 - val_mae: 0.4306\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3045 - mae: 0.4309 - val_loss: 0.3096 - val_mae: 0.4448\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2733 - mae: 0.4261 - val_loss: 0.2813 - val_mae: 0.4330\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2513 - mae: 0.4098 - val_loss: 0.3221 - val_mae: 0.4489\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2504 - mae: 0.4021 - val_loss: 0.3009 - val_mae: 0.4448\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2233 - mae: 0.3852 - val_loss: 0.3019 - val_mae: 0.4332\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2208 - mae: 0.3712 - val_loss: 0.2925 - val_mae: 0.4322\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2066 - mae: 0.3658 - val_loss: 0.3034 - val_mae: 0.4430\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1785 - mae: 0.3462 - val_loss: 0.3002 - val_mae: 0.4417\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1862 - mae: 0.3412 - val_loss: 0.3068 - val_mae: 0.4400\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1736 - mae: 0.3361 - val_loss: 0.3282 - val_mae: 0.4473\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1612 - mae: 0.3231 - val_loss: 0.3138 - val_mae: 0.4522\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1529 - mae: 0.3137 - val_loss: 0.3328 - val_mae: 0.4503\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1603 - mae: 0.3304 - val_loss: 0.3267 - val_mae: 0.4521\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1369 - mae: 0.3003 - val_loss: 0.3336 - val_mae: 0.4501\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1459 - mae: 0.3127 - val_loss: 0.3465 - val_mae: 0.4634\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1295 - mae: 0.2912 - val_loss: 0.3297 - val_mae: 0.4533\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1119 - mae: 0.2774 - val_loss: 0.3290 - val_mae: 0.4493\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1084 - mae: 0.2683 - val_loss: 0.3403 - val_mae: 0.4557\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1108 - mae: 0.2691 - val_loss: 0.3232 - val_mae: 0.4465\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1023 - mae: 0.2595 - val_loss: 0.3465 - val_mae: 0.4600\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1066 - mae: 0.2589 - val_loss: 0.3458 - val_mae: 0.4557\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0997 - mae: 0.2600 - val_loss: 0.3407 - val_mae: 0.4532\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0919 - mae: 0.2482 - val_loss: 0.3421 - val_mae: 0.4580\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0882 - mae: 0.2440 - val_loss: 0.3295 - val_mae: 0.4458\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0761 - mae: 0.2272 - val_loss: 0.3513 - val_mae: 0.4639\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0861 - mae: 0.2371 - val_loss: 0.3421 - val_mae: 0.4573\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0791 - mae: 0.2283 - val_loss: 0.3255 - val_mae: 0.4446\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0733 - mae: 0.2181 - val_loss: 0.3352 - val_mae: 0.4494\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0765 - mae: 0.2269 - val_loss: 0.3315 - val_mae: 0.4469\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0684 - mae: 0.2131 - val_loss: 0.3587 - val_mae: 0.4593\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0759 - mae: 0.2221 - val_loss: 0.3299 - val_mae: 0.4451\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0705 - mae: 0.2140 - val_loss: 0.3516 - val_mae: 0.4625\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0644 - mae: 0.2031 - val_loss: 0.3488 - val_mae: 0.4518\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0667 - mae: 0.2084 - val_loss: 0.3442 - val_mae: 0.4514\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0696 - mae: 0.2048 - val_loss: 0.3476 - val_mae: 0.4553\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0583 - mae: 0.1933 - val_loss: 0.3412 - val_mae: 0.4510\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0567 - mae: 0.1883 - val_loss: 0.3639 - val_mae: 0.4645\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0612 - mae: 0.1957 - val_loss: 0.3685 - val_mae: 0.4647\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0595 - mae: 0.1927 - val_loss: 0.3624 - val_mae: 0.4617\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0586 - mae: 0.1873 - val_loss: 0.3694 - val_mae: 0.4617\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0555 - mae: 0.1840 - val_loss: 0.3471 - val_mae: 0.4490\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0539 - mae: 0.1847 - val_loss: 0.3805 - val_mae: 0.4629\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.0257 - mae: 1.0884 - val_loss: 0.4059 - val_mae: 0.5484\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5902 - mae: 0.5888 - val_loss: 0.2788 - val_mae: 0.4143\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4968 - mae: 0.5344 - val_loss: 0.2728 - val_mae: 0.4237\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4204 - mae: 0.4931 - val_loss: 0.2998 - val_mae: 0.4533\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.3858 - mae: 0.4813 - val_loss: 0.3137 - val_mae: 0.4539\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3542 - mae: 0.4592 - val_loss: 0.3295 - val_mae: 0.4682\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3344 - mae: 0.4583 - val_loss: 0.3333 - val_mae: 0.4644\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.3016 - mae: 0.4272 - val_loss: 0.3017 - val_mae: 0.4461\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2969 - mae: 0.4250 - val_loss: 0.3329 - val_mae: 0.4618\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2746 - mae: 0.4150 - val_loss: 0.3090 - val_mae: 0.4491\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2364 - mae: 0.3962 - val_loss: 0.3094 - val_mae: 0.4460\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2418 - mae: 0.3803 - val_loss: 0.3785 - val_mae: 0.4768\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2190 - mae: 0.3772 - val_loss: 0.3320 - val_mae: 0.4548\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2116 - mae: 0.3762 - val_loss: 0.3162 - val_mae: 0.4570\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2047 - mae: 0.3674 - val_loss: 0.3537 - val_mae: 0.4714\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1793 - mae: 0.3478 - val_loss: 0.3538 - val_mae: 0.4622\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1755 - mae: 0.3485 - val_loss: 0.3484 - val_mae: 0.4618\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.1943 - mae: 0.3612 - val_loss: 0.3559 - val_mae: 0.4696\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1999 - mae: 0.3579 - val_loss: 0.3385 - val_mae: 0.4635\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1910 - mae: 0.3501 - val_loss: 0.3469 - val_mae: 0.4642\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1650 - mae: 0.3229 - val_loss: 0.3791 - val_mae: 0.4765\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1637 - mae: 0.3341 - val_loss: 0.3446 - val_mae: 0.4644\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1545 - mae: 0.3214 - val_loss: 0.3865 - val_mae: 0.4831\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1701 - mae: 0.3296 - val_loss: 0.3810 - val_mae: 0.4763\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1388 - mae: 0.3115 - val_loss: 0.3811 - val_mae: 0.4760\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1451 - mae: 0.3031 - val_loss: 0.3706 - val_mae: 0.4682\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1190 - mae: 0.2880 - val_loss: 0.3671 - val_mae: 0.4690\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1225 - mae: 0.2871 - val_loss: 0.3798 - val_mae: 0.4708\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1158 - mae: 0.2818 - val_loss: 0.4009 - val_mae: 0.4808\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1396 - mae: 0.3051 - val_loss: 0.3673 - val_mae: 0.4727\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1260 - mae: 0.2805 - val_loss: 0.3649 - val_mae: 0.4718\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1198 - mae: 0.2719 - val_loss: 0.3544 - val_mae: 0.4660\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1223 - mae: 0.2797 - val_loss: 0.3475 - val_mae: 0.4619\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1070 - mae: 0.2615 - val_loss: 0.3719 - val_mae: 0.4697\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0903 - mae: 0.2469 - val_loss: 0.3561 - val_mae: 0.4656\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1047 - mae: 0.2525 - val_loss: 0.3585 - val_mae: 0.4633\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0888 - mae: 0.2436 - val_loss: 0.3453 - val_mae: 0.4593\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0808 - mae: 0.2301 - val_loss: 0.3519 - val_mae: 0.4624\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0850 - mae: 0.2354 - val_loss: 0.3773 - val_mae: 0.4762\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0930 - mae: 0.2518 - val_loss: 0.3581 - val_mae: 0.4623\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0868 - mae: 0.2248 - val_loss: 0.3551 - val_mae: 0.4586\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0748 - mae: 0.2169 - val_loss: 0.3676 - val_mae: 0.4637\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0808 - mae: 0.2235 - val_loss: 0.3885 - val_mae: 0.4812\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0728 - mae: 0.2172 - val_loss: 0.3684 - val_mae: 0.4656\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0727 - mae: 0.2167 - val_loss: 0.3529 - val_mae: 0.4594\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0694 - mae: 0.2013 - val_loss: 0.3613 - val_mae: 0.4581\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0735 - mae: 0.2164 - val_loss: 0.3619 - val_mae: 0.4643\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0745 - mae: 0.2083 - val_loss: 0.3696 - val_mae: 0.4696\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0640 - mae: 0.1981 - val_loss: 0.3592 - val_mae: 0.4574\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0644 - mae: 0.2044 - val_loss: 0.3978 - val_mae: 0.4814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.3152 - mae: 1.1154 - val_loss: 0.3164 - val_mae: 0.4581\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.7197 - mae: 0.6369 - val_loss: 0.2859 - val_mae: 0.4040\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.5434 - mae: 0.5613 - val_loss: 0.2800 - val_mae: 0.4244\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.4862 - mae: 0.5122 - val_loss: 0.3045 - val_mae: 0.4476\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.4492 - mae: 0.5081 - val_loss: 0.3211 - val_mae: 0.4679\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3806 - mae: 0.4737 - val_loss: 0.3108 - val_mae: 0.4487\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3290 - mae: 0.4500 - val_loss: 0.3336 - val_mae: 0.4620\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3354 - mae: 0.4430 - val_loss: 0.3287 - val_mae: 0.4563\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3128 - mae: 0.4397 - val_loss: 0.3197 - val_mae: 0.4465\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2828 - mae: 0.4231 - val_loss: 0.3180 - val_mae: 0.4466\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2576 - mae: 0.4114 - val_loss: 0.3463 - val_mae: 0.4546\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2646 - mae: 0.4163 - val_loss: 0.3163 - val_mae: 0.4455\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2399 - mae: 0.3890 - val_loss: 0.3674 - val_mae: 0.4659\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2293 - mae: 0.3921 - val_loss: 0.3527 - val_mae: 0.4601\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2187 - mae: 0.3786 - val_loss: 0.3476 - val_mae: 0.4544\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2102 - mae: 0.3707 - val_loss: 0.3142 - val_mae: 0.4389\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1923 - mae: 0.3525 - val_loss: 0.3167 - val_mae: 0.4404\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1933 - mae: 0.3610 - val_loss: 0.3199 - val_mae: 0.4470\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2082 - mae: 0.3701 - val_loss: 0.3361 - val_mae: 0.4545\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1896 - mae: 0.3555 - val_loss: 0.3344 - val_mae: 0.4565\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1686 - mae: 0.3427 - val_loss: 0.3567 - val_mae: 0.4617\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1595 - mae: 0.3260 - val_loss: 0.3328 - val_mae: 0.4546\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1542 - mae: 0.3193 - val_loss: 0.3362 - val_mae: 0.4560\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.1659 - mae: 0.3307 - val_loss: 0.3371 - val_mae: 0.4579\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1700 - mae: 0.3290 - val_loss: 0.3820 - val_mae: 0.4849\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1570 - mae: 0.3224 - val_loss: 0.3756 - val_mae: 0.4769\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1461 - mae: 0.3110 - val_loss: 0.3611 - val_mae: 0.4613\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1348 - mae: 0.2962 - val_loss: 0.3914 - val_mae: 0.4753\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1324 - mae: 0.2977 - val_loss: 0.3645 - val_mae: 0.4701\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1189 - mae: 0.2872 - val_loss: 0.3577 - val_mae: 0.4686\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1037 - mae: 0.2728 - val_loss: 0.3816 - val_mae: 0.4801\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1145 - mae: 0.2697 - val_loss: 0.3986 - val_mae: 0.4821\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1097 - mae: 0.2686 - val_loss: 0.3722 - val_mae: 0.4682\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1006 - mae: 0.2558 - val_loss: 0.3493 - val_mae: 0.4617\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1181 - mae: 0.2682 - val_loss: 0.3689 - val_mae: 0.4675\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0949 - mae: 0.2493 - val_loss: 0.3702 - val_mae: 0.4742\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0959 - mae: 0.2505 - val_loss: 0.3531 - val_mae: 0.4598\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2391 - val_loss: 0.3625 - val_mae: 0.4604\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0848 - mae: 0.2314 - val_loss: 0.3813 - val_mae: 0.4756\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0826 - mae: 0.2350 - val_loss: 0.3856 - val_mae: 0.4712\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0770 - mae: 0.2203 - val_loss: 0.3910 - val_mae: 0.4778\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0738 - mae: 0.2185 - val_loss: 0.3621 - val_mae: 0.4649\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0691 - mae: 0.2101 - val_loss: 0.3776 - val_mae: 0.4742\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0709 - mae: 0.2123 - val_loss: 0.3803 - val_mae: 0.4709\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0758 - mae: 0.2157 - val_loss: 0.3800 - val_mae: 0.4731\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0718 - mae: 0.2133 - val_loss: 0.3948 - val_mae: 0.4849\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0677 - mae: 0.2102 - val_loss: 0.3618 - val_mae: 0.4696\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0726 - mae: 0.2076 - val_loss: 0.3631 - val_mae: 0.4641\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0777 - mae: 0.2118 - val_loss: 0.3957 - val_mae: 0.4833\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0673 - mae: 0.2061 - val_loss: 0.3884 - val_mae: 0.4711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.3505 - mae: 0.8589 - val_loss: 0.4325 - val_mae: 0.5556\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6496 - mae: 0.6144 - val_loss: 0.3807 - val_mae: 0.4530\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4852 - mae: 0.5225 - val_loss: 0.3224 - val_mae: 0.4428\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4139 - mae: 0.4859 - val_loss: 0.2837 - val_mae: 0.4201\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4078 - mae: 0.4931 - val_loss: 0.2861 - val_mae: 0.4285\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3726 - mae: 0.4678 - val_loss: 0.2957 - val_mae: 0.4361\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3257 - mae: 0.4452 - val_loss: 0.3070 - val_mae: 0.4438\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3137 - mae: 0.4361 - val_loss: 0.3357 - val_mae: 0.4734\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2778 - mae: 0.4273 - val_loss: 0.3163 - val_mae: 0.4493\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2802 - mae: 0.4172 - val_loss: 0.3243 - val_mae: 0.4572\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2586 - mae: 0.4011 - val_loss: 0.3356 - val_mae: 0.4686\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.2533 - mae: 0.4031 - val_loss: 0.3406 - val_mae: 0.4668\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2472 - mae: 0.4036 - val_loss: 0.3341 - val_mae: 0.4651\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2275 - mae: 0.3894 - val_loss: 0.3222 - val_mae: 0.4499\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2128 - mae: 0.3738 - val_loss: 0.3081 - val_mae: 0.4456\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2090 - mae: 0.3632 - val_loss: 0.3298 - val_mae: 0.4547\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1896 - mae: 0.3489 - val_loss: 0.3254 - val_mae: 0.4619\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1799 - mae: 0.3459 - val_loss: 0.3284 - val_mae: 0.4638\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1679 - mae: 0.3364 - val_loss: 0.3266 - val_mae: 0.4529\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1593 - mae: 0.3316 - val_loss: 0.3225 - val_mae: 0.4509\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1506 - mae: 0.3173 - val_loss: 0.3424 - val_mae: 0.4567\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1683 - mae: 0.3374 - val_loss: 0.3228 - val_mae: 0.4483\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1454 - mae: 0.3067 - val_loss: 0.3102 - val_mae: 0.4398\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1501 - mae: 0.3108 - val_loss: 0.3160 - val_mae: 0.4362\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1534 - mae: 0.3189 - val_loss: 0.3189 - val_mae: 0.4412\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1471 - mae: 0.3110 - val_loss: 0.3084 - val_mae: 0.4325\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1354 - mae: 0.3035 - val_loss: 0.3509 - val_mae: 0.4677\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1411 - mae: 0.3028 - val_loss: 0.3343 - val_mae: 0.4530\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1240 - mae: 0.2839 - val_loss: 0.3312 - val_mae: 0.4482\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1190 - mae: 0.2831 - val_loss: 0.3296 - val_mae: 0.4457\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1070 - mae: 0.2703 - val_loss: 0.3364 - val_mae: 0.4452\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1031 - mae: 0.2669 - val_loss: 0.3322 - val_mae: 0.4473\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1022 - mae: 0.2535 - val_loss: 0.3326 - val_mae: 0.4402\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1081 - mae: 0.2546 - val_loss: 0.3278 - val_mae: 0.4430\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1001 - mae: 0.2588 - val_loss: 0.3294 - val_mae: 0.4442\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0908 - mae: 0.2504 - val_loss: 0.3327 - val_mae: 0.4474\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0865 - mae: 0.2362 - val_loss: 0.3184 - val_mae: 0.4353\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0815 - mae: 0.2316 - val_loss: 0.3421 - val_mae: 0.4471\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0800 - mae: 0.2366 - val_loss: 0.3315 - val_mae: 0.4438\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0820 - mae: 0.2338 - val_loss: 0.3223 - val_mae: 0.4298\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0719 - mae: 0.2143 - val_loss: 0.3149 - val_mae: 0.4296\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0823 - mae: 0.2308 - val_loss: 0.3234 - val_mae: 0.4362\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0788 - mae: 0.2259 - val_loss: 0.3348 - val_mae: 0.4433\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0714 - mae: 0.2149 - val_loss: 0.3385 - val_mae: 0.4409\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0717 - mae: 0.2196 - val_loss: 0.3258 - val_mae: 0.4350\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0693 - mae: 0.2119 - val_loss: 0.3312 - val_mae: 0.4364\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0643 - mae: 0.2043 - val_loss: 0.3206 - val_mae: 0.4366\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0607 - mae: 0.1968 - val_loss: 0.3345 - val_mae: 0.4342\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0604 - mae: 0.1937 - val_loss: 0.3409 - val_mae: 0.4446\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0653 - mae: 0.2026 - val_loss: 0.3356 - val_mae: 0.4390\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3392 - mae: 0.4353\n",
            "Test MAE for Pa: 0.44178450107574463\n",
            "Training model for Total...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 777.6163 - mae: 22.2487 - val_loss: 504.1802 - val_mae: 21.7620\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 191.3007 - mae: 15.4687 - val_loss: 209.3230 - val_mae: 13.8447\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 107.4950 - mae: 11.2411 - val_loss: 114.7808 - val_mae: 9.4612\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 66.8090 - mae: 8.3693 - val_loss: 86.2533 - val_mae: 7.4427\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 59.0661 - mae: 8.0219 - val_loss: 61.9720 - val_mae: 6.1370\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 53.1878 - mae: 6.8410 - val_loss: 48.5788 - val_mae: 5.4705\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 45.0903 - mae: 6.0101 - val_loss: 38.6213 - val_mae: 4.9434\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 45.1767 - mae: 5.5334 - val_loss: 29.6063 - val_mae: 4.4283\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 29.4058 - mae: 4.8068 - val_loss: 23.9907 - val_mae: 3.9780\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.2230 - mae: 4.5680 - val_loss: 16.7039 - val_mae: 3.2672\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 36.7523 - mae: 4.4167 - val_loss: 18.3516 - val_mae: 3.3968\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.6919 - mae: 4.0835 - val_loss: 23.4938 - val_mae: 3.9022\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 27.3081 - mae: 4.3622 - val_loss: 15.6368 - val_mae: 3.1463\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 25.3242 - mae: 3.9308 - val_loss: 17.3319 - val_mae: 3.3138\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 24.9422 - mae: 3.8222 - val_loss: 16.4697 - val_mae: 3.1917\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 20.8102 - mae: 3.6732 - val_loss: 15.6310 - val_mae: 3.1210\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 25.4992 - mae: 3.9655 - val_loss: 14.1177 - val_mae: 3.0206\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 22.5605 - mae: 3.6682 - val_loss: 15.0561 - val_mae: 3.0991\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 19.9181 - mae: 3.5660 - val_loss: 13.3882 - val_mae: 2.9390\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 24.8666 - mae: 3.6543 - val_loss: 16.9572 - val_mae: 3.2550\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 26.1086 - mae: 3.9947 - val_loss: 13.5033 - val_mae: 2.9388\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 20.3405 - mae: 3.5729 - val_loss: 12.8287 - val_mae: 2.8695\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.8448 - mae: 3.5108 - val_loss: 14.6543 - val_mae: 3.0524\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.8445 - mae: 3.5088 - val_loss: 15.0269 - val_mae: 3.0776\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.6656 - mae: 3.4898 - val_loss: 12.9028 - val_mae: 2.8791\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.4259 - mae: 3.4410 - val_loss: 13.8291 - val_mae: 2.9678\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 22.2822 - mae: 3.6398 - val_loss: 14.7706 - val_mae: 3.0296\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.7147 - mae: 3.5260 - val_loss: 12.6150 - val_mae: 2.7978\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.6505 - mae: 3.5002 - val_loss: 13.8646 - val_mae: 2.9205\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 30.5935 - mae: 3.6480 - val_loss: 12.2742 - val_mae: 2.7478\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 22.3731 - mae: 3.2616 - val_loss: 14.2220 - val_mae: 2.9881\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 19.8639 - mae: 3.3510 - val_loss: 12.7930 - val_mae: 2.8271\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 20.7380 - mae: 3.2807 - val_loss: 12.9453 - val_mae: 2.8397\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 19.6770 - mae: 3.2559 - val_loss: 12.5985 - val_mae: 2.8126\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 17.8232 - mae: 3.2439 - val_loss: 12.4293 - val_mae: 2.7996\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 17.5266 - mae: 3.2070 - val_loss: 12.7070 - val_mae: 2.8451\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.3496 - mae: 3.3500 - val_loss: 12.9259 - val_mae: 2.8288\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 16.6096 - mae: 3.2642 - val_loss: 12.4980 - val_mae: 2.8035\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.5269 - mae: 3.1455 - val_loss: 12.2035 - val_mae: 2.7727\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 14.8481 - mae: 3.1155 - val_loss: 13.1877 - val_mae: 2.8990\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.7472 - mae: 3.1670 - val_loss: 14.6363 - val_mae: 3.0189\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.7680 - mae: 3.1467 - val_loss: 12.6481 - val_mae: 2.8041\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.9213 - mae: 3.1247 - val_loss: 12.6087 - val_mae: 2.8091\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 25.2890 - mae: 3.4067 - val_loss: 20.4580 - val_mae: 3.5778\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 20.1359 - mae: 3.4722 - val_loss: 13.7346 - val_mae: 2.9655\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 35.5729 - mae: 3.3859 - val_loss: 13.5341 - val_mae: 2.9132\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 18.1825 - mae: 3.1083 - val_loss: 15.6482 - val_mae: 3.1062\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 23.8663 - mae: 3.4561 - val_loss: 13.6395 - val_mae: 2.9524\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 18.3840 - mae: 3.0455 - val_loss: 13.4371 - val_mae: 2.8795\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 17.2237 - mae: 3.1442 - val_loss: 13.1002 - val_mae: 2.8303\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 634.3503 - mae: 23.6705 - val_loss: 574.3726 - val_mae: 22.9440\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 199.7439 - mae: 15.6653 - val_loss: 237.8061 - val_mae: 14.7459\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 69.6459 - mae: 8.8538 - val_loss: 104.0445 - val_mae: 9.2316\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 43.7287 - mae: 6.7988 - val_loss: 62.4081 - val_mae: 6.8050\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 39.1153 - mae: 5.7013 - val_loss: 30.2434 - val_mae: 4.5250\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 30.2915 - mae: 4.7744 - val_loss: 20.6563 - val_mae: 3.6054\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 26.0307 - mae: 4.4913 - val_loss: 15.5501 - val_mae: 3.0273\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 20.4457 - mae: 4.1094 - val_loss: 14.9603 - val_mae: 3.0360\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 22.9069 - mae: 3.7709 - val_loss: 16.2945 - val_mae: 3.1156\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 19.2318 - mae: 3.8081 - val_loss: 15.0456 - val_mae: 2.9925\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 27.4401 - mae: 3.9255 - val_loss: 14.1357 - val_mae: 2.9150\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.1820 - mae: 3.4524 - val_loss: 15.8200 - val_mae: 3.0454\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 31.1355 - mae: 3.8785 - val_loss: 14.3868 - val_mae: 2.9104\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 17.1115 - mae: 3.5450 - val_loss: 14.5049 - val_mae: 2.9283\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.4704 - mae: 3.4884 - val_loss: 13.6980 - val_mae: 2.8536\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.7529 - mae: 3.5482 - val_loss: 14.1994 - val_mae: 2.9038\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.6862 - mae: 3.5265 - val_loss: 15.0507 - val_mae: 2.9829\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.0081 - mae: 3.4648 - val_loss: 18.1785 - val_mae: 3.1810\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.2490 - mae: 3.5645 - val_loss: 15.8246 - val_mae: 3.0996\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.0469 - mae: 3.3237 - val_loss: 14.1983 - val_mae: 2.8422\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 16.2680 - mae: 3.3026 - val_loss: 16.8534 - val_mae: 3.0944\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 23.3723 - mae: 3.6650 - val_loss: 14.4185 - val_mae: 2.9718\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 15.7904 - mae: 3.3886 - val_loss: 15.4692 - val_mae: 3.0694\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 15.1702 - mae: 3.3857 - val_loss: 14.4023 - val_mae: 2.9635\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 15.6746 - mae: 3.2268 - val_loss: 15.7350 - val_mae: 3.1247\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 15.9982 - mae: 3.3701 - val_loss: 14.8048 - val_mae: 3.0022\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.7438 - mae: 3.1188 - val_loss: 15.1094 - val_mae: 3.0477\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.9279 - mae: 3.2098 - val_loss: 15.0006 - val_mae: 2.9608\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.1552 - mae: 3.1505 - val_loss: 13.5706 - val_mae: 2.8680\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 13.3472 - mae: 3.2185 - val_loss: 13.7527 - val_mae: 2.8727\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 14.1491 - mae: 3.1236 - val_loss: 13.5193 - val_mae: 2.8246\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 15.6496 - mae: 3.0688 - val_loss: 13.7257 - val_mae: 2.8691\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 12.4292 - mae: 2.9879 - val_loss: 13.7745 - val_mae: 2.9030\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 13.4709 - mae: 3.1081 - val_loss: 14.4798 - val_mae: 2.9227\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 16.4641 - mae: 3.1843 - val_loss: 14.1719 - val_mae: 2.9045\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 12.1449 - mae: 3.0844 - val_loss: 14.0439 - val_mae: 2.9089\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 31.8969 - mae: 3.1639 - val_loss: 14.7403 - val_mae: 2.9578\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 11.6057 - mae: 2.9612 - val_loss: 15.4866 - val_mae: 3.0394\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 15.8344 - mae: 3.1512 - val_loss: 13.9130 - val_mae: 2.8805\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.5464 - mae: 2.9880 - val_loss: 14.2436 - val_mae: 2.8932\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.7324 - mae: 3.1655 - val_loss: 13.9805 - val_mae: 2.8812\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 11.4872 - mae: 2.8873 - val_loss: 13.8515 - val_mae: 2.9217\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 17.3284 - mae: 3.0629 - val_loss: 14.3467 - val_mae: 2.9129\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.8413 - mae: 2.9880 - val_loss: 14.6552 - val_mae: 2.9647\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.4983 - mae: 3.1449 - val_loss: 13.7873 - val_mae: 2.9006\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.3376 - mae: 2.9128 - val_loss: 14.4450 - val_mae: 2.9292\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.1845 - mae: 2.9646 - val_loss: 14.3185 - val_mae: 2.9464\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.3318 - mae: 2.9752 - val_loss: 13.8993 - val_mae: 2.8679\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 11.9713 - mae: 2.7867 - val_loss: 13.5624 - val_mae: 2.8441\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 20.5670 - mae: 2.8831 - val_loss: 14.2368 - val_mae: 2.9171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 642.5594 - mae: 24.5686 - val_loss: 550.4560 - val_mae: 22.6401\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 209.5642 - mae: 17.0802 - val_loss: 295.1565 - val_mae: 16.6031\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 92.4901 - mae: 10.8903 - val_loss: 154.7289 - val_mae: 11.5768\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 57.1791 - mae: 8.2493 - val_loss: 87.1544 - val_mae: 8.0060\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 42.2485 - mae: 6.7216 - val_loss: 44.6704 - val_mae: 5.4475\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 34.1200 - mae: 5.5200 - val_loss: 26.6142 - val_mae: 4.1674\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.7245 - mae: 4.8460 - val_loss: 23.1358 - val_mae: 3.9354\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 23.1716 - mae: 4.2089 - val_loss: 17.7744 - val_mae: 3.2598\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.9642 - mae: 4.0669 - val_loss: 15.9962 - val_mae: 3.0479\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 19.2747 - mae: 3.8650 - val_loss: 14.7385 - val_mae: 2.9394\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 26.3290 - mae: 3.9976 - val_loss: 13.3117 - val_mae: 2.7654\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 20.1862 - mae: 3.7695 - val_loss: 14.1568 - val_mae: 2.8919\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 18.3860 - mae: 3.6820 - val_loss: 12.3286 - val_mae: 2.6897\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 24.4013 - mae: 3.9714 - val_loss: 12.5784 - val_mae: 2.6530\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.1479 - mae: 3.5939 - val_loss: 13.4932 - val_mae: 2.7272\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.9783 - mae: 3.7990 - val_loss: 13.1993 - val_mae: 2.7380\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.3633 - mae: 3.6089 - val_loss: 13.8021 - val_mae: 2.8218\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 17.5563 - mae: 3.6046 - val_loss: 13.0727 - val_mae: 2.7457\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.3033 - mae: 3.4611 - val_loss: 13.0217 - val_mae: 2.7412\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.0571 - mae: 3.5660 - val_loss: 12.3773 - val_mae: 2.6177\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.7243 - mae: 3.4128 - val_loss: 12.6520 - val_mae: 2.6692\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.3103 - mae: 3.3725 - val_loss: 13.3440 - val_mae: 2.7425\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.7407 - mae: 3.3000 - val_loss: 12.7498 - val_mae: 2.6840\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.3421 - mae: 3.3529 - val_loss: 12.1677 - val_mae: 2.6127\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 16.7538 - mae: 3.3390 - val_loss: 12.7224 - val_mae: 2.6856\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 14.5377 - mae: 3.2502 - val_loss: 13.1522 - val_mae: 2.7277\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 17.0467 - mae: 3.2083 - val_loss: 12.2401 - val_mae: 2.6249\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 13.5804 - mae: 3.1786 - val_loss: 12.2941 - val_mae: 2.6328\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 16.1137 - mae: 3.2084 - val_loss: 12.8162 - val_mae: 2.6834\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 14.0508 - mae: 3.1113 - val_loss: 12.5165 - val_mae: 2.6280\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.8452 - mae: 3.1445 - val_loss: 12.3906 - val_mae: 2.6386\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.3784 - mae: 3.1454 - val_loss: 12.4760 - val_mae: 2.6694\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.5415 - mae: 3.1157 - val_loss: 13.2570 - val_mae: 2.7144\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.0691 - mae: 3.2108 - val_loss: 11.8542 - val_mae: 2.5637\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.5351 - mae: 3.0194 - val_loss: 11.7076 - val_mae: 2.5630\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.9651 - mae: 3.1994 - val_loss: 12.8567 - val_mae: 2.6789\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.9698 - mae: 3.2908 - val_loss: 12.2459 - val_mae: 2.6542\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.4278 - mae: 3.0787 - val_loss: 12.9520 - val_mae: 2.7608\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.0676 - mae: 3.1764 - val_loss: 11.9201 - val_mae: 2.6278\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 15.9336 - mae: 3.1524 - val_loss: 12.8337 - val_mae: 2.7502\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 12.0134 - mae: 2.9777 - val_loss: 14.4735 - val_mae: 2.8494\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 15.7388 - mae: 3.1282 - val_loss: 12.3139 - val_mae: 2.6571\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 13.5652 - mae: 2.9747 - val_loss: 11.8567 - val_mae: 2.6293\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 11.7627 - mae: 2.9610 - val_loss: 12.4540 - val_mae: 2.6804\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 15.4629 - mae: 3.0299 - val_loss: 12.4926 - val_mae: 2.6969\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.4170 - mae: 2.8657 - val_loss: 13.7843 - val_mae: 2.8079\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.1837 - mae: 2.8776 - val_loss: 14.0567 - val_mae: 2.8058\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 10.4974 - mae: 2.7995 - val_loss: 14.6483 - val_mae: 2.8503\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.7815 - mae: 3.0294 - val_loss: 12.4541 - val_mae: 2.6369\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.3980 - mae: 2.9484 - val_loss: 13.7431 - val_mae: 2.7515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 468.5814 - mae: 22.5339 - val_loss: 451.9274 - val_mae: 20.6778\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 134.2299 - mae: 13.4901 - val_loss: 229.9931 - val_mae: 14.5814\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 72.5159 - mae: 9.4063 - val_loss: 113.6640 - val_mae: 9.8607\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 47.9894 - mae: 7.2880 - val_loss: 67.7855 - val_mae: 7.2187\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 40.4738 - mae: 6.1456 - val_loss: 35.4752 - val_mae: 4.9431\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 32.5301 - mae: 5.1223 - val_loss: 18.9397 - val_mae: 3.4986\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 27.3635 - mae: 4.5365 - val_loss: 15.7898 - val_mae: 3.1550\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 30.6871 - mae: 4.6943 - val_loss: 12.4571 - val_mae: 2.7789\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 23.6675 - mae: 4.0051 - val_loss: 12.9737 - val_mae: 2.8463\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.9089 - mae: 3.6125 - val_loss: 12.6598 - val_mae: 2.7934\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 22.4552 - mae: 3.9064 - val_loss: 14.6940 - val_mae: 2.9571\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.8381 - mae: 3.6830 - val_loss: 12.7318 - val_mae: 2.8282\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.8878 - mae: 3.6286 - val_loss: 12.4750 - val_mae: 2.7916\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 17.2360 - mae: 3.6405 - val_loss: 12.7391 - val_mae: 2.7896\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.2316 - mae: 3.5212 - val_loss: 12.5445 - val_mae: 2.7746\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.3769 - mae: 3.5054 - val_loss: 12.5058 - val_mae: 2.7951\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 15.7151 - mae: 3.3422 - val_loss: 12.4614 - val_mae: 2.8049\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 18.9233 - mae: 3.3806 - val_loss: 12.3972 - val_mae: 2.7792\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 17.5834 - mae: 3.2518 - val_loss: 12.7623 - val_mae: 2.8331\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 16.1352 - mae: 3.4234 - val_loss: 14.1489 - val_mae: 2.9860\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 17.6510 - mae: 3.4391 - val_loss: 13.8809 - val_mae: 2.9800\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.8695 - mae: 3.7677 - val_loss: 15.5585 - val_mae: 3.0856\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 17.6549 - mae: 3.4998 - val_loss: 12.3523 - val_mae: 2.7196\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 17.2500 - mae: 3.2534 - val_loss: 12.4550 - val_mae: 2.7898\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.2461 - mae: 3.4617 - val_loss: 12.5789 - val_mae: 2.7848\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 20.1201 - mae: 3.4333 - val_loss: 11.6780 - val_mae: 2.7060\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.0694 - mae: 3.4001 - val_loss: 11.4960 - val_mae: 2.6422\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.5414 - mae: 3.4378 - val_loss: 12.2848 - val_mae: 2.7759\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.5802 - mae: 3.1789 - val_loss: 13.0602 - val_mae: 2.8231\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.5807 - mae: 3.3108 - val_loss: 11.8962 - val_mae: 2.7005\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 16.6286 - mae: 3.3102 - val_loss: 11.9987 - val_mae: 2.7197\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 12.7494 - mae: 3.1349 - val_loss: 12.9708 - val_mae: 2.8023\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 13.8175 - mae: 3.1336 - val_loss: 12.8144 - val_mae: 2.8694\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 13.7757 - mae: 3.0895 - val_loss: 11.6169 - val_mae: 2.6714\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 14.9193 - mae: 3.1493 - val_loss: 11.3932 - val_mae: 2.6385\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 13.8906 - mae: 3.1074 - val_loss: 12.0228 - val_mae: 2.6666\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.7900 - mae: 3.1712 - val_loss: 12.7094 - val_mae: 2.7947\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 14.8077 - mae: 3.1098 - val_loss: 11.3710 - val_mae: 2.6347\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.9638 - mae: 3.1142 - val_loss: 13.6269 - val_mae: 2.8737\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.4089 - mae: 3.0381 - val_loss: 12.6587 - val_mae: 2.7576\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.6174 - mae: 3.0655 - val_loss: 12.5035 - val_mae: 2.7562\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.8539 - mae: 3.0934 - val_loss: 11.7413 - val_mae: 2.6818\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.2464 - mae: 2.9677 - val_loss: 12.7937 - val_mae: 2.7960\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.0723 - mae: 2.9614 - val_loss: 14.9474 - val_mae: 2.9893\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 17.2127 - mae: 3.1780 - val_loss: 11.5547 - val_mae: 2.6263\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 11.7403 - mae: 2.9109 - val_loss: 13.2256 - val_mae: 2.8045\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 19.1794 - mae: 2.9709 - val_loss: 11.8829 - val_mae: 2.6760\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 13.1488 - mae: 2.9646 - val_loss: 12.1372 - val_mae: 2.7220\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 14.2646 - mae: 2.9612 - val_loss: 12.3555 - val_mae: 2.7723\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.7274 - mae: 2.8656 - val_loss: 11.7886 - val_mae: 2.7055\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 612.7885 - mae: 23.0731 - val_loss: 538.0311 - val_mae: 22.2386\n",
            "Epoch 2/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 215.8048 - mae: 14.7958 - val_loss: 274.8913 - val_mae: 15.9299\n",
            "Epoch 3/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 77.9630 - mae: 8.8080 - val_loss: 151.2961 - val_mae: 11.3427\n",
            "Epoch 4/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 47.6271 - mae: 6.8470 - val_loss: 76.9476 - val_mae: 7.5279\n",
            "Epoch 5/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 37.8861 - mae: 5.5855 - val_loss: 38.8043 - val_mae: 5.1150\n",
            "Epoch 6/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 37.0207 - mae: 4.8798 - val_loss: 21.0056 - val_mae: 3.5364\n",
            "Epoch 7/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 27.4309 - mae: 4.3972 - val_loss: 16.9567 - val_mae: 3.1301\n",
            "Epoch 8/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 22.9248 - mae: 3.9777 - val_loss: 18.7127 - val_mae: 3.3608\n",
            "Epoch 9/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 23.2428 - mae: 4.0544 - val_loss: 15.9519 - val_mae: 3.0963\n",
            "Epoch 10/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 28.9793 - mae: 4.1076 - val_loss: 16.0498 - val_mae: 3.0362\n",
            "Epoch 11/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 20.6621 - mae: 3.9464 - val_loss: 14.1108 - val_mae: 2.8765\n",
            "Epoch 12/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 23.3807 - mae: 3.6654 - val_loss: 18.6690 - val_mae: 3.2787\n",
            "Epoch 13/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 22.0738 - mae: 4.0032 - val_loss: 14.5668 - val_mae: 2.9390\n",
            "Epoch 14/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.7854 - mae: 3.6002 - val_loss: 15.8784 - val_mae: 3.1033\n",
            "Epoch 15/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 17.6138 - mae: 3.6840 - val_loss: 13.9432 - val_mae: 2.9032\n",
            "Epoch 16/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.0515 - mae: 3.5885 - val_loss: 14.0351 - val_mae: 2.8862\n",
            "Epoch 17/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 20.0435 - mae: 3.5446 - val_loss: 14.6837 - val_mae: 2.9930\n",
            "Epoch 18/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.9858 - mae: 3.4142 - val_loss: 14.9757 - val_mae: 2.9798\n",
            "Epoch 19/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 17.7635 - mae: 3.6305 - val_loss: 14.1914 - val_mae: 2.9313\n",
            "Epoch 20/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.7909 - mae: 3.6254 - val_loss: 13.9926 - val_mae: 2.8742\n",
            "Epoch 21/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 15.5245 - mae: 3.3253 - val_loss: 13.6022 - val_mae: 2.8333\n",
            "Epoch 22/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 16.1287 - mae: 3.2404 - val_loss: 13.5501 - val_mae: 2.8231\n",
            "Epoch 23/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 17.6560 - mae: 3.4437 - val_loss: 14.3751 - val_mae: 2.8844\n",
            "Epoch 24/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 18.4612 - mae: 3.4304 - val_loss: 13.2593 - val_mae: 2.8225\n",
            "Epoch 25/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 16.1709 - mae: 3.4648 - val_loss: 12.9322 - val_mae: 2.7890\n",
            "Epoch 26/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.6101 - mae: 3.1863 - val_loss: 13.3837 - val_mae: 2.8501\n",
            "Epoch 27/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.3607 - mae: 3.2758 - val_loss: 14.2840 - val_mae: 2.8976\n",
            "Epoch 28/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.8825 - mae: 3.2229 - val_loss: 15.2714 - val_mae: 3.0084\n",
            "Epoch 29/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 15.2646 - mae: 3.2864 - val_loss: 16.4669 - val_mae: 3.0895\n",
            "Epoch 30/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.4684 - mae: 3.1064 - val_loss: 14.0249 - val_mae: 2.8980\n",
            "Epoch 31/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.1372 - mae: 3.3695 - val_loss: 14.8333 - val_mae: 2.9954\n",
            "Epoch 32/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 16.8737 - mae: 3.2237 - val_loss: 15.0584 - val_mae: 2.9541\n",
            "Epoch 33/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.6399 - mae: 3.2965 - val_loss: 14.1768 - val_mae: 2.9351\n",
            "Epoch 34/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 20.8972 - mae: 3.1524 - val_loss: 14.5105 - val_mae: 2.9330\n",
            "Epoch 35/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.2189 - mae: 3.1406 - val_loss: 14.2994 - val_mae: 2.9196\n",
            "Epoch 36/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 15.0794 - mae: 3.1644 - val_loss: 13.5862 - val_mae: 2.8510\n",
            "Epoch 37/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 16.4823 - mae: 3.1309 - val_loss: 15.3694 - val_mae: 2.9749\n",
            "Epoch 38/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 15.5938 - mae: 3.3005 - val_loss: 14.2200 - val_mae: 2.9515\n",
            "Epoch 39/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 12.7622 - mae: 2.9957 - val_loss: 15.2418 - val_mae: 3.0183\n",
            "Epoch 40/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 18.3322 - mae: 3.3702 - val_loss: 13.8795 - val_mae: 2.8757\n",
            "Epoch 41/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.7537 - mae: 3.0239 - val_loss: 14.1367 - val_mae: 2.9356\n",
            "Epoch 42/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.2190 - mae: 3.0369 - val_loss: 14.4222 - val_mae: 2.9192\n",
            "Epoch 43/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 23.0312 - mae: 3.1398 - val_loss: 13.7490 - val_mae: 2.8249\n",
            "Epoch 44/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 14.4319 - mae: 2.9610 - val_loss: 13.4878 - val_mae: 2.8172\n",
            "Epoch 45/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13.0662 - mae: 3.0360 - val_loss: 13.3787 - val_mae: 2.8289\n",
            "Epoch 46/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 10.6831 - mae: 2.8969 - val_loss: 13.9041 - val_mae: 2.9254\n",
            "Epoch 47/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 12.8499 - mae: 2.9392 - val_loss: 13.7003 - val_mae: 2.8627\n",
            "Epoch 48/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 15.0726 - mae: 2.9971 - val_loss: 13.7223 - val_mae: 2.8507\n",
            "Epoch 49/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 12.3173 - mae: 2.9789 - val_loss: 14.0194 - val_mae: 2.8888\n",
            "Epoch 50/50\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 11.1028 - mae: 2.8649 - val_loss: 13.1156 - val_mae: 2.7888\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.3517 - mae: 2.6812\n",
            "Test MAE for Total: 2.8176071643829346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models to Google Drive with sanitized file names\n",
        "def sanitize_filename(name):\n",
        "    return name.replace('/', '_').replace('\\\\', '_')\n",
        "\n",
        "for criterion, model in models.items():\n",
        "    sanitized_criterion = sanitize_filename(criterion)\n",
        "    model.save(f'/content/drive/MyDrive/model_{sanitized_criterion}.keras')\n"
      ],
      "metadata": {
        "id": "Ugz2-T-VcprE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the new data file for predictions\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the uploaded file into a DataFrame\n",
        "for filename in uploaded.keys():\n",
        "    df_new_data = pd.read_csv(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Ni__1hFFeiKA",
        "outputId": "e2b44ef8-166c-43d0-beb7-8f2d6d563318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b10990d7-e2be-4e48-baa1-f68ea0f8f41d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b10990d7-e2be-4e48-baa1-f68ea0f8f41d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Data for testing new 1.csv to Data for testing new 1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure TextLength and AvgSentenceLength features are calculated for the new data\n",
        "df_new_data['TextLength'] = df_new_data['Raw text'].apply(len)\n",
        "df_new_data['AvgSentenceLength'] = df_new_data['Raw text'].apply(lambda x: len(x.split()) / (x.count('.') + 1))\n",
        "\n",
        "# Apply the same TF-IDF transformation to the new text data\n",
        "X_new_text = tfidf.transform(df_new_data['Raw text'].fillna('')).toarray()\n",
        "\n",
        "# Scale WordCount, TextLength, and AvgSentenceLength features for the new data\n",
        "X_new_scaled = scaler.transform(df_new_data[['WordCount', 'TextLength', 'AvgSentenceLength']])\n",
        "\n",
        "# Combine scaled features with TF-IDF text features for new data\n",
        "X_combined_new = np.hstack([X_new_scaled, X_new_text])\n",
        "\n"
      ],
      "metadata": {
        "id": "E-TGAApoewnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the new dataset for each criterion\n",
        "predictions = {}  # Initialize an empty dictionary to store predictions\n",
        "for criterion, model in models.items():\n",
        "    predictions[criterion] = model.predict(X_combined_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q86JDC3JfHIj",
        "outputId": "0f4389da-672b-441a-aa9e-71d3ed20b7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eff232143a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eff232148b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add predictions to the DataFrame\n",
        "df_new_data = df_new_data.copy()\n",
        "for criterion in ['Punctuation', 'Spelling', 'Vocabulary', 'SentenceStructure', 'AU', 'TS', 'ID', 'CS/PD', 'Coh', 'Pa', 'Total']:\n",
        "    df_new_data[f'Predicted_{criterion}'] = predictions[criterion].flatten()  # Flatten the predictions if needed\n",
        "\n",
        "# Ensure the 'Research ID' is included in the DataFrame\n",
        "df_new_data[['Research ID', 'Pun', 'Predicted_Punctuation', 'Spell', 'Predicted_Spelling',\n",
        "             'Voc', 'Predicted_Vocabulary', 'SS', 'Predicted_SentenceStructure', 'AU', 'Predicted_AU',\n",
        "             'TS', 'Predicted_TS', 'ID', 'Predicted_ID', 'CS/PD', 'Predicted_CS/PD',\n",
        "             'Coh', 'Predicted_Coh', 'Pa', 'Predicted_Pa', 'Total', 'Predicted_Total']].head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "muOSgRcUe_om",
        "outputId": "dd3188ba-34a9-4b23-e12f-050d5c9a68e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Research ID  Pun  Predicted_Punctuation  Spell  Predicted_Spelling  Voc  \\\n",
              "0    BJTMNVPG  NaN               1.823363    NaN            3.388788  NaN   \n",
              "1    GJSLWKTB  NaN               3.410403    NaN            5.137444  NaN   \n",
              "2    BJSZLGQD  NaN               4.065038    NaN            4.918148  NaN   \n",
              "3    BWKSSRCL  NaN               3.065855    NaN            5.621377  NaN   \n",
              "4    MBHSGPHB  NaN               4.056054    NaN            4.940531  NaN   \n",
              "\n",
              "   Predicted_Vocabulary  SS  Predicted_SentenceStructure  AU  ...  ID  \\\n",
              "0              2.433860 NaN                     2.864099 NaN  ... NaN   \n",
              "1              4.417605 NaN                     3.780169 NaN  ... NaN   \n",
              "2              3.335489 NaN                     4.239034 NaN  ... NaN   \n",
              "3              4.000545 NaN                     4.048550 NaN  ... NaN   \n",
              "4              3.783028 NaN                     3.667631 NaN  ... NaN   \n",
              "\n",
              "   Predicted_ID  CS/PD  Predicted_CS/PD  Coh  Predicted_Coh  Pa  Predicted_Pa  \\\n",
              "0      3.022624    NaN         2.643881  NaN       1.945249 NaN      1.177077   \n",
              "1      3.587497    NaN         2.970989  NaN       3.158924 NaN      0.883589   \n",
              "2      3.974502    NaN         3.172841  NaN       3.191678 NaN      1.729106   \n",
              "3      3.444714    NaN         3.594187  NaN       3.216712 NaN      1.768407   \n",
              "4      4.215660    NaN         3.549146  NaN       3.203457 NaN      1.853752   \n",
              "\n",
              "   Total  Predicted_Total  \n",
              "0    NaN        25.444159  \n",
              "1    NaN        34.909271  \n",
              "2    NaN        36.407852  \n",
              "3    NaN        38.927147  \n",
              "4    NaN        39.155968  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-245ffed6-de45-43dc-9ccd-2f897b5a3d33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Research ID</th>\n",
              "      <th>Pun</th>\n",
              "      <th>Predicted_Punctuation</th>\n",
              "      <th>Spell</th>\n",
              "      <th>Predicted_Spelling</th>\n",
              "      <th>Voc</th>\n",
              "      <th>Predicted_Vocabulary</th>\n",
              "      <th>SS</th>\n",
              "      <th>Predicted_SentenceStructure</th>\n",
              "      <th>AU</th>\n",
              "      <th>...</th>\n",
              "      <th>ID</th>\n",
              "      <th>Predicted_ID</th>\n",
              "      <th>CS/PD</th>\n",
              "      <th>Predicted_CS/PD</th>\n",
              "      <th>Coh</th>\n",
              "      <th>Predicted_Coh</th>\n",
              "      <th>Pa</th>\n",
              "      <th>Predicted_Pa</th>\n",
              "      <th>Total</th>\n",
              "      <th>Predicted_Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BJTMNVPG</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.823363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.388788</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.433860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.864099</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.022624</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.643881</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.945249</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.177077</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.444159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GJSLWKTB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.410403</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.137444</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.417605</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.780169</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.587497</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.970989</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.158924</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.883589</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.909271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BJSZLGQD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.065038</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.918148</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.335489</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.239034</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.974502</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.172841</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.191678</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.729106</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.407852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BWKSSRCL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.065855</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.621377</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000545</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.048550</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.444714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.594187</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.216712</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.768407</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.927147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MBHSGPHB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.056054</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.940531</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.783028</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.667631</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.215660</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.549146</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.203457</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.853752</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.155968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245ffed6-de45-43dc-9ccd-2f897b5a3d33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-245ffed6-de45-43dc-9ccd-2f897b5a3d33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-245ffed6-de45-43dc-9ccd-2f897b5a3d33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7e9ced3-fcb6-4007-b86a-83cf9bde61cd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7e9ced3-fcb6-4007-b86a-83cf9bde61cd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7e9ced3-fcb6-4007-b86a-83cf9bde61cd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions to a CSV file\n",
        "df_new_data.to_csv('/content/drive/MyDrive/predictions_with_research_id.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('/content/drive/MyDrive/predictions_with_research_id.csv')"
      ],
      "metadata": {
        "id": "UrpdELvxfZkv",
        "outputId": "ecc74bed-9ab8-4aa4-e34d-6f362eee669c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a5de5cf2-4ded-4d88-84c6-aa35bcdf8713\", \"predictions_with_research_id.csv\", 400481)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}